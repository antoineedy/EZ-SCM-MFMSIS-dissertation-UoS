/mnt/fast/nobackup/scratch4weeks/ae01116/zegenv/lib/python3.9/site-packages/torch/distributed/launch.py:178: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
[i 0721 11:35:08.481156 40 __init__.py:227] Total mem: 503.74GB, using 16 procs for compiling.
[i 0721 11:35:27.599991 40 jit_compiler.cc:28] Load cc_path: /usr/bin/g++
[i 0721 11:35:30.778718 40 init.cc:62] Found cuda archs: [86,]
[w 0721 11:35:30.903154 40 compiler.py:1384] CUDA arch(86)>80 will be backward-compatible
[i 0721 11:35:31.050555 40 __init__.py:411] Found mpicc(2.1.1) at /usr/bin/mpicc.
[i 0721 11:35:31.473161 40 compiler.py:34] Create cache dir: /user/HS400/ae01116/.cache/jittor/jt1.3.8/g++7.5.0/py3.9.19/Linux-4.18.0-4xa9/AMDEPYC753232-x73/default/cu11.0.221_sm_86/custom_ops
[i 0721 11:35:33.701986 40 compiler.py:956] Jittor(1.3.8.5) src: /mnt/fast/nobackup/scratch4weeks/ae01116/zegenv/lib/python3.9/site-packages/jittor
[i 0721 11:35:33.735112 40 compiler.py:957] g++ at /usr/bin/g++(7.5.0)
[i 0721 11:35:33.735195 40 compiler.py:958] cache_path: /user/HS400/ae01116/.cache/jittor/jt1.3.8/g++7.5.0/py3.9.19/Linux-4.18.0-4xa9/AMDEPYC753232-x73/default
[i 0721 11:35:33.773583 40 __init__.py:411] Found nvcc(11.0.221) at /usr/local/cuda/bin/nvcc.
[i 0721 11:35:33.811798 40 __init__.py:411] Found addr2line(2.30) at /usr/bin/addr2line.
[i 0721 11:35:34.037494 40 compiler.py:1011] cuda key:cu11.0.221_sm_86
[i 0721 11:35:34.780781 40 __init__.py:227] Total mem: 503.74GB, using 16 procs for compiling.
[i 0721 11:35:35.119732 40 jit_compiler.cc:28] Load cc_path: /usr/bin/g++
[i 0721 11:35:38.243104 40 init.cc:62] Found cuda archs: [86,]
[w 0721 11:35:38.368954 40 compiler.py:1384] CUDA arch(86)>80 will be backward-compatible
[i 0721 11:35:38.491637 40 __init__.py:411] Found mpicc(2.1.1) at /usr/bin/mpicc.
[i 0721 11:35:39.066478 96 compiler.py:956] Jittor(1.3.8.5) src: /mnt/fast/nobackup/scratch4weeks/ae01116/zegenv/lib/python3.9/site-packages/jittor
[i 0721 11:35:39.092457 96 compiler.py:957] g++ at /usr/bin/g++(7.5.0)
[i 0721 11:35:39.092530 96 compiler.py:958] cache_path: /user/HS400/ae01116/.cache/jittor/jt1.3.8/g++7.5.0/py3.9.19/Linux-4.18.0-4xa9/AMDEPYC753232-x73/default
[i 0721 11:35:39.121187 96 __init__.py:411] Found nvcc(11.0.221) at /usr/local/cuda/bin/nvcc.
[i 0721 11:35:39.149732 96 __init__.py:411] Found addr2line(2.30) at /usr/bin/addr2line.
[i 0721 11:35:39.390318 96 compiler.py:1011] cuda key:cu11.0.221_sm_86
[i 0721 11:35:40.168689 96 __init__.py:227] Total mem: 503.74GB, using 16 procs for compiling.
[i 0721 11:35:40.535522 96 jit_compiler.cc:28] Load cc_path: /usr/bin/g++
[i 0721 11:35:43.724519 96 init.cc:62] Found cuda archs: [86,]
[w 0721 11:35:43.828748 96 compiler.py:1384] CUDA arch(86)>80 will be backward-compatible
[i 0721 11:35:43.938327 96 __init__.py:411] Found mpicc(2.1.1) at /usr/bin/mpicc.
[i 0721 11:35:44.307048 40 compiler.py:956] Jittor(1.3.8.5) src: /mnt/fast/nobackup/scratch4weeks/ae01116/zegenv/lib/python3.9/site-packages/jittor
[i 0721 11:35:44.340518 40 compiler.py:957] g++ at /usr/bin/g++(7.5.0)
[i 0721 11:35:44.340594 40 compiler.py:958] cache_path: /user/HS400/ae01116/.cache/jittor/jt1.3.8/g++7.5.0/py3.9.19/Linux-4.18.0-4xa9/AMDEPYC753232-x73/default
[i 0721 11:35:44.376965 40 __init__.py:411] Found nvcc(11.0.221) at /usr/local/cuda/bin/nvcc.
[i 0721 11:35:44.409314 40 __init__.py:411] Found addr2line(2.30) at /usr/bin/addr2line.
[i 0721 11:35:44.621840 40 compiler.py:1011] cuda key:cu11.0.221_sm_86
[i 0721 11:35:45.253011 40 __init__.py:227] Total mem: 503.74GB, using 16 procs for compiling.
[i 0721 11:35:45.700187 40 jit_compiler.cc:28] Load cc_path: /usr/bin/g++
[i 0721 11:35:48.802478 40 init.cc:62] Found cuda archs: [86,]
[w 0721 11:35:48.888128 40 compiler.py:1384] CUDA arch(86)>80 will be backward-compatible
[i 0721 11:35:48.983372 40 __init__.py:411] Found mpicc(2.1.1) at /usr/bin/mpicc.
[i 0721 11:35:49.446979 40 compile_extern.py:339] Downloading cutt...
[i 0721 11:35:49.651009 40 compile_extern.py:352] installing cutt...
[i 0721 11:36:02.436118 40 compiler.py:34] Create cache dir: /user/HS400/ae01116/.cache/jittor/jt1.3.8/g++7.5.0/py3.9.19/Linux-4.18.0-4xa9/AMDEPYC753232-x73/default/cu11.0.221_sm_86/cuda
Traceback (most recent call last):
  File "/mnt/fast/nobackup/users/ae01116/multi-modal-dissertation-uos/train.py", line 15, in <module>
    import models
Traceback (most recent call last):
  File "/mnt/fast/nobackup/users/ae01116/multi-modal-dissertation-uos/models/__init__.py", line 10, in <module>
    from models.segmentor.clip_rc import CLIPRC
  File "/mnt/fast/nobackup/users/ae01116/multi-modal-dissertation-uos/models/segmentor/clip_rc.py", line 8, in <module>
    from .encoder_decoder import EncoderDecoder
ModuleNotFoundError: No module named 'models.segmentor.encoder_decoder'
  File "/mnt/fast/nobackup/users/ae01116/multi-modal-dissertation-uos/train.py", line 15, in <module>
    import models
  File "/mnt/fast/nobackup/users/ae01116/multi-modal-dissertation-uos/models/__init__.py", line 10, in <module>
    from models.segmentor.clip_rc import CLIPRC
  File "/mnt/fast/nobackup/users/ae01116/multi-modal-dissertation-uos/models/segmentor/clip_rc.py", line 8, in <module>
    from .encoder_decoder import EncoderDecoder
ModuleNotFoundError: No module named 'models.segmentor.encoder_decoder'
Traceback (most recent call last):
  File "/mnt/fast/nobackup/users/ae01116/multi-modal-dissertation-uos/train.py", line 15, in <module>
    import models
  File "/mnt/fast/nobackup/users/ae01116/multi-modal-dissertation-uos/models/__init__.py", line 10, in <module>
    from models.segmentor.clip_rc import CLIPRC
  File "/mnt/fast/nobackup/users/ae01116/multi-modal-dissertation-uos/models/segmentor/clip_rc.py", line 8, in <module>
    from .encoder_decoder import EncoderDecoder
ModuleNotFoundError: No module named 'models.segmentor.encoder_decoder'
Traceback (most recent call last):
  File "/mnt/fast/nobackup/users/ae01116/multi-modal-dissertation-uos/train.py", line 15, in <module>
    import models
  File "/mnt/fast/nobackup/users/ae01116/multi-modal-dissertation-uos/models/__init__.py", line 10, in <module>
    from models.segmentor.clip_rc import CLIPRC
  File "/mnt/fast/nobackup/users/ae01116/multi-modal-dissertation-uos/models/segmentor/clip_rc.py", line 8, in <module>
    from .encoder_decoder import EncoderDecoder
ModuleNotFoundError: No module named 'models.segmentor.encoder_decoder'
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 26) of binary: /mnt/fast/nobackup/scratch4weeks/ae01116/zegenv/bin/python
Traceback (most recent call last):
  File "/mnt/fast/nobackup/scratch4weeks/ae01116/zegenv/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/mnt/fast/nobackup/scratch4weeks/ae01116/zegenv/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/mnt/fast/nobackup/scratch4weeks/ae01116/zegenv/lib/python3.9/site-packages/torch/distributed/launch.py", line 193, in <module>
    main()
  File "/mnt/fast/nobackup/scratch4weeks/ae01116/zegenv/lib/python3.9/site-packages/torch/distributed/launch.py", line 189, in main
    launch(args)
  File "/mnt/fast/nobackup/scratch4weeks/ae01116/zegenv/lib/python3.9/site-packages/torch/distributed/launch.py", line 174, in launch
    run(args)
  File "/mnt/fast/nobackup/scratch4weeks/ae01116/zegenv/lib/python3.9/site-packages/torch/distributed/run.py", line 710, in run
    elastic_launch(
  File "/mnt/fast/nobackup/scratch4weeks/ae01116/zegenv/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 131, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/mnt/fast/nobackup/scratch4weeks/ae01116/zegenv/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 259, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
/mnt/fast/nobackup/users/ae01116/multi-modal-dissertation-uos/train.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2024-07-21_11:36:21
  host      : ae01116-176632.0-aisurrey15.surrey.ac.uk
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 27)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2024-07-21_11:36:21
  host      : ae01116-176632.0-aisurrey15.surrey.ac.uk
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 28)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[3]:
  time      : 2024-07-21_11:36:21
  host      : ae01116-176632.0-aisurrey15.surrey.ac.uk
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 29)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-07-21_11:36:21
  host      : ae01116-176632.0-aisurrey15.surrey.ac.uk
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 26)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
