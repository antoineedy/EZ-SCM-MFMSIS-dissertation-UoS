/mnt/fast/nobackup/scratch4weeks/ae01116/zegenv/lib/python3.9/site-packages/torch/distributed/launch.py:178: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
2024-06-28 09:45:05,485 - mmseg - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.9.19 (main, May  6 2024, 19:43:03) [GCC 11.2.0]
CUDA available: True
GPU 0,1,2,3: NVIDIA GeForce RTX 3090
CUDA_HOME: /usr/local/cuda
NVCC: Build cuda_11.0_bu.TC445_37.28845127_0
GCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
PyTorch: 1.10.1+cu111
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

TorchVision: 0.11.2+cu111
OpenCV: 4.10.0
MMCV: 1.4.4
MMCV Compiler: GCC 7.3
MMCV CUDA Compiler: 11.1
------------------------------------------------------------

2024-06-28 09:45:05,486 - mmseg - INFO - Distributed training: True
2024-06-28 09:45:06,356 - mmseg - INFO - Config:
norm_cfg = dict(type='SyncBN', requires_grad=True)
img_size = 512
in_channels = 512
out_indices = [11]
model = dict(
    type='MultiScalesOutputZegCLIP',
    pretrained='/mnt/fast/nobackup/scratch4weeks/ae01116/weights/ViT-B-16.pt',
    context_length=77,
    backbone=dict(
        type='VPTCLIPVisionTransformer',
        layers=12,
        style='pytorch',
        patch_size=16,
        width=768,
        output_dim=512,
        get_embeddings=True,
        drop_path_rate=0.1,
        input_resolution=512,
        out_indices=[11],
        num_tokens=10,
        prompt_dim=768,
        total_d_layer=11),
    text_encoder=dict(
        type='CLIPTextEncoder',
        context_length=77,
        style='pytorch',
        embed_dim=512,
        transformer_width=512,
        transformer_heads=8,
        transformer_layers=12),
    decode_head=dict(
        type='ATMSingleHeadSeg',
        img_size=512,
        in_channels=512,
        channels=512,
        num_classes=15,
        num_layers=3,
        num_heads=8,
        use_stages=1,
        embed_dims=512,
        loss_decode=dict(
            type='SegLossPlus',
            num_classes=15,
            dec_layers=3,
            loss_weight=1.0,
            mask_weight=100.0,
            dice_weight=1.0),
        seen_idx=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14],
        all_idx=[
            0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18,
            19
        ],
        use_proj=False),
    train_cfg=dict(),
    test_cfg=dict(mode='slide', crop_size=(512, 512), stride=(426, 426)),
    pretrained_text=
    '/mnt/fast/nobackup/scratch4weeks/ae01116/weights/ViT-B-16.pt',
    base_class=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14],
    novel_class=[15, 16, 17, 18, 19],
    both_class=[
        0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19
    ],
    ft_backbone=False,
    exclude_key='prompt',
    load_text_embedding=
    '/mnt/fast/nobackup/users/ae01116/multi-modal-dissertation-uos/configs/_base_/datasets/text_embedding/voc12_single.npy'
)
dataset_type = 'ZeroPascalVOCDataset20'
base = '/mnt/fast/nobackup/users/ae01116/multi-modal-dissertation-uos'
base_scratch = '/mnt/fast/nobackup/scratch4weeks/ae01116'
data_root = '/mnt/fast/nobackup/scratch4weeks/ae01116/data/VOC2012'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
crop_size = (512, 512)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations', reduce_zero_label=True),
    dict(type='Resize', img_scale=(2048, 512), ratio_range=(0.5, 2.0)),
    dict(type='RandomCrop', crop_size=(512, 512), cat_max_ratio=0.75),
    dict(type='RandomFlip', prob=0.5),
    dict(type='PhotoMetricDistortion'),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='Pad', size=(512, 512), pad_val=0, seg_pad_val=255),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_semantic_seg'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(2048, 512),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True, min_size=512),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
data = dict(
    samples_per_gpu=4,
    workers_per_gpu=4,
    train=dict(
        type='ZeroPascalVOCDataset20',
        data_root='/mnt/fast/nobackup/scratch4weeks/ae01116/data/VOC2012',
        img_dir='JPEGImages',
        ann_dir=['SegmentationClass', 'SegmentationClassAug'],
        split=[
            'ImageSets/Segmentation/train.txt',
            'ImageSets/Segmentation/aug.txt'
        ],
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations', reduce_zero_label=True),
            dict(type='Resize', img_scale=(2048, 512), ratio_range=(0.5, 2.0)),
            dict(type='RandomCrop', crop_size=(512, 512), cat_max_ratio=0.75),
            dict(type='RandomFlip', prob=0.5),
            dict(type='PhotoMetricDistortion'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size=(512, 512), pad_val=0, seg_pad_val=255),
            dict(type='DefaultFormatBundle'),
            dict(type='Collect', keys=['img', 'gt_semantic_seg'])
        ]),
    val=dict(
        type='ZeroPascalVOCDataset20',
        data_root='/mnt/fast/nobackup/scratch4weeks/ae01116/data/VOC2012',
        img_dir='JPEGImages',
        ann_dir='SegmentationClass',
        split='ImageSets/Segmentation/val.txt',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(2048, 512),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True, min_size=512),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]),
    test=dict(
        type='ZeroPascalVOCDataset20',
        data_root='/mnt/fast/nobackup/scratch4weeks/ae01116/data/VOC2012',
        img_dir='JPEGImages',
        ann_dir='SegmentationClass',
        split='ImageSets/Segmentation/val.txt',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(2048, 512),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True, min_size=512),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]))
log_config = dict(
    interval=50, hooks=[dict(type='TextLoggerHook', by_epoch=False)])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
cudnn_benchmark = True
find_unused_parameters = True
optimizer = dict(
    type='AdamW',
    lr=2e-05,
    weight_decay=0.01,
    paramwise_cfg=dict(
        custom_keys=dict(
            backbone=dict(lr_mult=10.0),
            text_encoder=dict(lr_mult=0.0),
            norm=dict(decay_mult=0.0),
            ln=dict(decay_mult=0.0),
            head=dict(lr_mult=10.0))))
optimizer_config = dict()
lr_config = dict(
    policy='poly',
    power=0.9,
    min_lr=1e-06,
    by_epoch=False,
    warmup='linear',
    warmup_iters=1500,
    warmup_ratio=1e-06)
runner = dict(type='IterBasedRunner', max_iters=20000)
checkpoint_config = dict(by_epoch=False, interval=2000)
evaluation = dict(
    start=18000, interval=100, metric='mIoU', save_best='mIoU', rule='greater')
base_class = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]
novel_class = [15, 16, 17, 18, 19]
both_class = [
    0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19
]
num_classes = 15
pretrained = '/mnt/fast/nobackup/scratch4weeks/ae01116/weights/ViT-B-16.pt'
work_dir = '/mnt/fast/nobackup/scratch4weeks/ae01116/data/VOC2012'
gpu_ids = range(0, 1)

2024-06-28 09:45:06,357 - mmseg - INFO - Set random seed to 9, deterministic: True
2024-06-28 09:45:06,360 - mmseg - INFO - Loaded 1464 images
2024-06-28 09:45:06,369 - mmseg - INFO - Loaded 10582 images
2024-06-28 09:45:07,259 - mmseg - INFO - #Params: 171157248
/mnt/fast/nobackup/scratch4weeks/ae01116/zegenv/lib/python3.9/site-packages/torch/nn/functional.py:3631: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  warnings.warn(
/mnt/fast/nobackup/scratch4weeks/ae01116/zegenv/lib/python3.9/site-packages/torch/nn/functional.py:3631: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  warnings.warn(
/mnt/fast/nobackup/scratch4weeks/ae01116/zegenv/lib/python3.9/site-packages/torch/nn/functional.py:3631: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  warnings.warn(
/mnt/fast/nobackup/scratch4weeks/ae01116/zegenv/lib/python3.9/site-packages/torch/nn/functional.py:3631: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  warnings.warn(
2024-06-28 09:45:08,081 - mmseg - INFO - MultiScalesOutputZegCLIP(
  (backbone): VPTCLIPVisionTransformer(
    (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
    (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (transformer): Transformer(
      (resblocks): Sequential(
        (0): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
        (1): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (drop_path): DropPath(p=0.00909090880304575)
        )
        (2): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (drop_path): DropPath(p=0.0181818176060915)
        )
        (3): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (drop_path): DropPath(p=0.027272727340459824)
        )
        (4): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (drop_path): DropPath(p=0.036363635212183)
        )
        (5): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (drop_path): DropPath(p=0.045454543083906174)
        )
        (6): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (drop_path): DropPath(p=0.054545458406209946)
        )
        (7): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (drop_path): DropPath(p=0.06363636255264282)
        )
        (8): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (drop_path): DropPath(p=0.0727272778749466)
        )
        (9): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (drop_path): DropPath(p=0.08181818574666977)
        )
        (10): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (drop_path): DropPath(p=0.09090909361839294)
        )
        (11): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (drop_path): DropPath(p=0.10000000149011612)
        )
      )
    )
    (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (prompt_proj): Linear(in_features=768, out_features=768, bias=True)
    (prompt_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (prompt_dropout): Dropout(p=0.1, inplace=False)
  )
  (decode_head): ATMSingleHeadSeg(
    input_transform=None, ignore_index=255, align_corners=False
    (loss_decode): SegLossPlus(
      (criterion): SegPlusCriterion()
    )
    (dropout): Dropout2d(p=0.1, inplace=False)
    (input_proj_1): Identity()
    (proj_norm_1): Identity()
    (decoder_1): TPN_Decoder(
      (layers): ModuleList(
        (0): TPN_DecoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (linear1): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=2048, out_features=512, bias=True)
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
          (dropout3): Dropout(p=0.1, inplace=False)
          (multihead_attn): Attention(
            (q): Linear(in_features=512, out_features=512, bias=True)
            (k): Linear(in_features=512, out_features=512, bias=True)
            (v): Linear(in_features=512, out_features=512, bias=True)
            (attn_drop): Dropout(p=0.1, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): TPN_DecoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (linear1): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=2048, out_features=512, bias=True)
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
          (dropout3): Dropout(p=0.1, inplace=False)
          (multihead_attn): Attention(
            (q): Linear(in_features=512, out_features=512, bias=True)
            (k): Linear(in_features=512, out_features=512, bias=True)
            (v): Linear(in_features=512, out_features=512, bias=True)
            (attn_drop): Dropout(p=0.1, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
        )
        (2): TPN_DecoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (linear1): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=2048, out_features=512, bias=True)
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
          (dropout3): Dropout(p=0.1, inplace=False)
          (multihead_attn): Attention(
            (q): Linear(in_features=512, out_features=512, bias=True)
            (k): Linear(in_features=512, out_features=512, bias=True)
            (v): Linear(in_features=512, out_features=512, bias=True)
            (attn_drop): Dropout(p=0.1, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
    (q_proj): Linear(in_features=1024, out_features=512, bias=True)
  )
  init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
  (text_encoder): CLIPTextEncoder(
    (transformer): Transformer(
      (resblocks): Sequential(
        (0): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
        (1): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
        (2): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
        (3): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
        (4): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
        (5): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
        (6): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
        (7): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
        (8): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
        (9): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
        (10): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
        (11): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
    )
    (token_embedding): Embedding(49408, 512)
    (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (upsample2): Upsample(scale_factor=2.0, mode=bilinear)
  (upsample4): Upsample(scale_factor=4.0, mode=bilinear)
  (upsample8): Upsample(scale_factor=8.0, mode=bilinear)
  (conv_mult_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv_mult_2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv_mult_3): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
)
fatal: not a git repository (or any parent up to mount point /scratch/condor)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
fatal: not a git repository (or any parent up to mount point /scratch/condor)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
fatal: not a git repository (or any parent up to mount point /scratch/condor)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
fatal: not a git repository (or any parent up to mount point /scratch/condor)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2024-06-28 09:45:12,772 - mmseg - INFO - Loaded 1449 images
2024-06-28 09:45:12,965 - mmseg - INFO - Start running, host: ae01116@ae01116-173635.0-aisurrey15.surrey.ac.uk, work_dir: /mnt/fast/nobackup/scratch4weeks/ae01116/data/VOC2012
2024-06-28 09:45:12,965 - mmseg - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2024-06-28 09:45:12,966 - mmseg - INFO - workflow: [('train', 1)], max: 20000 iters
2024-06-28 09:45:12,966 - mmseg - INFO - Checkpoints will be saved to /mnt/fast/nobackup/scratch4weeks/ae01116/data/VOC2012 by HardDiskBackend.
/mnt/fast/nobackup/scratch4weeks/ae01116/zegenv/lib/python3.9/site-packages/torch/nn/functional.py:3631: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  warnings.warn(
/mnt/fast/nobackup/scratch4weeks/ae01116/zegenv/lib/python3.9/site-packages/torch/nn/functional.py:3631: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  warnings.warn(
/mnt/fast/nobackup/scratch4weeks/ae01116/zegenv/lib/python3.9/site-packages/torch/nn/functional.py:3631: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  warnings.warn(
/mnt/fast/nobackup/scratch4weeks/ae01116/zegenv/lib/python3.9/site-packages/torch/nn/functional.py:3631: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  warnings.warn(
2024-06-28 09:45:55,901 - mmseg - INFO - Iter [50/20000]	lr: 6.520e-07, eta: 2:36:40, time: 0.471, data_time: 0.010, memory: 8447, decode.loss_mask: 163.6232, decode.loss_dice: 0.7264, decode.acc_seg: 10.2465, loss: 164.3496
2024-06-28 09:46:18,847 - mmseg - INFO - Iter [100/20000]	lr: 1.314e-06, eta: 2:34:14, time: 0.459, data_time: 0.006, memory: 8450, decode.loss_mask: 144.4029, decode.loss_dice: 0.7394, decode.acc_seg: 10.4884, loss: 145.1423
2024-06-28 09:46:42,046 - mmseg - INFO - Iter [150/20000]	lr: 1.974e-06, eta: 2:33:44, time: 0.464, data_time: 0.005, memory: 8452, decode.loss_mask: 102.2567, decode.loss_dice: 0.7392, decode.acc_seg: 5.5167, loss: 102.9958
2024-06-28 09:47:05,027 - mmseg - INFO - Iter [200/20000]	lr: 2.631e-06, eta: 2:32:55, time: 0.460, data_time: 0.005, memory: 8452, decode.loss_mask: 30.3666, decode.loss_dice: 0.8092, decode.acc_seg: 8.5189, loss: 31.1758
2024-06-28 09:47:28,345 - mmseg - INFO - Iter [250/20000]	lr: 3.285e-06, eta: 2:32:44, time: 0.466, data_time: 0.006, memory: 8452, decode.loss_mask: 12.8447, decode.loss_dice: 0.8722, decode.acc_seg: 8.6768, loss: 13.7169
2024-06-28 09:47:51,433 - mmseg - INFO - Iter [300/20000]	lr: 3.936e-06, eta: 2:32:13, time: 0.462, data_time: 0.006, memory: 8452, decode.loss_mask: 12.5248, decode.loss_dice: 0.8603, decode.acc_seg: 12.2935, loss: 13.3850
2024-06-28 09:48:14,682 - mmseg - INFO - Iter [350/20000]	lr: 4.584e-06, eta: 2:31:54, time: 0.465, data_time: 0.006, memory: 8452, decode.loss_mask: 12.7053, decode.loss_dice: 0.8456, decode.acc_seg: 18.5818, loss: 13.5509
2024-06-28 09:48:37,763 - mmseg - INFO - Iter [400/20000]	lr: 5.229e-06, eta: 2:31:25, time: 0.462, data_time: 0.006, memory: 8452, decode.loss_mask: 10.7775, decode.loss_dice: 0.8400, decode.acc_seg: 25.5165, loss: 11.6175
2024-06-28 09:49:00,721 - mmseg - INFO - Iter [450/20000]	lr: 5.872e-06, eta: 2:30:52, time: 0.459, data_time: 0.006, memory: 8452, decode.loss_mask: 10.8489, decode.loss_dice: 0.8203, decode.acc_seg: 29.3968, loss: 11.6692
2024-06-28 09:49:23,726 - mmseg - INFO - Iter [500/20000]	lr: 6.511e-06, eta: 2:30:23, time: 0.460, data_time: 0.006, memory: 8452, decode.loss_mask: 9.5792, decode.loss_dice: 0.8188, decode.acc_seg: 30.5314, loss: 10.3979
2024-06-28 09:49:46,494 - mmseg - INFO - Iter [550/20000]	lr: 7.148e-06, eta: 2:29:47, time: 0.455, data_time: 0.006, memory: 8452, decode.loss_mask: 10.0645, decode.loss_dice: 0.8089, decode.acc_seg: 26.8985, loss: 10.8734
2024-06-28 09:50:09,527 - mmseg - INFO - Iter [600/20000]	lr: 7.782e-06, eta: 2:29:22, time: 0.461, data_time: 0.006, memory: 8452, decode.loss_mask: 10.1301, decode.loss_dice: 0.8028, decode.acc_seg: 27.2159, loss: 10.9329
2024-06-28 09:50:32,477 - mmseg - INFO - Iter [650/20000]	lr: 8.413e-06, eta: 2:28:54, time: 0.459, data_time: 0.006, memory: 8452, decode.loss_mask: 9.8356, decode.loss_dice: 0.8030, decode.acc_seg: 26.5688, loss: 10.6386
2024-06-28 09:50:55,523 - mmseg - INFO - Iter [700/20000]	lr: 9.041e-06, eta: 2:28:30, time: 0.461, data_time: 0.006, memory: 8452, decode.loss_mask: 9.2612, decode.loss_dice: 0.8020, decode.acc_seg: 30.3592, loss: 10.0632
2024-06-28 09:51:18,709 - mmseg - INFO - Iter [750/20000]	lr: 9.666e-06, eta: 2:28:10, time: 0.464, data_time: 0.006, memory: 8452, decode.loss_mask: 8.7823, decode.loss_dice: 0.7989, decode.acc_seg: 29.6226, loss: 9.5813
2024-06-28 09:51:43,891 - mmseg - INFO - Iter [800/20000]	lr: 1.029e-05, eta: 2:28:37, time: 0.504, data_time: 0.049, memory: 8452, decode.loss_mask: 8.6327, decode.loss_dice: 0.7918, decode.acc_seg: 45.8935, loss: 9.4244
2024-06-28 09:52:07,133 - mmseg - INFO - Iter [850/20000]	lr: 1.091e-05, eta: 2:28:14, time: 0.465, data_time: 0.006, memory: 8452, decode.loss_mask: 8.1702, decode.loss_dice: 0.7815, decode.acc_seg: 53.2034, loss: 8.9516
2024-06-28 09:52:30,372 - mmseg - INFO - Iter [900/20000]	lr: 1.152e-05, eta: 2:27:51, time: 0.465, data_time: 0.006, memory: 8452, decode.loss_mask: 7.5352, decode.loss_dice: 0.7724, decode.acc_seg: 58.6475, loss: 8.3076
2024-06-28 09:52:53,424 - mmseg - INFO - Iter [950/20000]	lr: 1.214e-05, eta: 2:27:24, time: 0.461, data_time: 0.006, memory: 8452, decode.loss_mask: 7.1462, decode.loss_dice: 0.7675, decode.acc_seg: 65.7953, loss: 7.9136
2024-06-28 09:53:16,559 - mmseg - INFO - Exp name: xxscales_output_vpt_seg_zero_vit-b_512x512_20k_12_10.py
2024-06-28 09:53:16,560 - mmseg - INFO - Iter [1000/20000]	lr: 1.275e-05, eta: 2:27:00, time: 0.463, data_time: 0.006, memory: 8452, decode.loss_mask: 5.7265, decode.loss_dice: 0.7489, decode.acc_seg: 79.5140, loss: 6.4754
2024-06-28 09:53:39,672 - mmseg - INFO - Iter [1050/20000]	lr: 1.336e-05, eta: 2:26:35, time: 0.462, data_time: 0.006, memory: 8452, decode.loss_mask: 5.1052, decode.loss_dice: 0.7662, decode.acc_seg: 77.1043, loss: 5.8714
2024-06-28 09:54:03,040 - mmseg - INFO - Iter [1100/20000]	lr: 1.396e-05, eta: 2:26:14, time: 0.467, data_time: 0.006, memory: 8452, decode.loss_mask: 5.4120, decode.loss_dice: 0.7421, decode.acc_seg: 81.7729, loss: 6.1541
2024-06-28 09:54:26,022 - mmseg - INFO - Iter [1150/20000]	lr: 1.457e-05, eta: 2:25:47, time: 0.460, data_time: 0.006, memory: 8452, decode.loss_mask: 5.2118, decode.loss_dice: 0.7361, decode.acc_seg: 84.0640, loss: 5.9479
2024-06-28 09:54:49,150 - mmseg - INFO - Iter [1200/20000]	lr: 1.516e-05, eta: 2:25:23, time: 0.463, data_time: 0.006, memory: 8452, decode.loss_mask: 4.5216, decode.loss_dice: 0.7280, decode.acc_seg: 85.9493, loss: 5.2495
2024-06-28 09:55:12,289 - mmseg - INFO - Iter [1250/20000]	lr: 1.576e-05, eta: 2:24:59, time: 0.463, data_time: 0.006, memory: 8452, decode.loss_mask: 4.1323, decode.loss_dice: 0.7179, decode.acc_seg: 86.3690, loss: 4.8502
2024-06-28 09:55:35,256 - mmseg - INFO - Iter [1300/20000]	lr: 1.635e-05, eta: 2:24:32, time: 0.459, data_time: 0.006, memory: 8452, decode.loss_mask: 4.3265, decode.loss_dice: 0.7124, decode.acc_seg: 84.7327, loss: 5.0389
2024-06-28 09:55:58,614 - mmseg - INFO - Iter [1350/20000]	lr: 1.695e-05, eta: 2:24:11, time: 0.467, data_time: 0.006, memory: 8452, decode.loss_mask: 4.3031, decode.loss_dice: 0.6953, decode.acc_seg: 84.6994, loss: 4.9984
2024-06-28 09:56:21,717 - mmseg - INFO - Iter [1400/20000]	lr: 1.753e-05, eta: 2:23:47, time: 0.462, data_time: 0.006, memory: 8452, decode.loss_mask: 4.0675, decode.loss_dice: 0.6635, decode.acc_seg: 87.3185, loss: 4.7310
2024-06-28 09:56:44,918 - mmseg - INFO - Iter [1450/20000]	lr: 1.812e-05, eta: 2:23:24, time: 0.464, data_time: 0.006, memory: 8452, decode.loss_mask: 3.7991, decode.loss_dice: 0.6333, decode.acc_seg: 86.1849, loss: 4.4324
2024-06-28 09:57:08,115 - mmseg - INFO - Iter [1500/20000]	lr: 1.870e-05, eta: 2:23:01, time: 0.464, data_time: 0.006, memory: 8452, decode.loss_mask: 3.8278, decode.loss_dice: 0.6293, decode.acc_seg: 86.2032, loss: 4.4571
2024-06-28 09:57:33,395 - mmseg - INFO - Iter [1550/20000]	lr: 1.867e-05, eta: 2:23:02, time: 0.506, data_time: 0.049, memory: 8452, decode.loss_mask: 3.2040, decode.loss_dice: 0.6394, decode.acc_seg: 87.4304, loss: 3.8434
2024-06-28 09:57:56,680 - mmseg - INFO - Iter [1600/20000]	lr: 1.863e-05, eta: 2:22:39, time: 0.466, data_time: 0.006, memory: 8452, decode.loss_mask: 3.2011, decode.loss_dice: 0.6381, decode.acc_seg: 87.5923, loss: 3.8392
2024-06-28 09:58:19,766 - mmseg - INFO - Iter [1650/20000]	lr: 1.858e-05, eta: 2:22:14, time: 0.462, data_time: 0.006, memory: 8452, decode.loss_mask: 3.0800, decode.loss_dice: 0.6236, decode.acc_seg: 85.9234, loss: 3.7036
2024-06-28 09:58:43,109 - mmseg - INFO - Iter [1700/20000]	lr: 1.854e-05, eta: 2:21:52, time: 0.467, data_time: 0.006, memory: 8452, decode.loss_mask: 3.3371, decode.loss_dice: 0.6122, decode.acc_seg: 88.8804, loss: 3.9493
2024-06-28 09:59:06,447 - mmseg - INFO - Iter [1750/20000]	lr: 1.850e-05, eta: 2:21:29, time: 0.467, data_time: 0.006, memory: 8452, decode.loss_mask: 3.3742, decode.loss_dice: 0.6233, decode.acc_seg: 87.8800, loss: 3.9975
2024-06-28 09:59:29,605 - mmseg - INFO - Iter [1800/20000]	lr: 1.845e-05, eta: 2:21:05, time: 0.463, data_time: 0.006, memory: 8452, decode.loss_mask: 3.2651, decode.loss_dice: 0.6080, decode.acc_seg: 87.1622, loss: 3.8731
2024-06-28 09:59:52,733 - mmseg - INFO - Iter [1850/20000]	lr: 1.841e-05, eta: 2:20:41, time: 0.463, data_time: 0.006, memory: 8452, decode.loss_mask: 3.1015, decode.loss_dice: 0.5969, decode.acc_seg: 89.1316, loss: 3.6983
2024-06-28 10:00:15,760 - mmseg - INFO - Iter [1900/20000]	lr: 1.837e-05, eta: 2:20:15, time: 0.461, data_time: 0.006, memory: 8452, decode.loss_mask: 3.1882, decode.loss_dice: 0.6105, decode.acc_seg: 87.3053, loss: 3.7986
2024-06-28 10:00:39,005 - mmseg - INFO - Iter [1950/20000]	lr: 1.833e-05, eta: 2:19:52, time: 0.465, data_time: 0.006, memory: 8452, decode.loss_mask: 2.9637, decode.loss_dice: 0.6013, decode.acc_seg: 89.5419, loss: 3.5651
2024-06-28 10:01:01,889 - mmseg - INFO - Saving checkpoint at 2000 iterations
2024-06-28 10:01:03,017 - mmseg - INFO - Exp name: xxscales_output_vpt_seg_zero_vit-b_512x512_20k_12_10.py
2024-06-28 10:01:03,017 - mmseg - INFO - Iter [2000/20000]	lr: 1.828e-05, eta: 2:19:35, time: 0.480, data_time: 0.006, memory: 8452, decode.loss_mask: 3.2611, decode.loss_dice: 0.6230, decode.acc_seg: 87.6221, loss: 3.8841
2024-06-28 10:01:26,029 - mmseg - INFO - Iter [2050/20000]	lr: 1.824e-05, eta: 2:19:10, time: 0.460, data_time: 0.006, memory: 8452, decode.loss_mask: 3.0102, decode.loss_dice: 0.5956, decode.acc_seg: 88.3023, loss: 3.6058
2024-06-28 10:01:49,232 - mmseg - INFO - Iter [2100/20000]	lr: 1.820e-05, eta: 2:18:46, time: 0.464, data_time: 0.006, memory: 8452, decode.loss_mask: 3.3720, decode.loss_dice: 0.6039, decode.acc_seg: 87.1420, loss: 3.9759
2024-06-28 10:02:12,173 - mmseg - INFO - Iter [2150/20000]	lr: 1.815e-05, eta: 2:18:20, time: 0.459, data_time: 0.006, memory: 8452, decode.loss_mask: 3.3118, decode.loss_dice: 0.5958, decode.acc_seg: 89.3510, loss: 3.9076
2024-06-28 10:02:35,329 - mmseg - INFO - Iter [2200/20000]	lr: 1.811e-05, eta: 2:17:56, time: 0.463, data_time: 0.006, memory: 8452, decode.loss_mask: 3.0514, decode.loss_dice: 0.5968, decode.acc_seg: 90.5822, loss: 3.6482
2024-06-28 10:02:58,350 - mmseg - INFO - Iter [2250/20000]	lr: 1.807e-05, eta: 2:17:31, time: 0.460, data_time: 0.007, memory: 8455, decode.loss_mask: 2.9527, decode.loss_dice: 0.6088, decode.acc_seg: 87.6989, loss: 3.5615
2024-06-28 10:03:23,611 - mmseg - INFO - Iter [2300/20000]	lr: 1.802e-05, eta: 2:17:24, time: 0.505, data_time: 0.049, memory: 8455, decode.loss_mask: 2.5920, decode.loss_dice: 0.5746, decode.acc_seg: 89.9963, loss: 3.1667
2024-06-28 10:03:46,685 - mmseg - INFO - Iter [2350/20000]	lr: 1.798e-05, eta: 2:16:59, time: 0.461, data_time: 0.006, memory: 8455, decode.loss_mask: 2.6749, decode.loss_dice: 0.5860, decode.acc_seg: 89.6572, loss: 3.2609
2024-06-28 10:04:09,684 - mmseg - INFO - Iter [2400/20000]	lr: 1.794e-05, eta: 2:16:33, time: 0.460, data_time: 0.006, memory: 8455, decode.loss_mask: 2.7651, decode.loss_dice: 0.5898, decode.acc_seg: 89.3863, loss: 3.3550
2024-06-28 10:04:32,925 - mmseg - INFO - Iter [2450/20000]	lr: 1.789e-05, eta: 2:16:10, time: 0.465, data_time: 0.006, memory: 8455, decode.loss_mask: 2.6538, decode.loss_dice: 0.5802, decode.acc_seg: 90.0619, loss: 3.2340
2024-06-28 10:04:55,884 - mmseg - INFO - Iter [2500/20000]	lr: 1.785e-05, eta: 2:15:44, time: 0.459, data_time: 0.006, memory: 8455, decode.loss_mask: 2.8178, decode.loss_dice: 0.5701, decode.acc_seg: 89.3910, loss: 3.3879
2024-06-28 10:05:19,130 - mmseg - INFO - Iter [2550/20000]	lr: 1.781e-05, eta: 2:15:21, time: 0.465, data_time: 0.006, memory: 8455, decode.loss_mask: 2.8365, decode.loss_dice: 0.5901, decode.acc_seg: 89.5569, loss: 3.4266
2024-06-28 10:05:42,164 - mmseg - INFO - Iter [2600/20000]	lr: 1.776e-05, eta: 2:14:56, time: 0.461, data_time: 0.006, memory: 8455, decode.loss_mask: 2.7460, decode.loss_dice: 0.5552, decode.acc_seg: 89.0350, loss: 3.3011
2024-06-28 10:06:05,151 - mmseg - INFO - Iter [2650/20000]	lr: 1.772e-05, eta: 2:14:31, time: 0.460, data_time: 0.006, memory: 8455, decode.loss_mask: 2.4758, decode.loss_dice: 0.5637, decode.acc_seg: 90.1689, loss: 3.0394
2024-06-28 10:06:28,239 - mmseg - INFO - Iter [2700/20000]	lr: 1.768e-05, eta: 2:14:06, time: 0.462, data_time: 0.006, memory: 8455, decode.loss_mask: 2.6277, decode.loss_dice: 0.5825, decode.acc_seg: 91.0896, loss: 3.2102
2024-06-28 10:06:51,184 - mmseg - INFO - Iter [2750/20000]	lr: 1.763e-05, eta: 2:13:41, time: 0.459, data_time: 0.006, memory: 8455, decode.loss_mask: 2.8266, decode.loss_dice: 0.5948, decode.acc_seg: 87.7124, loss: 3.4214
2024-06-28 10:07:14,432 - mmseg - INFO - Iter [2800/20000]	lr: 1.759e-05, eta: 2:13:18, time: 0.465, data_time: 0.006, memory: 8455, decode.loss_mask: 2.8286, decode.loss_dice: 0.5717, decode.acc_seg: 89.6364, loss: 3.4003
2024-06-28 10:07:37,488 - mmseg - INFO - Iter [2850/20000]	lr: 1.755e-05, eta: 2:12:54, time: 0.461, data_time: 0.006, memory: 8455, decode.loss_mask: 2.5629, decode.loss_dice: 0.5695, decode.acc_seg: 90.2109, loss: 3.1324
2024-06-28 10:08:00,676 - mmseg - INFO - Iter [2900/20000]	lr: 1.750e-05, eta: 2:12:30, time: 0.464, data_time: 0.006, memory: 8455, decode.loss_mask: 2.7982, decode.loss_dice: 0.5891, decode.acc_seg: 88.6557, loss: 3.3874
2024-06-28 10:08:23,916 - mmseg - INFO - Iter [2950/20000]	lr: 1.746e-05, eta: 2:12:07, time: 0.465, data_time: 0.006, memory: 8455, decode.loss_mask: 2.6865, decode.loss_dice: 0.5780, decode.acc_seg: 89.5231, loss: 3.2645
2024-06-28 10:08:47,067 - mmseg - INFO - Exp name: xxscales_output_vpt_seg_zero_vit-b_512x512_20k_12_10.py
2024-06-28 10:08:47,067 - mmseg - INFO - Iter [3000/20000]	lr: 1.742e-05, eta: 2:11:43, time: 0.463, data_time: 0.006, memory: 8455, decode.loss_mask: 2.9029, decode.loss_dice: 0.5894, decode.acc_seg: 88.8065, loss: 3.4923
2024-06-28 10:09:12,288 - mmseg - INFO - Iter [3050/20000]	lr: 1.737e-05, eta: 2:11:31, time: 0.504, data_time: 0.048, memory: 8455, decode.loss_mask: 2.5216, decode.loss_dice: 0.5678, decode.acc_seg: 91.1576, loss: 3.0894
2024-06-28 10:09:35,269 - mmseg - INFO - Iter [3100/20000]	lr: 1.733e-05, eta: 2:11:06, time: 0.460, data_time: 0.006, memory: 8455, decode.loss_mask: 2.7249, decode.loss_dice: 0.5641, decode.acc_seg: 89.6649, loss: 3.2890
2024-06-28 10:09:58,297 - mmseg - INFO - Iter [3150/20000]	lr: 1.729e-05, eta: 2:10:41, time: 0.461, data_time: 0.006, memory: 8455, decode.loss_mask: 2.5094, decode.loss_dice: 0.5650, decode.acc_seg: 91.3066, loss: 3.0744
2024-06-28 10:10:21,349 - mmseg - INFO - Iter [3200/20000]	lr: 1.724e-05, eta: 2:10:17, time: 0.461, data_time: 0.006, memory: 8455, decode.loss_mask: 2.9320, decode.loss_dice: 0.5708, decode.acc_seg: 88.0916, loss: 3.5028
2024-06-28 10:10:44,438 - mmseg - INFO - Iter [3250/20000]	lr: 1.720e-05, eta: 2:09:53, time: 0.462, data_time: 0.006, memory: 8455, decode.loss_mask: 2.8759, decode.loss_dice: 0.5443, decode.acc_seg: 89.8029, loss: 3.4202
2024-06-28 10:11:07,633 - mmseg - INFO - Iter [3300/20000]	lr: 1.715e-05, eta: 2:09:29, time: 0.464, data_time: 0.006, memory: 8455, decode.loss_mask: 2.4933, decode.loss_dice: 0.5578, decode.acc_seg: 91.1934, loss: 3.0511
2024-06-28 10:11:30,738 - mmseg - INFO - Iter [3350/20000]	lr: 1.711e-05, eta: 2:09:05, time: 0.462, data_time: 0.006, memory: 8455, decode.loss_mask: 2.7762, decode.loss_dice: 0.5646, decode.acc_seg: 89.7209, loss: 3.3409
2024-06-28 10:11:53,989 - mmseg - INFO - Iter [3400/20000]	lr: 1.707e-05, eta: 2:08:42, time: 0.465, data_time: 0.006, memory: 8455, decode.loss_mask: 2.3980, decode.loss_dice: 0.5659, decode.acc_seg: 90.4223, loss: 2.9639
2024-06-28 10:12:17,085 - mmseg - INFO - Iter [3450/20000]	lr: 1.702e-05, eta: 2:08:18, time: 0.462, data_time: 0.006, memory: 8455, decode.loss_mask: 2.7170, decode.loss_dice: 0.5696, decode.acc_seg: 90.1094, loss: 3.2866
2024-06-28 10:12:40,079 - mmseg - INFO - Iter [3500/20000]	lr: 1.698e-05, eta: 2:07:53, time: 0.460, data_time: 0.006, memory: 8455, decode.loss_mask: 2.6020, decode.loss_dice: 0.5701, decode.acc_seg: 90.3373, loss: 3.1721
2024-06-28 10:13:03,173 - mmseg - INFO - Iter [3550/20000]	lr: 1.694e-05, eta: 2:07:29, time: 0.462, data_time: 0.006, memory: 8455, decode.loss_mask: 2.5677, decode.loss_dice: 0.5690, decode.acc_seg: 89.8151, loss: 3.1366
2024-06-28 10:13:26,128 - mmseg - INFO - Iter [3600/20000]	lr: 1.689e-05, eta: 2:07:04, time: 0.459, data_time: 0.006, memory: 8455, decode.loss_mask: 2.3565, decode.loss_dice: 0.5708, decode.acc_seg: 91.3144, loss: 2.9273
2024-06-28 10:13:49,210 - mmseg - INFO - Iter [3650/20000]	lr: 1.685e-05, eta: 2:06:40, time: 0.462, data_time: 0.006, memory: 8455, decode.loss_mask: 2.4386, decode.loss_dice: 0.5445, decode.acc_seg: 90.5616, loss: 2.9831
2024-06-28 10:14:12,252 - mmseg - INFO - Iter [3700/20000]	lr: 1.681e-05, eta: 2:06:16, time: 0.461, data_time: 0.006, memory: 8455, decode.loss_mask: 2.6703, decode.loss_dice: 0.5770, decode.acc_seg: 89.3888, loss: 3.2473
2024-06-28 10:14:35,409 - mmseg - INFO - Iter [3750/20000]	lr: 1.676e-05, eta: 2:05:53, time: 0.463, data_time: 0.006, memory: 8455, decode.loss_mask: 2.3859, decode.loss_dice: 0.5639, decode.acc_seg: 89.7595, loss: 2.9499
2024-06-28 10:15:00,781 - mmseg - INFO - Iter [3800/20000]	lr: 1.672e-05, eta: 2:05:39, time: 0.507, data_time: 0.049, memory: 8455, decode.loss_mask: 2.7733, decode.loss_dice: 0.5465, decode.acc_seg: 90.4107, loss: 3.3199
2024-06-28 10:15:23,782 - mmseg - INFO - Iter [3850/20000]	lr: 1.667e-05, eta: 2:05:14, time: 0.460, data_time: 0.006, memory: 8455, decode.loss_mask: 2.3118, decode.loss_dice: 0.5686, decode.acc_seg: 91.2829, loss: 2.8805
2024-06-28 10:15:46,825 - mmseg - INFO - Iter [3900/20000]	lr: 1.663e-05, eta: 2:04:50, time: 0.461, data_time: 0.006, memory: 8455, decode.loss_mask: 2.7098, decode.loss_dice: 0.5757, decode.acc_seg: 89.1553, loss: 3.2856
2024-06-28 10:16:10,061 - mmseg - INFO - Iter [3950/20000]	lr: 1.659e-05, eta: 2:04:27, time: 0.465, data_time: 0.006, memory: 8455, decode.loss_mask: 2.3405, decode.loss_dice: 0.5362, decode.acc_seg: 92.8124, loss: 2.8767
2024-06-28 10:16:33,339 - mmseg - INFO - Saving checkpoint at 4000 iterations
2024-06-28 10:16:34,421 - mmseg - INFO - Exp name: xxscales_output_vpt_seg_zero_vit-b_512x512_20k_12_10.py
2024-06-28 10:16:34,421 - mmseg - INFO - Iter [4000/20000]	lr: 1.654e-05, eta: 2:04:08, time: 0.487, data_time: 0.006, memory: 8455, decode.loss_mask: 2.6077, decode.loss_dice: 0.5430, decode.acc_seg: 91.0022, loss: 3.1507
2024-06-28 10:16:57,450 - mmseg - INFO - Iter [4050/20000]	lr: 1.650e-05, eta: 2:03:43, time: 0.461, data_time: 0.006, memory: 8455, decode.loss_mask: 2.4038, decode.loss_dice: 0.5544, decode.acc_seg: 91.0200, loss: 2.9583
2024-06-28 10:17:20,657 - mmseg - INFO - Iter [4100/20000]	lr: 1.646e-05, eta: 2:03:20, time: 0.464, data_time: 0.006, memory: 8455, decode.loss_mask: 2.3751, decode.loss_dice: 0.5438, decode.acc_seg: 91.0903, loss: 2.9188
2024-06-28 10:17:43,643 - mmseg - INFO - Iter [4150/20000]	lr: 1.641e-05, eta: 2:02:56, time: 0.460, data_time: 0.006, memory: 8455, decode.loss_mask: 2.4700, decode.loss_dice: 0.5366, decode.acc_seg: 91.3102, loss: 3.0067
2024-06-28 10:18:06,476 - mmseg - INFO - Iter [4200/20000]	lr: 1.637e-05, eta: 2:02:31, time: 0.457, data_time: 0.006, memory: 8455, decode.loss_mask: 2.4557, decode.loss_dice: 0.5458, decode.acc_seg: 92.1126, loss: 3.0015
2024-06-28 10:18:29,644 - mmseg - INFO - Iter [4250/20000]	lr: 1.633e-05, eta: 2:02:07, time: 0.463, data_time: 0.006, memory: 8455, decode.loss_mask: 2.3281, decode.loss_dice: 0.5365, decode.acc_seg: 91.3303, loss: 2.8646
2024-06-28 10:18:52,703 - mmseg - INFO - Iter [4300/20000]	lr: 1.628e-05, eta: 2:01:43, time: 0.461, data_time: 0.006, memory: 8455, decode.loss_mask: 2.5679, decode.loss_dice: 0.5613, decode.acc_seg: 90.7275, loss: 3.1293
2024-06-28 10:19:15,823 - mmseg - INFO - Iter [4350/20000]	lr: 1.624e-05, eta: 2:01:19, time: 0.462, data_time: 0.006, memory: 8455, decode.loss_mask: 2.4199, decode.loss_dice: 0.5356, decode.acc_seg: 91.5562, loss: 2.9554
2024-06-28 10:19:39,002 - mmseg - INFO - Iter [4400/20000]	lr: 1.619e-05, eta: 2:00:56, time: 0.464, data_time: 0.006, memory: 8455, decode.loss_mask: 2.5390, decode.loss_dice: 0.5439, decode.acc_seg: 91.1268, loss: 3.0829
2024-06-28 10:20:02,183 - mmseg - INFO - Iter [4450/20000]	lr: 1.615e-05, eta: 2:00:32, time: 0.464, data_time: 0.006, memory: 8455, decode.loss_mask: 2.6810, decode.loss_dice: 0.5634, decode.acc_seg: 90.2145, loss: 3.2444
2024-06-28 10:20:25,283 - mmseg - INFO - Iter [4500/20000]	lr: 1.611e-05, eta: 2:00:08, time: 0.462, data_time: 0.006, memory: 8455, decode.loss_mask: 2.5250, decode.loss_dice: 0.5304, decode.acc_seg: 91.6863, loss: 3.0554
2024-06-28 10:20:50,549 - mmseg - INFO - Iter [4550/20000]	lr: 1.606e-05, eta: 1:59:52, time: 0.505, data_time: 0.049, memory: 8455, decode.loss_mask: 2.2134, decode.loss_dice: 0.5288, decode.acc_seg: 93.2234, loss: 2.7422
2024-06-28 10:21:13,754 - mmseg - INFO - Iter [4600/20000]	lr: 1.602e-05, eta: 1:59:28, time: 0.464, data_time: 0.006, memory: 8455, decode.loss_mask: 2.3033, decode.loss_dice: 0.5421, decode.acc_seg: 93.1323, loss: 2.8454
2024-06-28 10:21:36,912 - mmseg - INFO - Iter [4650/20000]	lr: 1.597e-05, eta: 1:59:05, time: 0.463, data_time: 0.006, memory: 8455, decode.loss_mask: 2.4302, decode.loss_dice: 0.5509, decode.acc_seg: 93.0258, loss: 2.9811
2024-06-28 10:21:59,969 - mmseg - INFO - Iter [4700/20000]	lr: 1.593e-05, eta: 1:58:41, time: 0.461, data_time: 0.006, memory: 8455, decode.loss_mask: 2.4496, decode.loss_dice: 0.5287, decode.acc_seg: 93.7706, loss: 2.9783
2024-06-28 10:22:23,074 - mmseg - INFO - Iter [4750/20000]	lr: 1.589e-05, eta: 1:58:17, time: 0.462, data_time: 0.006, memory: 8455, decode.loss_mask: 2.3036, decode.loss_dice: 0.5348, decode.acc_seg: 92.8302, loss: 2.8384
2024-06-28 10:22:46,073 - mmseg - INFO - Iter [4800/20000]	lr: 1.584e-05, eta: 1:57:53, time: 0.460, data_time: 0.006, memory: 8455, decode.loss_mask: 2.4402, decode.loss_dice: 0.5376, decode.acc_seg: 91.7237, loss: 2.9778
2024-06-28 10:23:09,355 - mmseg - INFO - Iter [4850/20000]	lr: 1.580e-05, eta: 1:57:30, time: 0.466, data_time: 0.006, memory: 8455, decode.loss_mask: 2.4336, decode.loss_dice: 0.5110, decode.acc_seg: 94.2245, loss: 2.9446
2024-06-28 10:23:32,646 - mmseg - INFO - Iter [4900/20000]	lr: 1.575e-05, eta: 1:57:06, time: 0.466, data_time: 0.006, memory: 8455, decode.loss_mask: 2.2515, decode.loss_dice: 0.5260, decode.acc_seg: 93.2532, loss: 2.7775
2024-06-28 10:23:55,829 - mmseg - INFO - Iter [4950/20000]	lr: 1.571e-05, eta: 1:56:43, time: 0.464, data_time: 0.006, memory: 8455, decode.loss_mask: 2.4064, decode.loss_dice: 0.5336, decode.acc_seg: 92.7351, loss: 2.9400
2024-06-28 10:24:18,901 - mmseg - INFO - Exp name: xxscales_output_vpt_seg_zero_vit-b_512x512_20k_12_10.py
2024-06-28 10:24:18,902 - mmseg - INFO - Iter [5000/20000]	lr: 1.567e-05, eta: 1:56:19, time: 0.461, data_time: 0.006, memory: 8455, decode.loss_mask: 2.4193, decode.loss_dice: 0.5399, decode.acc_seg: 92.4047, loss: 2.9592
2024-06-28 10:24:41,940 - mmseg - INFO - Iter [5050/20000]	lr: 1.562e-05, eta: 1:55:55, time: 0.461, data_time: 0.006, memory: 8455, decode.loss_mask: 2.1957, decode.loss_dice: 0.5363, decode.acc_seg: 93.7161, loss: 2.7320
2024-06-28 10:25:05,007 - mmseg - INFO - Iter [5100/20000]	lr: 1.558e-05, eta: 1:55:31, time: 0.461, data_time: 0.006, memory: 8455, decode.loss_mask: 2.0672, decode.loss_dice: 0.5213, decode.acc_seg: 94.2985, loss: 2.5885
2024-06-28 10:25:27,968 - mmseg - INFO - Iter [5150/20000]	lr: 1.553e-05, eta: 1:55:07, time: 0.459, data_time: 0.006, memory: 8455, decode.loss_mask: 2.2189, decode.loss_dice: 0.5272, decode.acc_seg: 93.4472, loss: 2.7460
2024-06-28 10:25:51,136 - mmseg - INFO - Iter [5200/20000]	lr: 1.549e-05, eta: 1:54:44, time: 0.463, data_time: 0.006, memory: 8455, decode.loss_mask: 2.2343, decode.loss_dice: 0.5308, decode.acc_seg: 93.4294, loss: 2.7651
2024-06-28 10:26:14,256 - mmseg - INFO - Iter [5250/20000]	lr: 1.545e-05, eta: 1:54:20, time: 0.462, data_time: 0.006, memory: 8455, decode.loss_mask: 2.1417, decode.loss_dice: 0.5239, decode.acc_seg: 93.6382, loss: 2.6656
2024-06-28 10:26:39,549 - mmseg - INFO - Iter [5300/20000]	lr: 1.540e-05, eta: 1:54:02, time: 0.506, data_time: 0.048, memory: 8455, decode.loss_mask: 2.2578, decode.loss_dice: 0.5033, decode.acc_seg: 94.9814, loss: 2.7611
2024-06-28 10:27:02,684 - mmseg - INFO - Iter [5350/20000]	lr: 1.536e-05, eta: 1:53:39, time: 0.463, data_time: 0.006, memory: 8455, decode.loss_mask: 2.2616, decode.loss_dice: 0.5149, decode.acc_seg: 93.9953, loss: 2.7765
2024-06-28 10:27:25,621 - mmseg - INFO - Iter [5400/20000]	lr: 1.531e-05, eta: 1:53:15, time: 0.459, data_time: 0.006, memory: 8455, decode.loss_mask: 2.2412, decode.loss_dice: 0.5332, decode.acc_seg: 93.7248, loss: 2.7744
2024-06-28 10:27:48,643 - mmseg - INFO - Iter [5450/20000]	lr: 1.527e-05, eta: 1:52:51, time: 0.460, data_time: 0.006, memory: 8455, decode.loss_mask: 2.2162, decode.loss_dice: 0.5302, decode.acc_seg: 93.6673, loss: 2.7465
2024-06-28 10:28:11,779 - mmseg - INFO - Iter [5500/20000]	lr: 1.523e-05, eta: 1:52:27, time: 0.463, data_time: 0.006, memory: 8455, decode.loss_mask: 2.1841, decode.loss_dice: 0.5110, decode.acc_seg: 93.3174, loss: 2.6951
2024-06-28 10:28:34,856 - mmseg - INFO - Iter [5550/20000]	lr: 1.518e-05, eta: 1:52:03, time: 0.462, data_time: 0.006, memory: 8455, decode.loss_mask: 2.1870, decode.loss_dice: 0.5203, decode.acc_seg: 93.3591, loss: 2.7073
2024-06-28 10:28:57,937 - mmseg - INFO - Iter [5600/20000]	lr: 1.514e-05, eta: 1:51:40, time: 0.462, data_time: 0.006, memory: 8455, decode.loss_mask: 2.2343, decode.loss_dice: 0.5211, decode.acc_seg: 92.7502, loss: 2.7554
2024-06-28 10:29:21,014 - mmseg - INFO - Iter [5650/20000]	lr: 1.509e-05, eta: 1:51:16, time: 0.462, data_time: 0.006, memory: 8455, decode.loss_mask: 2.1185, decode.loss_dice: 0.5141, decode.acc_seg: 94.0436, loss: 2.6326
2024-06-28 10:29:44,280 - mmseg - INFO - Iter [5700/20000]	lr: 1.505e-05, eta: 1:50:53, time: 0.465, data_time: 0.006, memory: 8455, decode.loss_mask: 2.2453, decode.loss_dice: 0.5152, decode.acc_seg: 93.4258, loss: 2.7605
2024-06-28 10:30:07,495 - mmseg - INFO - Iter [5750/20000]	lr: 1.501e-05, eta: 1:50:29, time: 0.464, data_time: 0.006, memory: 8455, decode.loss_mask: 2.0816, decode.loss_dice: 0.5272, decode.acc_seg: 94.2080, loss: 2.6088
2024-06-28 10:30:30,689 - mmseg - INFO - Iter [5800/20000]	lr: 1.496e-05, eta: 1:50:06, time: 0.464, data_time: 0.006, memory: 8455, decode.loss_mask: 2.1858, decode.loss_dice: 0.5332, decode.acc_seg: 93.3680, loss: 2.7190
2024-06-28 10:30:53,734 - mmseg - INFO - Iter [5850/20000]	lr: 1.492e-05, eta: 1:49:42, time: 0.461, data_time: 0.006, memory: 8455, decode.loss_mask: 2.0823, decode.loss_dice: 0.4899, decode.acc_seg: 93.5892, loss: 2.5722
2024-06-28 10:31:16,822 - mmseg - INFO - Iter [5900/20000]	lr: 1.487e-05, eta: 1:49:18, time: 0.462, data_time: 0.006, memory: 8455, decode.loss_mask: 2.2292, decode.loss_dice: 0.5021, decode.acc_seg: 94.3099, loss: 2.7313
2024-06-28 10:31:40,023 - mmseg - INFO - Iter [5950/20000]	lr: 1.483e-05, eta: 1:48:55, time: 0.464, data_time: 0.006, memory: 8455, decode.loss_mask: 2.1835, decode.loss_dice: 0.5109, decode.acc_seg: 94.3556, loss: 2.6944
2024-06-28 10:32:02,926 - mmseg - INFO - Saving checkpoint at 6000 iterations
2024-06-28 10:32:04,001 - mmseg - INFO - Exp name: xxscales_output_vpt_seg_zero_vit-b_512x512_20k_12_10.py
2024-06-28 10:32:04,001 - mmseg - INFO - Iter [6000/20000]	lr: 1.478e-05, eta: 1:48:33, time: 0.480, data_time: 0.006, memory: 8455, decode.loss_mask: 1.9378, decode.loss_dice: 0.4903, decode.acc_seg: 93.8584, loss: 2.4281
2024-06-28 10:32:29,201 - mmseg - INFO - Iter [6050/20000]	lr: 1.474e-05, eta: 1:48:15, time: 0.504, data_time: 0.049, memory: 8455, decode.loss_mask: 2.2613, decode.loss_dice: 0.5345, decode.acc_seg: 92.5231, loss: 2.7958
2024-06-28 10:32:52,359 - mmseg - INFO - Iter [6100/20000]	lr: 1.470e-05, eta: 1:47:51, time: 0.463, data_time: 0.006, memory: 8455, decode.loss_mask: 1.9911, decode.loss_dice: 0.4964, decode.acc_seg: 93.6912, loss: 2.4875
2024-06-28 10:33:15,480 - mmseg - INFO - Iter [6150/20000]	lr: 1.465e-05, eta: 1:47:27, time: 0.462, data_time: 0.006, memory: 8455, decode.loss_mask: 1.9634, decode.loss_dice: 0.5033, decode.acc_seg: 94.7341, loss: 2.4667
2024-06-28 10:33:38,725 - mmseg - INFO - Iter [6200/20000]	lr: 1.461e-05, eta: 1:47:04, time: 0.465, data_time: 0.006, memory: 8455, decode.loss_mask: 2.1819, decode.loss_dice: 0.5118, decode.acc_seg: 93.8697, loss: 2.6937
2024-06-28 10:34:01,619 - mmseg - INFO - Iter [6250/20000]	lr: 1.456e-05, eta: 1:46:40, time: 0.458, data_time: 0.006, memory: 8455, decode.loss_mask: 2.2094, decode.loss_dice: 0.5143, decode.acc_seg: 94.2939, loss: 2.7237
2024-06-28 10:34:24,699 - mmseg - INFO - Iter [6300/20000]	lr: 1.452e-05, eta: 1:46:16, time: 0.462, data_time: 0.006, memory: 8455, decode.loss_mask: 2.1522, decode.loss_dice: 0.4981, decode.acc_seg: 93.7631, loss: 2.6503
2024-06-28 10:34:47,789 - mmseg - INFO - Iter [6350/20000]	lr: 1.447e-05, eta: 1:45:52, time: 0.462, data_time: 0.006, memory: 8455, decode.loss_mask: 2.1426, decode.loss_dice: 0.5032, decode.acc_seg: 94.3610, loss: 2.6458
2024-06-28 10:35:10,916 - mmseg - INFO - Iter [6400/20000]	lr: 1.443e-05, eta: 1:45:29, time: 0.463, data_time: 0.006, memory: 8455, decode.loss_mask: 2.1327, decode.loss_dice: 0.5087, decode.acc_seg: 94.1698, loss: 2.6414
2024-06-28 10:35:34,161 - mmseg - INFO - Iter [6450/20000]	lr: 1.438e-05, eta: 1:45:06, time: 0.465, data_time: 0.006, memory: 8455, decode.loss_mask: 2.0276, decode.loss_dice: 0.5172, decode.acc_seg: 93.9426, loss: 2.5448
2024-06-28 10:35:57,242 - mmseg - INFO - Iter [6500/20000]	lr: 1.434e-05, eta: 1:44:42, time: 0.462, data_time: 0.006, memory: 8459, decode.loss_mask: 2.3120, decode.loss_dice: 0.5203, decode.acc_seg: 93.5062, loss: 2.8323
2024-06-28 10:36:20,355 - mmseg - INFO - Iter [6550/20000]	lr: 1.430e-05, eta: 1:44:18, time: 0.462, data_time: 0.006, memory: 8459, decode.loss_mask: 2.1668, decode.loss_dice: 0.4950, decode.acc_seg: 93.9003, loss: 2.6618
2024-06-28 10:36:43,523 - mmseg - INFO - Iter [6600/20000]	lr: 1.425e-05, eta: 1:43:55, time: 0.463, data_time: 0.006, memory: 8459, decode.loss_mask: 2.1717, decode.loss_dice: 0.5070, decode.acc_seg: 92.7193, loss: 2.6787
2024-06-28 10:37:06,489 - mmseg - INFO - Iter [6650/20000]	lr: 1.421e-05, eta: 1:43:31, time: 0.459, data_time: 0.006, memory: 8459, decode.loss_mask: 2.1642, decode.loss_dice: 0.4952, decode.acc_seg: 94.2986, loss: 2.6594
2024-06-28 10:37:29,644 - mmseg - INFO - Iter [6700/20000]	lr: 1.416e-05, eta: 1:43:08, time: 0.463, data_time: 0.006, memory: 8459, decode.loss_mask: 1.9984, decode.loss_dice: 0.5025, decode.acc_seg: 94.0564, loss: 2.5009
2024-06-28 10:37:52,758 - mmseg - INFO - Iter [6750/20000]	lr: 1.412e-05, eta: 1:42:44, time: 0.462, data_time: 0.006, memory: 8459, decode.loss_mask: 2.4118, decode.loss_dice: 0.5103, decode.acc_seg: 93.1019, loss: 2.9221
2024-06-28 10:38:18,024 - mmseg - INFO - Iter [6800/20000]	lr: 1.407e-05, eta: 1:42:25, time: 0.505, data_time: 0.049, memory: 8459, decode.loss_mask: 2.0767, decode.loss_dice: 0.5029, decode.acc_seg: 95.1876, loss: 2.5795
2024-06-28 10:38:41,282 - mmseg - INFO - Iter [6850/20000]	lr: 1.403e-05, eta: 1:42:01, time: 0.465, data_time: 0.006, memory: 8459, decode.loss_mask: 2.0783, decode.loss_dice: 0.4814, decode.acc_seg: 95.3987, loss: 2.5597
2024-06-28 10:39:04,275 - mmseg - INFO - Iter [6900/20000]	lr: 1.398e-05, eta: 1:41:37, time: 0.460, data_time: 0.007, memory: 8459, decode.loss_mask: 2.0761, decode.loss_dice: 0.5030, decode.acc_seg: 94.0077, loss: 2.5791
2024-06-28 10:39:27,378 - mmseg - INFO - Iter [6950/20000]	lr: 1.394e-05, eta: 1:41:14, time: 0.462, data_time: 0.006, memory: 8459, decode.loss_mask: 2.1364, decode.loss_dice: 0.5220, decode.acc_seg: 93.1907, loss: 2.6584
2024-06-28 10:39:50,565 - mmseg - INFO - Exp name: xxscales_output_vpt_seg_zero_vit-b_512x512_20k_12_10.py
2024-06-28 10:39:50,566 - mmseg - INFO - Iter [7000/20000]	lr: 1.389e-05, eta: 1:40:50, time: 0.464, data_time: 0.006, memory: 8459, decode.loss_mask: 1.9977, decode.loss_dice: 0.5043, decode.acc_seg: 93.8995, loss: 2.5020
2024-06-28 10:40:13,767 - mmseg - INFO - Iter [7050/20000]	lr: 1.385e-05, eta: 1:40:27, time: 0.464, data_time: 0.006, memory: 8459, decode.loss_mask: 1.9969, decode.loss_dice: 0.5218, decode.acc_seg: 92.4302, loss: 2.5187
2024-06-28 10:40:36,985 - mmseg - INFO - Iter [7100/20000]	lr: 1.381e-05, eta: 1:40:04, time: 0.464, data_time: 0.006, memory: 8459, decode.loss_mask: 1.9280, decode.loss_dice: 0.5022, decode.acc_seg: 94.2007, loss: 2.4302
2024-06-28 10:41:00,123 - mmseg - INFO - Iter [7150/20000]	lr: 1.376e-05, eta: 1:39:40, time: 0.463, data_time: 0.006, memory: 8459, decode.loss_mask: 2.2296, decode.loss_dice: 0.5004, decode.acc_seg: 93.7230, loss: 2.7300
2024-06-28 10:41:23,171 - mmseg - INFO - Iter [7200/20000]	lr: 1.372e-05, eta: 1:39:16, time: 0.461, data_time: 0.006, memory: 8459, decode.loss_mask: 1.9935, decode.loss_dice: 0.5044, decode.acc_seg: 94.6787, loss: 2.4979
2024-06-28 10:41:46,282 - mmseg - INFO - Iter [7250/20000]	lr: 1.367e-05, eta: 1:38:53, time: 0.462, data_time: 0.006, memory: 8459, decode.loss_mask: 2.2119, decode.loss_dice: 0.5131, decode.acc_seg: 93.9850, loss: 2.7250
2024-06-28 10:42:09,367 - mmseg - INFO - Iter [7300/20000]	lr: 1.363e-05, eta: 1:38:29, time: 0.462, data_time: 0.006, memory: 8459, decode.loss_mask: 1.9394, decode.loss_dice: 0.4865, decode.acc_seg: 94.8600, loss: 2.4259
2024-06-28 10:42:32,569 - mmseg - INFO - Iter [7350/20000]	lr: 1.358e-05, eta: 1:38:06, time: 0.464, data_time: 0.006, memory: 8459, decode.loss_mask: 2.0570, decode.loss_dice: 0.4953, decode.acc_seg: 94.3606, loss: 2.5523
2024-06-28 10:42:55,434 - mmseg - INFO - Iter [7400/20000]	lr: 1.354e-05, eta: 1:37:42, time: 0.457, data_time: 0.006, memory: 8459, decode.loss_mask: 2.0737, decode.loss_dice: 0.4994, decode.acc_seg: 93.4624, loss: 2.5731
2024-06-28 10:43:18,497 - mmseg - INFO - Iter [7450/20000]	lr: 1.349e-05, eta: 1:37:18, time: 0.461, data_time: 0.006, memory: 8459, decode.loss_mask: 2.0231, decode.loss_dice: 0.4827, decode.acc_seg: 94.4478, loss: 2.5058
2024-06-28 10:43:41,695 - mmseg - INFO - Iter [7500/20000]	lr: 1.345e-05, eta: 1:36:55, time: 0.464, data_time: 0.006, memory: 8459, decode.loss_mask: 1.8071, decode.loss_dice: 0.4978, decode.acc_seg: 95.3879, loss: 2.3048
2024-06-28 10:44:06,815 - mmseg - INFO - Iter [7550/20000]	lr: 1.340e-05, eta: 1:36:35, time: 0.502, data_time: 0.049, memory: 8459, decode.loss_mask: 2.0119, decode.loss_dice: 0.4676, decode.acc_seg: 94.6636, loss: 2.4795
2024-06-28 10:44:29,933 - mmseg - INFO - Iter [7600/20000]	lr: 1.336e-05, eta: 1:36:11, time: 0.462, data_time: 0.006, memory: 8459, decode.loss_mask: 2.1129, decode.loss_dice: 0.4994, decode.acc_seg: 93.0812, loss: 2.6123
2024-06-28 10:44:52,860 - mmseg - INFO - Iter [7650/20000]	lr: 1.331e-05, eta: 1:35:47, time: 0.459, data_time: 0.006, memory: 8459, decode.loss_mask: 1.9220, decode.loss_dice: 0.4778, decode.acc_seg: 95.0764, loss: 2.3997
2024-06-28 10:45:15,941 - mmseg - INFO - Iter [7700/20000]	lr: 1.327e-05, eta: 1:35:24, time: 0.462, data_time: 0.006, memory: 8459, decode.loss_mask: 2.2069, decode.loss_dice: 0.5009, decode.acc_seg: 94.2976, loss: 2.7078
2024-06-28 10:45:38,949 - mmseg - INFO - Iter [7750/20000]	lr: 1.322e-05, eta: 1:35:00, time: 0.460, data_time: 0.006, memory: 8459, decode.loss_mask: 2.1467, decode.loss_dice: 0.4992, decode.acc_seg: 92.5990, loss: 2.6459
2024-06-28 10:46:02,109 - mmseg - INFO - Iter [7800/20000]	lr: 1.318e-05, eta: 1:34:37, time: 0.463, data_time: 0.006, memory: 8459, decode.loss_mask: 1.9309, decode.loss_dice: 0.5063, decode.acc_seg: 94.0986, loss: 2.4373
2024-06-28 10:46:25,309 - mmseg - INFO - Iter [7850/20000]	lr: 1.313e-05, eta: 1:34:13, time: 0.464, data_time: 0.006, memory: 8459, decode.loss_mask: 1.9024, decode.loss_dice: 0.4936, decode.acc_seg: 93.7300, loss: 2.3960
2024-06-28 10:46:48,288 - mmseg - INFO - Iter [7900/20000]	lr: 1.309e-05, eta: 1:33:50, time: 0.460, data_time: 0.006, memory: 8459, decode.loss_mask: 1.8767, decode.loss_dice: 0.4869, decode.acc_seg: 94.6261, loss: 2.3635
2024-06-28 10:47:11,513 - mmseg - INFO - Iter [7950/20000]	lr: 1.304e-05, eta: 1:33:26, time: 0.465, data_time: 0.006, memory: 8459, decode.loss_mask: 2.1066, decode.loss_dice: 0.4843, decode.acc_seg: 94.9198, loss: 2.5908
2024-06-28 10:47:34,603 - mmseg - INFO - Saving checkpoint at 8000 iterations
2024-06-28 10:47:35,661 - mmseg - INFO - Exp name: xxscales_output_vpt_seg_zero_vit-b_512x512_20k_12_10.py
2024-06-28 10:47:35,661 - mmseg - INFO - Iter [8000/20000]	lr: 1.300e-05, eta: 1:33:04, time: 0.483, data_time: 0.006, memory: 8459, decode.loss_mask: 1.9487, decode.loss_dice: 0.4928, decode.acc_seg: 95.3148, loss: 2.4415
2024-06-28 10:47:58,542 - mmseg - INFO - Iter [8050/20000]	lr: 1.295e-05, eta: 1:32:41, time: 0.458, data_time: 0.006, memory: 8459, decode.loss_mask: 2.0248, decode.loss_dice: 0.4808, decode.acc_seg: 94.6750, loss: 2.5056
2024-06-28 10:48:21,699 - mmseg - INFO - Iter [8100/20000]	lr: 1.291e-05, eta: 1:32:17, time: 0.463, data_time: 0.006, memory: 8459, decode.loss_mask: 2.0014, decode.loss_dice: 0.5061, decode.acc_seg: 93.0900, loss: 2.5075
2024-06-28 10:48:44,898 - mmseg - INFO - Iter [8150/20000]	lr: 1.286e-05, eta: 1:31:54, time: 0.464, data_time: 0.006, memory: 8459, decode.loss_mask: 2.2548, decode.loss_dice: 0.4816, decode.acc_seg: 93.7079, loss: 2.7364
2024-06-28 10:49:07,901 - mmseg - INFO - Iter [8200/20000]	lr: 1.282e-05, eta: 1:31:30, time: 0.460, data_time: 0.006, memory: 8459, decode.loss_mask: 1.9144, decode.loss_dice: 0.4953, decode.acc_seg: 94.8317, loss: 2.4097
2024-06-28 10:49:31,215 - mmseg - INFO - Iter [8250/20000]	lr: 1.277e-05, eta: 1:31:07, time: 0.466, data_time: 0.006, memory: 8459, decode.loss_mask: 2.1311, decode.loss_dice: 0.4767, decode.acc_seg: 93.7888, loss: 2.6077
2024-06-28 10:49:56,364 - mmseg - INFO - Iter [8300/20000]	lr: 1.273e-05, eta: 1:30:46, time: 0.503, data_time: 0.050, memory: 8459, decode.loss_mask: 1.9777, decode.loss_dice: 0.4725, decode.acc_seg: 94.6372, loss: 2.4501
2024-06-28 10:50:19,386 - mmseg - INFO - Iter [8350/20000]	lr: 1.268e-05, eta: 1:30:23, time: 0.460, data_time: 0.006, memory: 8459, decode.loss_mask: 2.0755, decode.loss_dice: 0.4864, decode.acc_seg: 93.9542, loss: 2.5618
2024-06-28 10:50:42,552 - mmseg - INFO - Iter [8400/20000]	lr: 1.264e-05, eta: 1:29:59, time: 0.463, data_time: 0.006, memory: 8459, decode.loss_mask: 1.9364, decode.loss_dice: 0.4925, decode.acc_seg: 94.4166, loss: 2.4289
2024-06-28 10:51:05,566 - mmseg - INFO - Iter [8450/20000]	lr: 1.259e-05, eta: 1:29:36, time: 0.460, data_time: 0.006, memory: 8459, decode.loss_mask: 1.9565, decode.loss_dice: 0.4797, decode.acc_seg: 93.5624, loss: 2.4362
2024-06-28 10:51:28,728 - mmseg - INFO - Iter [8500/20000]	lr: 1.255e-05, eta: 1:29:12, time: 0.463, data_time: 0.006, memory: 8459, decode.loss_mask: 2.0249, decode.loss_dice: 0.4763, decode.acc_seg: 94.7592, loss: 2.5012
2024-06-28 10:51:51,773 - mmseg - INFO - Iter [8550/20000]	lr: 1.250e-05, eta: 1:28:49, time: 0.461, data_time: 0.006, memory: 8459, decode.loss_mask: 1.7238, decode.loss_dice: 0.4791, decode.acc_seg: 95.6326, loss: 2.2028
2024-06-28 10:52:14,960 - mmseg - INFO - Iter [8600/20000]	lr: 1.246e-05, eta: 1:28:25, time: 0.464, data_time: 0.006, memory: 8459, decode.loss_mask: 1.9276, decode.loss_dice: 0.4911, decode.acc_seg: 94.5210, loss: 2.4187
2024-06-28 10:52:38,037 - mmseg - INFO - Iter [8650/20000]	lr: 1.241e-05, eta: 1:28:02, time: 0.462, data_time: 0.006, memory: 8459, decode.loss_mask: 2.2439, decode.loss_dice: 0.5050, decode.acc_seg: 90.9644, loss: 2.7489
2024-06-28 10:53:01,059 - mmseg - INFO - Iter [8700/20000]	lr: 1.237e-05, eta: 1:27:38, time: 0.460, data_time: 0.006, memory: 8459, decode.loss_mask: 2.0356, decode.loss_dice: 0.4774, decode.acc_seg: 94.6979, loss: 2.5129
2024-06-28 10:53:24,165 - mmseg - INFO - Iter [8750/20000]	lr: 1.232e-05, eta: 1:27:15, time: 0.462, data_time: 0.006, memory: 8459, decode.loss_mask: 2.0188, decode.loss_dice: 0.5083, decode.acc_seg: 93.9955, loss: 2.5271
2024-06-28 10:53:47,332 - mmseg - INFO - Iter [8800/20000]	lr: 1.228e-05, eta: 1:26:51, time: 0.463, data_time: 0.006, memory: 8459, decode.loss_mask: 1.9920, decode.loss_dice: 0.4781, decode.acc_seg: 94.3535, loss: 2.4701
2024-06-28 10:54:10,380 - mmseg - INFO - Iter [8850/20000]	lr: 1.223e-05, eta: 1:26:28, time: 0.461, data_time: 0.006, memory: 8459, decode.loss_mask: 1.8944, decode.loss_dice: 0.4834, decode.acc_seg: 94.3323, loss: 2.3778
2024-06-28 10:54:33,427 - mmseg - INFO - Iter [8900/20000]	lr: 1.219e-05, eta: 1:26:04, time: 0.461, data_time: 0.006, memory: 8459, decode.loss_mask: 2.1443, decode.loss_dice: 0.4896, decode.acc_seg: 94.2395, loss: 2.6339
2024-06-28 10:54:56,493 - mmseg - INFO - Iter [8950/20000]	lr: 1.214e-05, eta: 1:25:41, time: 0.461, data_time: 0.006, memory: 8459, decode.loss_mask: 2.1055, decode.loss_dice: 0.4908, decode.acc_seg: 92.6549, loss: 2.5962
2024-06-28 10:55:19,631 - mmseg - INFO - Exp name: xxscales_output_vpt_seg_zero_vit-b_512x512_20k_12_10.py
2024-06-28 10:55:19,632 - mmseg - INFO - Iter [9000/20000]	lr: 1.209e-05, eta: 1:25:17, time: 0.463, data_time: 0.006, memory: 8459, decode.loss_mask: 1.8875, decode.loss_dice: 0.4828, decode.acc_seg: 94.9624, loss: 2.3703
2024-06-28 10:55:44,853 - mmseg - INFO - Iter [9050/20000]	lr: 1.205e-05, eta: 1:24:56, time: 0.504, data_time: 0.049, memory: 8459, decode.loss_mask: 1.8659, decode.loss_dice: 0.5023, decode.acc_seg: 94.5279, loss: 2.3682
2024-06-28 10:56:08,144 - mmseg - INFO - Iter [9100/20000]	lr: 1.200e-05, eta: 1:24:33, time: 0.466, data_time: 0.006, memory: 8459, decode.loss_mask: 1.8136, decode.loss_dice: 0.4795, decode.acc_seg: 94.6952, loss: 2.2931
2024-06-28 10:56:31,222 - mmseg - INFO - Iter [9150/20000]	lr: 1.196e-05, eta: 1:24:10, time: 0.462, data_time: 0.006, memory: 8459, decode.loss_mask: 1.8035, decode.loss_dice: 0.4820, decode.acc_seg: 95.2294, loss: 2.2855
2024-06-28 10:56:54,340 - mmseg - INFO - Iter [9200/20000]	lr: 1.191e-05, eta: 1:23:46, time: 0.462, data_time: 0.006, memory: 8459, decode.loss_mask: 2.0819, decode.loss_dice: 0.4843, decode.acc_seg: 94.0441, loss: 2.5662
2024-06-28 10:57:17,528 - mmseg - INFO - Iter [9250/20000]	lr: 1.187e-05, eta: 1:23:23, time: 0.464, data_time: 0.006, memory: 8459, decode.loss_mask: 1.9133, decode.loss_dice: 0.4782, decode.acc_seg: 95.2331, loss: 2.3914
2024-06-28 10:57:40,569 - mmseg - INFO - Iter [9300/20000]	lr: 1.182e-05, eta: 1:22:59, time: 0.461, data_time: 0.006, memory: 8459, decode.loss_mask: 2.0176, decode.loss_dice: 0.4613, decode.acc_seg: 94.5185, loss: 2.4789
2024-06-28 10:58:03,548 - mmseg - INFO - Iter [9350/20000]	lr: 1.178e-05, eta: 1:22:36, time: 0.460, data_time: 0.006, memory: 8459, decode.loss_mask: 2.1314, decode.loss_dice: 0.4928, decode.acc_seg: 93.9430, loss: 2.6242
2024-06-28 10:58:26,557 - mmseg - INFO - Iter [9400/20000]	lr: 1.173e-05, eta: 1:22:12, time: 0.460, data_time: 0.006, memory: 8459, decode.loss_mask: 1.7955, decode.loss_dice: 0.4770, decode.acc_seg: 95.0252, loss: 2.2726
2024-06-28 10:58:49,630 - mmseg - INFO - Iter [9450/20000]	lr: 1.169e-05, eta: 1:21:49, time: 0.461, data_time: 0.006, memory: 8459, decode.loss_mask: 1.9300, decode.loss_dice: 0.4778, decode.acc_seg: 94.9280, loss: 2.4078
2024-06-28 10:59:12,673 - mmseg - INFO - Iter [9500/20000]	lr: 1.164e-05, eta: 1:21:25, time: 0.461, data_time: 0.006, memory: 8459, decode.loss_mask: 1.9282, decode.loss_dice: 0.4645, decode.acc_seg: 95.2349, loss: 2.3927
2024-06-28 10:59:35,770 - mmseg - INFO - Iter [9550/20000]	lr: 1.159e-05, eta: 1:21:02, time: 0.462, data_time: 0.006, memory: 8459, decode.loss_mask: 1.9039, decode.loss_dice: 0.4727, decode.acc_seg: 94.5202, loss: 2.3766
2024-06-28 10:59:58,848 - mmseg - INFO - Iter [9600/20000]	lr: 1.155e-05, eta: 1:20:38, time: 0.462, data_time: 0.006, memory: 8459, decode.loss_mask: 1.7590, decode.loss_dice: 0.4705, decode.acc_seg: 95.3971, loss: 2.2295
2024-06-28 11:00:21,824 - mmseg - INFO - Iter [9650/20000]	lr: 1.150e-05, eta: 1:20:15, time: 0.460, data_time: 0.006, memory: 8459, decode.loss_mask: 1.9753, decode.loss_dice: 0.4927, decode.acc_seg: 94.1798, loss: 2.4680
2024-06-28 11:00:44,890 - mmseg - INFO - Iter [9700/20000]	lr: 1.146e-05, eta: 1:19:51, time: 0.461, data_time: 0.006, memory: 8459, decode.loss_mask: 1.7964, decode.loss_dice: 0.4791, decode.acc_seg: 95.3130, loss: 2.2754
2024-06-28 11:01:08,063 - mmseg - INFO - Iter [9750/20000]	lr: 1.141e-05, eta: 1:19:28, time: 0.463, data_time: 0.006, memory: 8459, decode.loss_mask: 1.9843, decode.loss_dice: 0.4830, decode.acc_seg: 94.5573, loss: 2.4673
2024-06-28 11:01:33,222 - mmseg - INFO - Iter [9800/20000]	lr: 1.137e-05, eta: 1:19:06, time: 0.503, data_time: 0.049, memory: 8459, decode.loss_mask: 2.0678, decode.loss_dice: 0.4584, decode.acc_seg: 94.5098, loss: 2.5262
2024-06-28 11:01:56,336 - mmseg - INFO - Iter [9850/20000]	lr: 1.132e-05, eta: 1:18:43, time: 0.462, data_time: 0.006, memory: 8459, decode.loss_mask: 1.7173, decode.loss_dice: 0.4816, decode.acc_seg: 95.4743, loss: 2.1989
2024-06-28 11:02:19,418 - mmseg - INFO - Iter [9900/20000]	lr: 1.127e-05, eta: 1:18:20, time: 0.462, data_time: 0.006, memory: 8459, decode.loss_mask: 2.2493, decode.loss_dice: 0.4877, decode.acc_seg: 94.4267, loss: 2.7369
2024-06-28 11:02:42,557 - mmseg - INFO - Iter [9950/20000]	lr: 1.123e-05, eta: 1:17:56, time: 0.463, data_time: 0.006, memory: 8459, decode.loss_mask: 2.1792, decode.loss_dice: 0.4841, decode.acc_seg: 93.7383, loss: 2.6632
2024-06-28 11:03:05,495 - mmseg - INFO - Saving checkpoint at 10000 iterations
2024-06-28 11:03:06,564 - mmseg - INFO - Exp name: xxscales_output_vpt_seg_zero_vit-b_512x512_20k_12_10.py
2024-06-28 11:03:06,564 - mmseg - INFO - Iter [10000/20000]	lr: 1.118e-05, eta: 1:17:34, time: 0.480, data_time: 0.006, memory: 8459, decode.loss_mask: 1.9688, decode.loss_dice: 0.4755, decode.acc_seg: 95.2923, loss: 2.4443
2024-06-28 11:03:29,548 - mmseg - INFO - Iter [10050/20000]	lr: 1.114e-05, eta: 1:17:10, time: 0.460, data_time: 0.006, memory: 8459, decode.loss_mask: 1.9253, decode.loss_dice: 0.4759, decode.acc_seg: 94.6887, loss: 2.4011
2024-06-28 11:03:52,585 - mmseg - INFO - Iter [10100/20000]	lr: 1.109e-05, eta: 1:16:47, time: 0.461, data_time: 0.006, memory: 8459, decode.loss_mask: 1.9750, decode.loss_dice: 0.4882, decode.acc_seg: 94.5658, loss: 2.4633
2024-06-28 11:04:15,558 - mmseg - INFO - Iter [10150/20000]	lr: 1.105e-05, eta: 1:16:23, time: 0.459, data_time: 0.006, memory: 8459, decode.loss_mask: 1.9212, decode.loss_dice: 0.4678, decode.acc_seg: 94.2759, loss: 2.3890
2024-06-28 11:04:38,717 - mmseg - INFO - Iter [10200/20000]	lr: 1.100e-05, eta: 1:16:00, time: 0.463, data_time: 0.006, memory: 8459, decode.loss_mask: 2.0841, decode.loss_dice: 0.4823, decode.acc_seg: 94.8572, loss: 2.5665
2024-06-28 11:05:01,679 - mmseg - INFO - Iter [10250/20000]	lr: 1.095e-05, eta: 1:15:36, time: 0.459, data_time: 0.006, memory: 8459, decode.loss_mask: 1.8631, decode.loss_dice: 0.4752, decode.acc_seg: 94.8612, loss: 2.3383
2024-06-28 11:05:24,858 - mmseg - INFO - Iter [10300/20000]	lr: 1.091e-05, eta: 1:15:13, time: 0.464, data_time: 0.006, memory: 8459, decode.loss_mask: 1.8897, decode.loss_dice: 0.4790, decode.acc_seg: 95.9666, loss: 2.3687
2024-06-28 11:05:48,014 - mmseg - INFO - Iter [10350/20000]	lr: 1.086e-05, eta: 1:14:49, time: 0.463, data_time: 0.006, memory: 8459, decode.loss_mask: 2.0009, decode.loss_dice: 0.4887, decode.acc_seg: 94.1972, loss: 2.4896
2024-06-28 11:06:11,099 - mmseg - INFO - Iter [10400/20000]	lr: 1.082e-05, eta: 1:14:26, time: 0.462, data_time: 0.006, memory: 8459, decode.loss_mask: 2.0822, decode.loss_dice: 0.4698, decode.acc_seg: 94.0522, loss: 2.5520
2024-06-28 11:06:34,253 - mmseg - INFO - Iter [10450/20000]	lr: 1.077e-05, eta: 1:14:03, time: 0.463, data_time: 0.006, memory: 8459, decode.loss_mask: 2.0374, decode.loss_dice: 0.4863, decode.acc_seg: 93.7971, loss: 2.5237
2024-06-28 11:06:57,256 - mmseg - INFO - Iter [10500/20000]	lr: 1.072e-05, eta: 1:13:39, time: 0.460, data_time: 0.006, memory: 8459, decode.loss_mask: 1.8528, decode.loss_dice: 0.4625, decode.acc_seg: 95.4110, loss: 2.3153
2024-06-28 11:07:22,555 - mmseg - INFO - Iter [10550/20000]	lr: 1.068e-05, eta: 1:13:18, time: 0.506, data_time: 0.050, memory: 8459, decode.loss_mask: 1.7928, decode.loss_dice: 0.4653, decode.acc_seg: 94.9502, loss: 2.2581
2024-06-28 11:07:45,573 - mmseg - INFO - Iter [10600/20000]	lr: 1.063e-05, eta: 1:12:54, time: 0.460, data_time: 0.006, memory: 8459, decode.loss_mask: 1.9991, decode.loss_dice: 0.4586, decode.acc_seg: 94.0197, loss: 2.4577
2024-06-28 11:08:08,720 - mmseg - INFO - Iter [10650/20000]	lr: 1.059e-05, eta: 1:12:31, time: 0.463, data_time: 0.006, memory: 8459, decode.loss_mask: 1.8698, decode.loss_dice: 0.4728, decode.acc_seg: 94.9401, loss: 2.3426
2024-06-28 11:08:31,993 - mmseg - INFO - Iter [10700/20000]	lr: 1.054e-05, eta: 1:12:08, time: 0.465, data_time: 0.006, memory: 8459, decode.loss_mask: 1.8370, decode.loss_dice: 0.4827, decode.acc_seg: 95.2237, loss: 2.3197
2024-06-28 11:08:55,082 - mmseg - INFO - Iter [10750/20000]	lr: 1.049e-05, eta: 1:11:44, time: 0.462, data_time: 0.006, memory: 8459, decode.loss_mask: 1.8171, decode.loss_dice: 0.4594, decode.acc_seg: 95.2093, loss: 2.2765
2024-06-28 11:09:18,215 - mmseg - INFO - Iter [10800/20000]	lr: 1.045e-05, eta: 1:11:21, time: 0.463, data_time: 0.006, memory: 8459, decode.loss_mask: 1.7560, decode.loss_dice: 0.4536, decode.acc_seg: 96.3217, loss: 2.2096
2024-06-28 11:09:41,217 - mmseg - INFO - Iter [10850/20000]	lr: 1.040e-05, eta: 1:10:57, time: 0.460, data_time: 0.006, memory: 8459, decode.loss_mask: 1.9991, decode.loss_dice: 0.4815, decode.acc_seg: 93.7230, loss: 2.4806
2024-06-28 11:10:04,435 - mmseg - INFO - Iter [10900/20000]	lr: 1.035e-05, eta: 1:10:34, time: 0.464, data_time: 0.006, memory: 8459, decode.loss_mask: 1.9112, decode.loss_dice: 0.4678, decode.acc_seg: 95.3765, loss: 2.3790
2024-06-28 11:10:27,474 - mmseg - INFO - Iter [10950/20000]	lr: 1.031e-05, eta: 1:10:11, time: 0.461, data_time: 0.006, memory: 8459, decode.loss_mask: 1.8580, decode.loss_dice: 0.4797, decode.acc_seg: 95.1174, loss: 2.3376
2024-06-28 11:10:50,537 - mmseg - INFO - Exp name: xxscales_output_vpt_seg_zero_vit-b_512x512_20k_12_10.py
2024-06-28 11:10:50,539 - mmseg - INFO - Iter [11000/20000]	lr: 1.026e-05, eta: 1:09:47, time: 0.461, data_time: 0.006, memory: 8459, decode.loss_mask: 1.7997, decode.loss_dice: 0.4644, decode.acc_seg: 94.2336, loss: 2.2641
2024-06-28 11:11:13,644 - mmseg - INFO - Iter [11050/20000]	lr: 1.022e-05, eta: 1:09:24, time: 0.462, data_time: 0.006, memory: 8459, decode.loss_mask: 1.9074, decode.loss_dice: 0.4715, decode.acc_seg: 95.3396, loss: 2.3788
2024-06-28 11:11:36,596 - mmseg - INFO - Iter [11100/20000]	lr: 1.017e-05, eta: 1:09:00, time: 0.459, data_time: 0.006, memory: 8459, decode.loss_mask: 1.9301, decode.loss_dice: 0.4817, decode.acc_seg: 94.3057, loss: 2.4118
2024-06-28 11:11:59,763 - mmseg - INFO - Iter [11150/20000]	lr: 1.012e-05, eta: 1:08:37, time: 0.463, data_time: 0.006, memory: 8459, decode.loss_mask: 2.0584, decode.loss_dice: 0.4748, decode.acc_seg: 94.9088, loss: 2.5332
2024-06-28 11:12:22,814 - mmseg - INFO - Iter [11200/20000]	lr: 1.008e-05, eta: 1:08:13, time: 0.461, data_time: 0.006, memory: 8459, decode.loss_mask: 1.7870, decode.loss_dice: 0.4723, decode.acc_seg: 95.0423, loss: 2.2593
2024-06-28 11:12:45,882 - mmseg - INFO - Iter [11250/20000]	lr: 1.003e-05, eta: 1:07:50, time: 0.461, data_time: 0.006, memory: 8459, decode.loss_mask: 1.7330, decode.loss_dice: 0.4624, decode.acc_seg: 95.0747, loss: 2.1954
2024-06-28 11:13:11,230 - mmseg - INFO - Iter [11300/20000]	lr: 9.983e-06, eta: 1:07:28, time: 0.507, data_time: 0.049, memory: 8459, decode.loss_mask: 1.8654, decode.loss_dice: 0.4748, decode.acc_seg: 94.5746, loss: 2.3402
2024-06-28 11:13:34,323 - mmseg - INFO - Iter [11350/20000]	lr: 9.937e-06, eta: 1:07:05, time: 0.462, data_time: 0.006, memory: 8459, decode.loss_mask: 1.7895, decode.loss_dice: 0.4720, decode.acc_seg: 95.5373, loss: 2.2615
2024-06-28 11:13:57,553 - mmseg - INFO - Iter [11400/20000]	lr: 9.890e-06, eta: 1:06:42, time: 0.465, data_time: 0.006, memory: 8459, decode.loss_mask: 1.7223, decode.loss_dice: 0.4564, decode.acc_seg: 96.1872, loss: 2.1787
2024-06-28 11:14:20,560 - mmseg - INFO - Iter [11450/20000]	lr: 9.844e-06, eta: 1:06:18, time: 0.460, data_time: 0.006, memory: 8459, decode.loss_mask: 1.7866, decode.loss_dice: 0.4650, decode.acc_seg: 95.5056, loss: 2.2516
2024-06-28 11:14:43,616 - mmseg - INFO - Iter [11500/20000]	lr: 9.797e-06, eta: 1:05:55, time: 0.461, data_time: 0.006, memory: 8459, decode.loss_mask: 1.8779, decode.loss_dice: 0.4717, decode.acc_seg: 94.6038, loss: 2.3496
2024-06-28 11:15:06,796 - mmseg - INFO - Iter [11550/20000]	lr: 9.751e-06, eta: 1:05:31, time: 0.464, data_time: 0.006, memory: 8459, decode.loss_mask: 1.8855, decode.loss_dice: 0.4676, decode.acc_seg: 95.6413, loss: 2.3531
2024-06-28 11:15:29,904 - mmseg - INFO - Iter [11600/20000]	lr: 9.704e-06, eta: 1:05:08, time: 0.462, data_time: 0.006, memory: 8459, decode.loss_mask: 1.8983, decode.loss_dice: 0.4639, decode.acc_seg: 95.2230, loss: 2.3622
2024-06-28 11:15:53,116 - mmseg - INFO - Iter [11650/20000]	lr: 9.657e-06, eta: 1:04:45, time: 0.464, data_time: 0.006, memory: 8459, decode.loss_mask: 1.7183, decode.loss_dice: 0.4709, decode.acc_seg: 95.1146, loss: 2.1892
2024-06-28 11:16:16,181 - mmseg - INFO - Iter [11700/20000]	lr: 9.611e-06, eta: 1:04:21, time: 0.461, data_time: 0.006, memory: 8459, decode.loss_mask: 1.8931, decode.loss_dice: 0.4747, decode.acc_seg: 95.1638, loss: 2.3678
2024-06-28 11:16:39,258 - mmseg - INFO - Iter [11750/20000]	lr: 9.564e-06, eta: 1:03:58, time: 0.462, data_time: 0.006, memory: 8459, decode.loss_mask: 2.0104, decode.loss_dice: 0.4695, decode.acc_seg: 95.2307, loss: 2.4799
2024-06-28 11:17:02,252 - mmseg - INFO - Iter [11800/20000]	lr: 9.517e-06, eta: 1:03:34, time: 0.460, data_time: 0.006, memory: 8459, decode.loss_mask: 1.8043, decode.loss_dice: 0.4803, decode.acc_seg: 95.7033, loss: 2.2845
2024-06-28 11:17:25,252 - mmseg - INFO - Iter [11850/20000]	lr: 9.471e-06, eta: 1:03:11, time: 0.460, data_time: 0.006, memory: 8459, decode.loss_mask: 1.7494, decode.loss_dice: 0.4621, decode.acc_seg: 95.0126, loss: 2.2115
2024-06-28 11:17:48,188 - mmseg - INFO - Iter [11900/20000]	lr: 9.424e-06, eta: 1:02:48, time: 0.459, data_time: 0.006, memory: 8459, decode.loss_mask: 2.0406, decode.loss_dice: 0.4638, decode.acc_seg: 95.8535, loss: 2.5044
2024-06-28 11:18:11,227 - mmseg - INFO - Iter [11950/20000]	lr: 9.377e-06, eta: 1:02:24, time: 0.461, data_time: 0.006, memory: 8459, decode.loss_mask: 1.8130, decode.loss_dice: 0.4733, decode.acc_seg: 95.5252, loss: 2.2863
2024-06-28 11:18:34,440 - mmseg - INFO - Saving checkpoint at 12000 iterations
2024-06-28 11:18:35,519 - mmseg - INFO - Exp name: xxscales_output_vpt_seg_zero_vit-b_512x512_20k_12_10.py
2024-06-28 11:18:35,519 - mmseg - INFO - Iter [12000/20000]	lr: 9.330e-06, eta: 1:02:02, time: 0.486, data_time: 0.006, memory: 8459, decode.loss_mask: 1.8277, decode.loss_dice: 0.4640, decode.acc_seg: 94.7600, loss: 2.2917
2024-06-28 11:19:00,766 - mmseg - INFO - Iter [12050/20000]	lr: 9.283e-06, eta: 1:01:40, time: 0.505, data_time: 0.049, memory: 8459, decode.loss_mask: 1.7880, decode.loss_dice: 0.4606, decode.acc_seg: 94.9282, loss: 2.2486
2024-06-28 11:19:23,806 - mmseg - INFO - Iter [12100/20000]	lr: 9.236e-06, eta: 1:01:16, time: 0.461, data_time: 0.006, memory: 8459, decode.loss_mask: 1.8857, decode.loss_dice: 0.4617, decode.acc_seg: 96.8949, loss: 2.3474
2024-06-28 11:19:46,920 - mmseg - INFO - Iter [12150/20000]	lr: 9.190e-06, eta: 1:00:53, time: 0.462, data_time: 0.006, memory: 8459, decode.loss_mask: 2.1435, decode.loss_dice: 0.4871, decode.acc_seg: 93.9507, loss: 2.6306
2024-06-28 11:20:10,084 - mmseg - INFO - Iter [12200/20000]	lr: 9.143e-06, eta: 1:00:29, time: 0.463, data_time: 0.006, memory: 8459, decode.loss_mask: 2.0206, decode.loss_dice: 0.4755, decode.acc_seg: 95.2560, loss: 2.4961
2024-06-28 11:20:33,176 - mmseg - INFO - Iter [12250/20000]	lr: 9.096e-06, eta: 1:00:06, time: 0.462, data_time: 0.006, memory: 8459, decode.loss_mask: 1.8693, decode.loss_dice: 0.4676, decode.acc_seg: 94.5608, loss: 2.3369
2024-06-28 11:20:56,035 - mmseg - INFO - Iter [12300/20000]	lr: 9.049e-06, eta: 0:59:43, time: 0.457, data_time: 0.006, memory: 8459, decode.loss_mask: 1.6503, decode.loss_dice: 0.4600, decode.acc_seg: 96.4145, loss: 2.1104
2024-06-28 11:21:19,012 - mmseg - INFO - Iter [12350/20000]	lr: 9.002e-06, eta: 0:59:19, time: 0.460, data_time: 0.006, memory: 8459, decode.loss_mask: 1.9716, decode.loss_dice: 0.4704, decode.acc_seg: 95.5887, loss: 2.4420
2024-06-28 11:21:42,155 - mmseg - INFO - Iter [12400/20000]	lr: 8.954e-06, eta: 0:58:56, time: 0.463, data_time: 0.006, memory: 8459, decode.loss_mask: 1.7572, decode.loss_dice: 0.4703, decode.acc_seg: 95.9210, loss: 2.2275
2024-06-28 11:22:05,193 - mmseg - INFO - Iter [12450/20000]	lr: 8.907e-06, eta: 0:58:32, time: 0.461, data_time: 0.006, memory: 8459, decode.loss_mask: 1.7257, decode.loss_dice: 0.4539, decode.acc_seg: 96.0679, loss: 2.1795
2024-06-28 11:22:28,295 - mmseg - INFO - Iter [12500/20000]	lr: 8.860e-06, eta: 0:58:09, time: 0.462, data_time: 0.006, memory: 8459, decode.loss_mask: 1.9055, decode.loss_dice: 0.4528, decode.acc_seg: 95.9122, loss: 2.3582
2024-06-28 11:22:51,397 - mmseg - INFO - Iter [12550/20000]	lr: 8.813e-06, eta: 0:57:46, time: 0.462, data_time: 0.006, memory: 8459, decode.loss_mask: 1.8043, decode.loss_dice: 0.4519, decode.acc_seg: 95.7618, loss: 2.2561
2024-06-28 11:23:14,491 - mmseg - INFO - Iter [12600/20000]	lr: 8.766e-06, eta: 0:57:22, time: 0.462, data_time: 0.006, memory: 8459, decode.loss_mask: 1.8354, decode.loss_dice: 0.4666, decode.acc_seg: 94.9400, loss: 2.3019
2024-06-28 11:23:37,553 - mmseg - INFO - Iter [12650/20000]	lr: 8.719e-06, eta: 0:56:59, time: 0.461, data_time: 0.006, memory: 8459, decode.loss_mask: 1.9232, decode.loss_dice: 0.4852, decode.acc_seg: 94.9762, loss: 2.4084
2024-06-28 11:24:00,597 - mmseg - INFO - Iter [12700/20000]	lr: 8.671e-06, eta: 0:56:36, time: 0.461, data_time: 0.006, memory: 8459, decode.loss_mask: 1.9304, decode.loss_dice: 0.4513, decode.acc_seg: 94.3080, loss: 2.3817
2024-06-28 11:24:23,670 - mmseg - INFO - Iter [12750/20000]	lr: 8.624e-06, eta: 0:56:12, time: 0.461, data_time: 0.006, memory: 8459, decode.loss_mask: 1.6476, decode.loss_dice: 0.4537, decode.acc_seg: 96.1661, loss: 2.1013
2024-06-28 11:24:46,664 - mmseg - INFO - Iter [12800/20000]	lr: 8.577e-06, eta: 0:55:49, time: 0.460, data_time: 0.006, memory: 8459, decode.loss_mask: 1.6977, decode.loss_dice: 0.4630, decode.acc_seg: 95.6658, loss: 2.1606
2024-06-28 11:25:11,936 - mmseg - INFO - Iter [12850/20000]	lr: 8.529e-06, eta: 0:55:27, time: 0.505, data_time: 0.049, memory: 8459, decode.loss_mask: 1.7718, decode.loss_dice: 0.4650, decode.acc_seg: 95.1297, loss: 2.2368
2024-06-28 11:25:35,095 - mmseg - INFO - Iter [12900/20000]	lr: 8.482e-06, eta: 0:55:03, time: 0.463, data_time: 0.006, memory: 8459, decode.loss_mask: 1.6076, decode.loss_dice: 0.4567, decode.acc_seg: 95.6506, loss: 2.0643
2024-06-28 11:25:58,228 - mmseg - INFO - Iter [12950/20000]	lr: 8.435e-06, eta: 0:54:40, time: 0.463, data_time: 0.006, memory: 8459, decode.loss_mask: 1.5907, decode.loss_dice: 0.4437, decode.acc_seg: 96.8652, loss: 2.0343
2024-06-28 11:26:21,375 - mmseg - INFO - Exp name: xxscales_output_vpt_seg_zero_vit-b_512x512_20k_12_10.py
2024-06-28 11:26:21,376 - mmseg - INFO - Iter [13000/20000]	lr: 8.387e-06, eta: 0:54:17, time: 0.463, data_time: 0.006, memory: 8459, decode.loss_mask: 1.8269, decode.loss_dice: 0.4468, decode.acc_seg: 96.1937, loss: 2.2736
2024-06-28 11:26:44,404 - mmseg - INFO - Iter [13050/20000]	lr: 8.340e-06, eta: 0:53:53, time: 0.461, data_time: 0.006, memory: 8459, decode.loss_mask: 1.8991, decode.loss_dice: 0.4517, decode.acc_seg: 94.5160, loss: 2.3508
2024-06-28 11:27:07,619 - mmseg - INFO - Iter [13100/20000]	lr: 8.292e-06, eta: 0:53:30, time: 0.464, data_time: 0.006, memory: 8459, decode.loss_mask: 1.9653, decode.loss_dice: 0.4706, decode.acc_seg: 94.4773, loss: 2.4358
2024-06-28 11:27:30,690 - mmseg - INFO - Iter [13150/20000]	lr: 8.244e-06, eta: 0:53:07, time: 0.461, data_time: 0.006, memory: 8459, decode.loss_mask: 1.8949, decode.loss_dice: 0.4672, decode.acc_seg: 95.2453, loss: 2.3621
2024-06-28 11:27:53,789 - mmseg - INFO - Iter [13200/20000]	lr: 8.197e-06, eta: 0:52:43, time: 0.462, data_time: 0.006, memory: 8459, decode.loss_mask: 1.7986, decode.loss_dice: 0.4553, decode.acc_seg: 95.7209, loss: 2.2540
2024-06-28 11:28:16,976 - mmseg - INFO - Iter [13250/20000]	lr: 8.149e-06, eta: 0:52:20, time: 0.464, data_time: 0.006, memory: 8459, decode.loss_mask: 1.9171, decode.loss_dice: 0.4666, decode.acc_seg: 95.2458, loss: 2.3837
2024-06-28 11:28:40,041 - mmseg - INFO - Iter [13300/20000]	lr: 8.102e-06, eta: 0:51:57, time: 0.461, data_time: 0.006, memory: 8459, decode.loss_mask: 1.8783, decode.loss_dice: 0.4760, decode.acc_seg: 95.4081, loss: 2.3543
2024-06-28 11:29:03,306 - mmseg - INFO - Iter [13350/20000]	lr: 8.054e-06, eta: 0:51:33, time: 0.465, data_time: 0.006, memory: 8459, decode.loss_mask: 1.7874, decode.loss_dice: 0.4500, decode.acc_seg: 95.8227, loss: 2.2374
2024-06-28 11:29:26,249 - mmseg - INFO - Iter [13400/20000]	lr: 8.006e-06, eta: 0:51:10, time: 0.459, data_time: 0.006, memory: 8459, decode.loss_mask: 2.0188, decode.loss_dice: 0.4569, decode.acc_seg: 94.4281, loss: 2.4757
2024-06-28 11:29:49,440 - mmseg - INFO - Iter [13450/20000]	lr: 7.958e-06, eta: 0:50:47, time: 0.464, data_time: 0.006, memory: 8459, decode.loss_mask: 1.7592, decode.loss_dice: 0.4727, decode.acc_seg: 95.4655, loss: 2.2319
2024-06-28 11:30:12,674 - mmseg - INFO - Iter [13500/20000]	lr: 7.910e-06, eta: 0:50:23, time: 0.465, data_time: 0.006, memory: 8459, decode.loss_mask: 1.8096, decode.loss_dice: 0.4520, decode.acc_seg: 95.2504, loss: 2.2616
2024-06-28 11:30:35,640 - mmseg - INFO - Iter [13550/20000]	lr: 7.863e-06, eta: 0:50:00, time: 0.459, data_time: 0.006, memory: 8459, decode.loss_mask: 1.7435, decode.loss_dice: 0.4689, decode.acc_seg: 96.5847, loss: 2.2124
2024-06-28 11:31:00,845 - mmseg - INFO - Iter [13600/20000]	lr: 7.815e-06, eta: 0:49:38, time: 0.504, data_time: 0.048, memory: 8459, decode.loss_mask: 1.6554, decode.loss_dice: 0.4464, decode.acc_seg: 95.3080, loss: 2.1018
2024-06-28 11:31:23,841 - mmseg - INFO - Iter [13650/20000]	lr: 7.767e-06, eta: 0:49:14, time: 0.460, data_time: 0.006, memory: 8459, decode.loss_mask: 1.7387, decode.loss_dice: 0.4647, decode.acc_seg: 95.9149, loss: 2.2034
2024-06-28 11:31:46,827 - mmseg - INFO - Iter [13700/20000]	lr: 7.719e-06, eta: 0:48:51, time: 0.460, data_time: 0.006, memory: 8459, decode.loss_mask: 1.7639, decode.loss_dice: 0.4639, decode.acc_seg: 94.9437, loss: 2.2278
2024-06-28 11:32:09,808 - mmseg - INFO - Iter [13750/20000]	lr: 7.671e-06, eta: 0:48:27, time: 0.460, data_time: 0.006, memory: 8459, decode.loss_mask: 1.8064, decode.loss_dice: 0.4566, decode.acc_seg: 95.7649, loss: 2.2630
2024-06-28 11:32:32,923 - mmseg - INFO - Iter [13800/20000]	lr: 7.623e-06, eta: 0:48:04, time: 0.462, data_time: 0.006, memory: 8459, decode.loss_mask: 1.7050, decode.loss_dice: 0.4552, decode.acc_seg: 96.0677, loss: 2.1602
2024-06-28 11:32:56,083 - mmseg - INFO - Iter [13850/20000]	lr: 7.575e-06, eta: 0:47:41, time: 0.463, data_time: 0.006, memory: 8459, decode.loss_mask: 1.7968, decode.loss_dice: 0.4602, decode.acc_seg: 95.9494, loss: 2.2570
2024-06-28 11:33:19,075 - mmseg - INFO - Iter [13900/20000]	lr: 7.527e-06, eta: 0:47:17, time: 0.460, data_time: 0.006, memory: 8459, decode.loss_mask: 1.7064, decode.loss_dice: 0.4650, decode.acc_seg: 96.5195, loss: 2.1714
2024-06-28 11:33:42,086 - mmseg - INFO - Iter [13950/20000]	lr: 7.478e-06, eta: 0:46:54, time: 0.460, data_time: 0.006, memory: 8459, decode.loss_mask: 1.7423, decode.loss_dice: 0.4673, decode.acc_seg: 94.9827, loss: 2.2097
2024-06-28 11:34:05,022 - mmseg - INFO - Saving checkpoint at 14000 iterations
2024-06-28 11:34:06,087 - mmseg - INFO - Exp name: xxscales_output_vpt_seg_zero_vit-b_512x512_20k_12_10.py
2024-06-28 11:34:06,089 - mmseg - INFO - Iter [14000/20000]	lr: 7.430e-06, eta: 0:46:31, time: 0.480, data_time: 0.006, memory: 8459, decode.loss_mask: 1.6793, decode.loss_dice: 0.4449, decode.acc_seg: 96.3372, loss: 2.1243
2024-06-28 11:34:28,962 - mmseg - INFO - Iter [14050/20000]	lr: 7.382e-06, eta: 0:46:08, time: 0.457, data_time: 0.007, memory: 8459, decode.loss_mask: 1.8670, decode.loss_dice: 0.4574, decode.acc_seg: 94.7303, loss: 2.3244
2024-06-28 11:34:51,800 - mmseg - INFO - Iter [14100/20000]	lr: 7.334e-06, eta: 0:45:44, time: 0.457, data_time: 0.006, memory: 8459, decode.loss_mask: 1.7929, decode.loss_dice: 0.4692, decode.acc_seg: 95.2195, loss: 2.2621
2024-06-28 11:35:14,586 - mmseg - INFO - Iter [14150/20000]	lr: 7.285e-06, eta: 0:45:21, time: 0.456, data_time: 0.006, memory: 8459, decode.loss_mask: 1.8509, decode.loss_dice: 0.4709, decode.acc_seg: 94.8545, loss: 2.3219
2024-06-28 11:35:37,708 - mmseg - INFO - Iter [14200/20000]	lr: 7.237e-06, eta: 0:44:57, time: 0.462, data_time: 0.006, memory: 8459, decode.loss_mask: 1.8269, decode.loss_dice: 0.4469, decode.acc_seg: 95.8922, loss: 2.2738
2024-06-28 11:36:00,772 - mmseg - INFO - Iter [14250/20000]	lr: 7.189e-06, eta: 0:44:34, time: 0.461, data_time: 0.006, memory: 8459, decode.loss_mask: 1.5834, decode.loss_dice: 0.4398, decode.acc_seg: 96.6617, loss: 2.0231
2024-06-28 11:36:23,873 - mmseg - INFO - Iter [14300/20000]	lr: 7.140e-06, eta: 0:44:11, time: 0.462, data_time: 0.006, memory: 8459, decode.loss_mask: 1.7719, decode.loss_dice: 0.4607, decode.acc_seg: 95.9699, loss: 2.2326
2024-06-28 11:36:49,243 - mmseg - INFO - Iter [14350/20000]	lr: 7.092e-06, eta: 0:43:48, time: 0.507, data_time: 0.050, memory: 8459, decode.loss_mask: 1.8745, decode.loss_dice: 0.4433, decode.acc_seg: 95.3868, loss: 2.3178
2024-06-28 11:37:12,420 - mmseg - INFO - Iter [14400/20000]	lr: 7.043e-06, eta: 0:43:25, time: 0.464, data_time: 0.006, memory: 8459, decode.loss_mask: 1.8806, decode.loss_dice: 0.4585, decode.acc_seg: 94.8425, loss: 2.3391
2024-06-28 11:37:35,620 - mmseg - INFO - Iter [14450/20000]	lr: 6.995e-06, eta: 0:43:02, time: 0.464, data_time: 0.006, memory: 8459, decode.loss_mask: 1.7123, decode.loss_dice: 0.4517, decode.acc_seg: 95.7198, loss: 2.1640
2024-06-28 11:37:58,862 - mmseg - INFO - Iter [14500/20000]	lr: 6.946e-06, eta: 0:42:38, time: 0.465, data_time: 0.006, memory: 8459, decode.loss_mask: 1.7081, decode.loss_dice: 0.4516, decode.acc_seg: 95.0367, loss: 2.1596
2024-06-28 11:38:22,025 - mmseg - INFO - Iter [14550/20000]	lr: 6.897e-06, eta: 0:42:15, time: 0.463, data_time: 0.006, memory: 8459, decode.loss_mask: 1.7711, decode.loss_dice: 0.4446, decode.acc_seg: 95.8104, loss: 2.2157
2024-06-28 11:38:45,048 - mmseg - INFO - Iter [14600/20000]	lr: 6.849e-06, eta: 0:41:52, time: 0.460, data_time: 0.006, memory: 8459, decode.loss_mask: 1.7784, decode.loss_dice: 0.4423, decode.acc_seg: 95.3454, loss: 2.2207
2024-06-28 11:39:07,914 - mmseg - INFO - Iter [14650/20000]	lr: 6.800e-06, eta: 0:41:28, time: 0.457, data_time: 0.006, memory: 8459, decode.loss_mask: 1.6617, decode.loss_dice: 0.4543, decode.acc_seg: 96.4544, loss: 2.1160
2024-06-28 11:39:31,202 - mmseg - INFO - Iter [14700/20000]	lr: 6.751e-06, eta: 0:41:05, time: 0.466, data_time: 0.006, memory: 8459, decode.loss_mask: 1.7002, decode.loss_dice: 0.4526, decode.acc_seg: 95.5297, loss: 2.1528
2024-06-28 11:39:54,269 - mmseg - INFO - Iter [14750/20000]	lr: 6.702e-06, eta: 0:40:42, time: 0.461, data_time: 0.006, memory: 8459, decode.loss_mask: 1.9250, decode.loss_dice: 0.4574, decode.acc_seg: 94.9637, loss: 2.3824
2024-06-28 11:40:17,225 - mmseg - INFO - Iter [14800/20000]	lr: 6.653e-06, eta: 0:40:18, time: 0.459, data_time: 0.006, memory: 8459, decode.loss_mask: 1.7532, decode.loss_dice: 0.4589, decode.acc_seg: 95.8493, loss: 2.2121
2024-06-28 11:40:40,241 - mmseg - INFO - Iter [14850/20000]	lr: 6.604e-06, eta: 0:39:55, time: 0.460, data_time: 0.006, memory: 8459, decode.loss_mask: 1.7755, decode.loss_dice: 0.4285, decode.acc_seg: 95.8362, loss: 2.2040
2024-06-28 11:41:03,353 - mmseg - INFO - Iter [14900/20000]	lr: 6.555e-06, eta: 0:39:32, time: 0.462, data_time: 0.006, memory: 8459, decode.loss_mask: 1.7012, decode.loss_dice: 0.4612, decode.acc_seg: 95.4891, loss: 2.1625
2024-06-28 11:41:26,343 - mmseg - INFO - Iter [14950/20000]	lr: 6.506e-06, eta: 0:39:08, time: 0.460, data_time: 0.006, memory: 8459, decode.loss_mask: 1.7464, decode.loss_dice: 0.4551, decode.acc_seg: 95.6977, loss: 2.2015
2024-06-28 11:41:49,525 - mmseg - INFO - Exp name: xxscales_output_vpt_seg_zero_vit-b_512x512_20k_12_10.py
2024-06-28 11:41:49,526 - mmseg - INFO - Iter [15000/20000]	lr: 6.457e-06, eta: 0:38:45, time: 0.464, data_time: 0.006, memory: 8459, decode.loss_mask: 1.8200, decode.loss_dice: 0.4732, decode.acc_seg: 95.8875, loss: 2.2932
2024-06-28 11:42:12,568 - mmseg - INFO - Iter [15050/20000]	lr: 6.408e-06, eta: 0:38:22, time: 0.461, data_time: 0.006, memory: 8459, decode.loss_mask: 1.9802, decode.loss_dice: 0.4573, decode.acc_seg: 94.6531, loss: 2.4375
2024-06-28 11:42:37,844 - mmseg - INFO - Iter [15100/20000]	lr: 6.359e-06, eta: 0:37:59, time: 0.506, data_time: 0.049, memory: 8459, decode.loss_mask: 1.7841, decode.loss_dice: 0.4692, decode.acc_seg: 95.3866, loss: 2.2533
2024-06-28 11:43:00,873 - mmseg - INFO - Iter [15150/20000]	lr: 6.310e-06, eta: 0:37:36, time: 0.461, data_time: 0.006, memory: 8459, decode.loss_mask: 1.8306, decode.loss_dice: 0.4479, decode.acc_seg: 94.9721, loss: 2.2785
2024-06-28 11:43:24,231 - mmseg - INFO - Iter [15200/20000]	lr: 6.260e-06, eta: 0:37:13, time: 0.467, data_time: 0.006, memory: 8459, decode.loss_mask: 1.8005, decode.loss_dice: 0.4621, decode.acc_seg: 96.3423, loss: 2.2625
2024-06-28 11:43:47,409 - mmseg - INFO - Iter [15250/20000]	lr: 6.211e-06, eta: 0:36:49, time: 0.464, data_time: 0.006, memory: 8459, decode.loss_mask: 1.8748, decode.loss_dice: 0.4488, decode.acc_seg: 95.9336, loss: 2.3236
2024-06-28 11:44:10,559 - mmseg - INFO - Iter [15300/20000]	lr: 6.162e-06, eta: 0:36:26, time: 0.463, data_time: 0.006, memory: 8459, decode.loss_mask: 1.6704, decode.loss_dice: 0.4298, decode.acc_seg: 95.7425, loss: 2.1002
2024-06-28 11:44:33,604 - mmseg - INFO - Iter [15350/20000]	lr: 6.112e-06, eta: 0:36:03, time: 0.461, data_time: 0.006, memory: 8459, decode.loss_mask: 1.8681, decode.loss_dice: 0.4564, decode.acc_seg: 96.2761, loss: 2.3245
2024-06-28 11:44:56,512 - mmseg - INFO - Iter [15400/20000]	lr: 6.063e-06, eta: 0:35:39, time: 0.458, data_time: 0.006, memory: 8459, decode.loss_mask: 1.7696, decode.loss_dice: 0.4334, decode.acc_seg: 96.1066, loss: 2.2030
2024-06-28 11:45:19,459 - mmseg - INFO - Iter [15450/20000]	lr: 6.013e-06, eta: 0:35:16, time: 0.459, data_time: 0.006, memory: 8459, decode.loss_mask: 1.6876, decode.loss_dice: 0.4538, decode.acc_seg: 95.2518, loss: 2.1414
2024-06-28 11:45:42,395 - mmseg - INFO - Iter [15500/20000]	lr: 5.964e-06, eta: 0:34:53, time: 0.459, data_time: 0.006, memory: 8459, decode.loss_mask: 1.7190, decode.loss_dice: 0.4470, decode.acc_seg: 95.3815, loss: 2.1661
2024-06-28 11:46:05,689 - mmseg - INFO - Iter [15550/20000]	lr: 5.914e-06, eta: 0:34:29, time: 0.466, data_time: 0.006, memory: 8459, decode.loss_mask: 1.6673, decode.loss_dice: 0.4737, decode.acc_seg: 95.5660, loss: 2.1411
2024-06-28 11:46:28,849 - mmseg - INFO - Iter [15600/20000]	lr: 5.864e-06, eta: 0:34:06, time: 0.463, data_time: 0.006, memory: 8459, decode.loss_mask: 1.5903, decode.loss_dice: 0.4494, decode.acc_seg: 97.2979, loss: 2.0397
2024-06-28 11:46:51,914 - mmseg - INFO - Iter [15650/20000]	lr: 5.815e-06, eta: 0:33:43, time: 0.461, data_time: 0.006, memory: 8459, decode.loss_mask: 1.7782, decode.loss_dice: 0.4543, decode.acc_seg: 94.7894, loss: 2.2325
2024-06-28 11:47:14,897 - mmseg - INFO - Iter [15700/20000]	lr: 5.765e-06, eta: 0:33:20, time: 0.460, data_time: 0.006, memory: 8459, decode.loss_mask: 1.6813, decode.loss_dice: 0.4352, decode.acc_seg: 96.5688, loss: 2.1165
2024-06-28 11:47:37,934 - mmseg - INFO - Iter [15750/20000]	lr: 5.715e-06, eta: 0:32:56, time: 0.461, data_time: 0.006, memory: 8459, decode.loss_mask: 1.6155, decode.loss_dice: 0.4442, decode.acc_seg: 96.3708, loss: 2.0597
2024-06-28 11:48:01,026 - mmseg - INFO - Iter [15800/20000]	lr: 5.665e-06, eta: 0:32:33, time: 0.462, data_time: 0.006, memory: 8459, decode.loss_mask: 1.8441, decode.loss_dice: 0.4460, decode.acc_seg: 95.5055, loss: 2.2902
2024-06-28 11:48:26,377 - mmseg - INFO - Iter [15850/20000]	lr: 5.615e-06, eta: 0:32:10, time: 0.507, data_time: 0.049, memory: 8459, decode.loss_mask: 1.7255, decode.loss_dice: 0.4432, decode.acc_seg: 96.5381, loss: 2.1687
2024-06-28 11:48:49,617 - mmseg - INFO - Iter [15900/20000]	lr: 5.565e-06, eta: 0:31:47, time: 0.465, data_time: 0.006, memory: 8459, decode.loss_mask: 1.8288, decode.loss_dice: 0.4692, decode.acc_seg: 96.0266, loss: 2.2980
2024-06-28 11:49:12,725 - mmseg - INFO - Iter [15950/20000]	lr: 5.515e-06, eta: 0:31:24, time: 0.462, data_time: 0.006, memory: 8459, decode.loss_mask: 1.6102, decode.loss_dice: 0.4604, decode.acc_seg: 95.7017, loss: 2.0706
2024-06-28 11:49:35,659 - mmseg - INFO - Saving checkpoint at 16000 iterations
2024-06-28 11:49:36,739 - mmseg - INFO - Exp name: xxscales_output_vpt_seg_zero_vit-b_512x512_20k_12_10.py
2024-06-28 11:49:36,740 - mmseg - INFO - Iter [16000/20000]	lr: 5.465e-06, eta: 0:31:01, time: 0.480, data_time: 0.006, memory: 8459, decode.loss_mask: 1.7271, decode.loss_dice: 0.4351, decode.acc_seg: 95.3714, loss: 2.1622
2024-06-28 11:49:59,840 - mmseg - INFO - Iter [16050/20000]	lr: 5.414e-06, eta: 0:30:37, time: 0.462, data_time: 0.006, memory: 8459, decode.loss_mask: 1.6719, decode.loss_dice: 0.4564, decode.acc_seg: 96.0829, loss: 2.1283
2024-06-28 11:50:22,834 - mmseg - INFO - Iter [16100/20000]	lr: 5.364e-06, eta: 0:30:14, time: 0.460, data_time: 0.006, memory: 8459, decode.loss_mask: 1.5842, decode.loss_dice: 0.4206, decode.acc_seg: 97.0112, loss: 2.0049
2024-06-28 11:50:46,028 - mmseg - INFO - Iter [16150/20000]	lr: 5.314e-06, eta: 0:29:51, time: 0.464, data_time: 0.006, memory: 8459, decode.loss_mask: 1.6163, decode.loss_dice: 0.4482, decode.acc_seg: 96.8165, loss: 2.0644
2024-06-28 11:51:09,136 - mmseg - INFO - Iter [16200/20000]	lr: 5.263e-06, eta: 0:29:27, time: 0.462, data_time: 0.006, memory: 8459, decode.loss_mask: 1.6979, decode.loss_dice: 0.4395, decode.acc_seg: 96.4536, loss: 2.1374
2024-06-28 11:51:32,041 - mmseg - INFO - Iter [16250/20000]	lr: 5.213e-06, eta: 0:29:04, time: 0.458, data_time: 0.006, memory: 8459, decode.loss_mask: 1.8719, decode.loss_dice: 0.4587, decode.acc_seg: 94.7662, loss: 2.3306
2024-06-28 11:51:55,172 - mmseg - INFO - Iter [16300/20000]	lr: 5.162e-06, eta: 0:28:41, time: 0.463, data_time: 0.006, memory: 8459, decode.loss_mask: 1.8568, decode.loss_dice: 0.4592, decode.acc_seg: 95.0618, loss: 2.3160
2024-06-28 11:52:17,973 - mmseg - INFO - Iter [16350/20000]	lr: 5.111e-06, eta: 0:28:17, time: 0.456, data_time: 0.006, memory: 8459, decode.loss_mask: 1.8327, decode.loss_dice: 0.4373, decode.acc_seg: 95.9461, loss: 2.2700
2024-06-28 11:52:40,968 - mmseg - INFO - Iter [16400/20000]	lr: 5.061e-06, eta: 0:27:54, time: 0.460, data_time: 0.006, memory: 8459, decode.loss_mask: 1.8398, decode.loss_dice: 0.4634, decode.acc_seg: 94.3040, loss: 2.3032
2024-06-28 11:53:04,102 - mmseg - INFO - Iter [16450/20000]	lr: 5.010e-06, eta: 0:27:31, time: 0.463, data_time: 0.006, memory: 8459, decode.loss_mask: 1.7195, decode.loss_dice: 0.4525, decode.acc_seg: 96.7885, loss: 2.1720
2024-06-28 11:53:27,077 - mmseg - INFO - Iter [16500/20000]	lr: 4.959e-06, eta: 0:27:07, time: 0.459, data_time: 0.006, memory: 8459, decode.loss_mask: 1.7371, decode.loss_dice: 0.4549, decode.acc_seg: 96.1388, loss: 2.1920
2024-06-28 11:53:50,241 - mmseg - INFO - Iter [16550/20000]	lr: 4.908e-06, eta: 0:26:44, time: 0.463, data_time: 0.006, memory: 8459, decode.loss_mask: 2.0252, decode.loss_dice: 0.4499, decode.acc_seg: 95.3552, loss: 2.4751
2024-06-28 11:54:15,366 - mmseg - INFO - Iter [16600/20000]	lr: 4.857e-06, eta: 0:26:21, time: 0.502, data_time: 0.048, memory: 8459, decode.loss_mask: 1.7416, decode.loss_dice: 0.4643, decode.acc_seg: 95.8394, loss: 2.2059
2024-06-28 11:54:38,415 - mmseg - INFO - Iter [16650/20000]	lr: 4.806e-06, eta: 0:25:58, time: 0.461, data_time: 0.006, memory: 8459, decode.loss_mask: 1.4750, decode.loss_dice: 0.4436, decode.acc_seg: 95.8335, loss: 1.9186
2024-06-28 11:55:01,608 - mmseg - INFO - Iter [16700/20000]	lr: 4.755e-06, eta: 0:25:35, time: 0.464, data_time: 0.006, memory: 8459, decode.loss_mask: 1.6271, decode.loss_dice: 0.4552, decode.acc_seg: 96.0579, loss: 2.0823
2024-06-28 11:55:24,620 - mmseg - INFO - Iter [16750/20000]	lr: 4.704e-06, eta: 0:25:11, time: 0.460, data_time: 0.006, memory: 8459, decode.loss_mask: 1.7427, decode.loss_dice: 0.4455, decode.acc_seg: 95.7925, loss: 2.1882
2024-06-28 11:55:47,850 - mmseg - INFO - Iter [16800/20000]	lr: 4.652e-06, eta: 0:24:48, time: 0.465, data_time: 0.006, memory: 8459, decode.loss_mask: 1.7844, decode.loss_dice: 0.4365, decode.acc_seg: 96.6577, loss: 2.2210
2024-06-28 11:56:10,810 - mmseg - INFO - Iter [16850/20000]	lr: 4.601e-06, eta: 0:24:25, time: 0.459, data_time: 0.006, memory: 8459, decode.loss_mask: 1.6449, decode.loss_dice: 0.4481, decode.acc_seg: 95.7185, loss: 2.0930
2024-06-28 11:56:33,801 - mmseg - INFO - Iter [16900/20000]	lr: 4.550e-06, eta: 0:24:02, time: 0.460, data_time: 0.006, memory: 8459, decode.loss_mask: 1.7574, decode.loss_dice: 0.4528, decode.acc_seg: 95.4850, loss: 2.2102
2024-06-28 11:56:56,792 - mmseg - INFO - Iter [16950/20000]	lr: 4.498e-06, eta: 0:23:38, time: 0.460, data_time: 0.006, memory: 8459, decode.loss_mask: 1.7166, decode.loss_dice: 0.4387, decode.acc_seg: 95.2773, loss: 2.1553
2024-06-28 11:57:19,984 - mmseg - INFO - Exp name: xxscales_output_vpt_seg_zero_vit-b_512x512_20k_12_10.py
2024-06-28 11:57:19,984 - mmseg - INFO - Iter [17000/20000]	lr: 4.446e-06, eta: 0:23:15, time: 0.464, data_time: 0.006, memory: 8459, decode.loss_mask: 1.6628, decode.loss_dice: 0.4504, decode.acc_seg: 96.0556, loss: 2.1132
2024-06-28 11:57:43,102 - mmseg - INFO - Iter [17050/20000]	lr: 4.395e-06, eta: 0:22:52, time: 0.462, data_time: 0.007, memory: 8459, decode.loss_mask: 1.5910, decode.loss_dice: 0.4459, decode.acc_seg: 96.1023, loss: 2.0369
2024-06-28 11:58:06,106 - mmseg - INFO - Iter [17100/20000]	lr: 4.343e-06, eta: 0:22:28, time: 0.460, data_time: 0.007, memory: 8459, decode.loss_mask: 1.6659, decode.loss_dice: 0.4420, decode.acc_seg: 95.6621, loss: 2.1079
2024-06-28 11:58:29,115 - mmseg - INFO - Iter [17150/20000]	lr: 4.291e-06, eta: 0:22:05, time: 0.460, data_time: 0.006, memory: 8459, decode.loss_mask: 1.6938, decode.loss_dice: 0.4422, decode.acc_seg: 96.5487, loss: 2.1360
2024-06-28 11:58:52,076 - mmseg - INFO - Iter [17200/20000]	lr: 4.239e-06, eta: 0:21:42, time: 0.459, data_time: 0.006, memory: 8459, decode.loss_mask: 1.8597, decode.loss_dice: 0.4435, decode.acc_seg: 94.8028, loss: 2.3032
2024-06-28 11:59:15,106 - mmseg - INFO - Iter [17250/20000]	lr: 4.187e-06, eta: 0:21:18, time: 0.461, data_time: 0.006, memory: 8459, decode.loss_mask: 1.6879, decode.loss_dice: 0.4407, decode.acc_seg: 95.9583, loss: 2.1285
2024-06-28 11:59:38,106 - mmseg - INFO - Iter [17300/20000]	lr: 4.135e-06, eta: 0:20:55, time: 0.460, data_time: 0.006, memory: 8459, decode.loss_mask: 1.6818, decode.loss_dice: 0.4399, decode.acc_seg: 94.9654, loss: 2.1218
2024-06-28 12:00:03,350 - mmseg - INFO - Iter [17350/20000]	lr: 4.082e-06, eta: 0:20:32, time: 0.505, data_time: 0.050, memory: 8459, decode.loss_mask: 1.6990, decode.loss_dice: 0.4183, decode.acc_seg: 96.2989, loss: 2.1173
2024-06-28 12:00:26,298 - mmseg - INFO - Iter [17400/20000]	lr: 4.030e-06, eta: 0:20:09, time: 0.459, data_time: 0.006, memory: 8459, decode.loss_mask: 1.7275, decode.loss_dice: 0.4321, decode.acc_seg: 96.2196, loss: 2.1596
2024-06-28 12:00:49,337 - mmseg - INFO - Iter [17450/20000]	lr: 3.978e-06, eta: 0:19:46, time: 0.461, data_time: 0.006, memory: 8459, decode.loss_mask: 1.6657, decode.loss_dice: 0.4550, decode.acc_seg: 96.1758, loss: 2.1208
2024-06-28 12:01:12,481 - mmseg - INFO - Iter [17500/20000]	lr: 3.925e-06, eta: 0:19:22, time: 0.463, data_time: 0.006, memory: 8459, decode.loss_mask: 1.7950, decode.loss_dice: 0.4536, decode.acc_seg: 95.7528, loss: 2.2487
2024-06-28 12:01:35,506 - mmseg - INFO - Iter [17550/20000]	lr: 3.872e-06, eta: 0:18:59, time: 0.461, data_time: 0.006, memory: 8459, decode.loss_mask: 1.7359, decode.loss_dice: 0.4469, decode.acc_seg: 95.1314, loss: 2.1828
2024-06-28 12:01:58,522 - mmseg - INFO - Iter [17600/20000]	lr: 3.820e-06, eta: 0:18:36, time: 0.460, data_time: 0.006, memory: 8459, decode.loss_mask: 1.6064, decode.loss_dice: 0.4437, decode.acc_seg: 95.9624, loss: 2.0501
2024-06-28 12:02:21,561 - mmseg - INFO - Iter [17650/20000]	lr: 3.767e-06, eta: 0:18:13, time: 0.461, data_time: 0.006, memory: 8459, decode.loss_mask: 1.8649, decode.loss_dice: 0.4455, decode.acc_seg: 95.9456, loss: 2.3104
2024-06-28 12:02:44,564 - mmseg - INFO - Iter [17700/20000]	lr: 3.714e-06, eta: 0:17:49, time: 0.460, data_time: 0.006, memory: 8459, decode.loss_mask: 1.6715, decode.loss_dice: 0.4434, decode.acc_seg: 96.6038, loss: 2.1149
2024-06-28 12:03:07,523 - mmseg - INFO - Iter [17750/20000]	lr: 3.661e-06, eta: 0:17:26, time: 0.459, data_time: 0.006, memory: 8459, decode.loss_mask: 1.6143, decode.loss_dice: 0.4305, decode.acc_seg: 95.6434, loss: 2.0448
2024-06-28 12:03:30,704 - mmseg - INFO - Iter [17800/20000]	lr: 3.607e-06, eta: 0:17:03, time: 0.464, data_time: 0.006, memory: 8459, decode.loss_mask: 1.5793, decode.loss_dice: 0.4478, decode.acc_seg: 96.0355, loss: 2.0271
2024-06-28 12:03:53,732 - mmseg - INFO - Iter [17850/20000]	lr: 3.554e-06, eta: 0:16:39, time: 0.461, data_time: 0.006, memory: 8459, decode.loss_mask: 1.7162, decode.loss_dice: 0.4436, decode.acc_seg: 95.6322, loss: 2.1598
2024-06-28 12:04:16,871 - mmseg - INFO - Iter [17900/20000]	lr: 3.500e-06, eta: 0:16:16, time: 0.463, data_time: 0.006, memory: 8459, decode.loss_mask: 1.6988, decode.loss_dice: 0.4573, decode.acc_seg: 95.8118, loss: 2.1560
2024-06-28 12:04:39,872 - mmseg - INFO - Iter [17950/20000]	lr: 3.447e-06, eta: 0:15:53, time: 0.460, data_time: 0.006, memory: 8459, decode.loss_mask: 1.6807, decode.loss_dice: 0.4606, decode.acc_seg: 95.5505, loss: 2.1413
2024-06-28 12:05:03,067 - mmseg - INFO - Saving checkpoint at 18000 iterations
2024-06-28 12:05:04,164 - mmseg - INFO - Exp name: xxscales_output_vpt_seg_zero_vit-b_512x512_20k_12_10.py
2024-06-28 12:05:04,165 - mmseg - INFO - Iter [18000/20000]	lr: 3.393e-06, eta: 0:15:30, time: 0.486, data_time: 0.006, memory: 8459, decode.loss_mask: 1.6373, decode.loss_dice: 0.4399, decode.acc_seg: 95.8230, loss: 2.0772
Traceback (most recent call last):
  File "/mnt/fast/nobackup/users/ae01116/multi-modal-dissertation-uos/train.py", line 195, in <module>
    main()
  File "/mnt/fast/nobackup/users/ae01116/multi-modal-dissertation-uos/train.py", line 183, in main
    train_segmentor(
  File "/mnt/fast/nobackup/users/ae01116/multi-modal-dissertation-uos/mmseg/apis/train.py", line 191, in train_segmentor
    runner.run(data_loaders, cfg.workflow)
  File "/mnt/fast/nobackup/scratch4weeks/ae01116/zegenv/lib/python3.9/site-packages/mmcv/runner/iter_based_runner.py", line 134, in run
    iter_runner(iter_loaders[i], **kwargs)
  File "/mnt/fast/nobackup/scratch4weeks/ae01116/zegenv/lib/python3.9/site-packages/mmcv/runner/iter_based_runner.py", line 67, in train
    self.call_hook('after_train_iter')
  File "/mnt/fast/nobackup/scratch4weeks/ae01116/zegenv/lib/python3.9/site-packages/mmcv/runner/base_runner.py", line 309, in call_hook
    getattr(hook, fn_name)(self)
  File "/mnt/fast/nobackup/scratch4weeks/ae01116/zegenv/lib/python3.9/site-packages/mmcv/runner/hooks/evaluation.py", line 262, in after_train_iter
    self._do_evaluate(runner)
  File "/mnt/fast/nobackup/users/ae01116/multi-modal-dissertation-uos/mmseg/core/evaluation/eval_hooks.py", line 125, in _do_evaluate
    key_score = self.evaluate(runner, results)
  File "/mnt/fast/nobackup/scratch4weeks/ae01116/zegenv/lib/python3.9/site-packages/mmcv/runner/hooks/evaluation.py", line 361, in evaluate
    eval_res = self.dataloader.dataset.evaluate(
TypeError: evaluate() missing 2 required positional arguments: 'unseen_idx' and 'results'
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 27 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 28 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 29 closing signal SIGTERM
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 26) of binary: /mnt/fast/nobackup/scratch4weeks/ae01116/zegenv/bin/python
Traceback (most recent call last):
  File "/mnt/fast/nobackup/scratch4weeks/ae01116/zegenv/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/mnt/fast/nobackup/scratch4weeks/ae01116/zegenv/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/mnt/fast/nobackup/scratch4weeks/ae01116/zegenv/lib/python3.9/site-packages/torch/distributed/launch.py", line 193, in <module>
    main()
  File "/mnt/fast/nobackup/scratch4weeks/ae01116/zegenv/lib/python3.9/site-packages/torch/distributed/launch.py", line 189, in main
    launch(args)
  File "/mnt/fast/nobackup/scratch4weeks/ae01116/zegenv/lib/python3.9/site-packages/torch/distributed/launch.py", line 174, in launch
    run(args)
  File "/mnt/fast/nobackup/scratch4weeks/ae01116/zegenv/lib/python3.9/site-packages/torch/distributed/run.py", line 710, in run
    elastic_launch(
  File "/mnt/fast/nobackup/scratch4weeks/ae01116/zegenv/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 131, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/mnt/fast/nobackup/scratch4weeks/ae01116/zegenv/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 259, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
/mnt/fast/nobackup/users/ae01116/multi-modal-dissertation-uos/train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-06-28_12:05:42
  host      : ae01116-173635.0-aisurrey15.surrey.ac.uk
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 26)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
