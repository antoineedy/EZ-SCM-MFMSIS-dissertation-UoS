/mnt/fast/nobackup/scratch4weeks/ae01116/zegenv/lib/python3.9/site-packages/torch/distributed/launch.py:178: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
2024-06-20 13:19:55,327 - mmseg - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.9.19 (main, May  6 2024, 19:43:03) [GCC 11.2.0]
CUDA available: True
GPU 0,1,2,3: NVIDIA GeForce RTX 3090
CUDA_HOME: /usr/local/cuda
NVCC: Build cuda_11.0_bu.TC445_37.28845127_0
GCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
PyTorch: 1.10.1+cu111
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

TorchVision: 0.11.2+cu111
OpenCV: 4.10.0
MMCV: 1.4.4
MMCV Compiler: GCC 7.3
MMCV CUDA Compiler: 11.1
------------------------------------------------------------

2024-06-20 13:19:55,327 - mmseg - INFO - Distributed training: True
2024-06-20 13:19:56,211 - mmseg - INFO - Config:
norm_cfg = dict(type='SyncBN', requires_grad=True)
img_size = 512
in_channels = 512
out_indices = [11]
model = dict(
    type='MultiScalesZegCLIP',
    pretrained='/mnt/fast/nobackup/scratch4weeks/ae01116/weights/ViT-B-16.pt',
    context_length=77,
    backbone=dict(
        type='VPTCLIPVisionTransformer',
        layers=12,
        style='pytorch',
        patch_size=16,
        width=768,
        output_dim=512,
        get_embeddings=True,
        drop_path_rate=0.1,
        input_resolution=512,
        out_indices=[11],
        num_tokens=10,
        prompt_dim=768,
        total_d_layer=11),
    text_encoder=dict(
        type='CLIPTextEncoder',
        context_length=77,
        style='pytorch',
        embed_dim=512,
        transformer_width=512,
        transformer_heads=8,
        transformer_layers=12),
    decode_head=dict(
        type='ATMSingleHeadSeg',
        img_size=512,
        in_channels=512,
        channels=512,
        num_classes=15,
        num_layers=3,
        num_heads=8,
        use_stages=1,
        embed_dims=512,
        loss_decode=dict(
            type='SegLossPlus',
            num_classes=15,
            dec_layers=3,
            loss_weight=1.0,
            mask_weight=100.0,
            dice_weight=1.0),
        seen_idx=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14],
        all_idx=[
            0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18,
            19
        ],
        use_proj=False),
    train_cfg=dict(),
    test_cfg=dict(mode='slide', crop_size=(512, 512), stride=(426, 426)),
    pretrained_text=
    '/mnt/fast/nobackup/scratch4weeks/ae01116/weights/ViT-B-16.pt',
    multi_scale=dict(type='MultiScales', divisions=[2]),
    base_class=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14],
    novel_class=[15, 16, 17, 18, 19],
    both_class=[
        0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19
    ],
    ft_backbone=False,
    exclude_key='prompt',
    load_text_embedding=
    '/mnt/fast/nobackup/users/ae01116/multi-modal-dissertation-uos/configs/_base_/datasets/text_embedding/voc12_single.npy'
)
dataset_type = 'ZeroPascalVOCDataset20'
base = '/mnt/fast/nobackup/users/ae01116/multi-modal-dissertation-uos'
base_scratch = '/mnt/fast/nobackup/scratch4weeks/ae01116'
data_root = '/mnt/fast/nobackup/scratch4weeks/ae01116/data/VOC2012'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
crop_size = (512, 512)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations', reduce_zero_label=True),
    dict(type='Resize', img_scale=(2048, 512), ratio_range=(0.5, 2.0)),
    dict(type='RandomCrop', crop_size=(512, 512), cat_max_ratio=0.75),
    dict(type='RandomFlip', prob=0.5),
    dict(type='PhotoMetricDistortion'),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='Pad', size=(512, 512), pad_val=0, seg_pad_val=255),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_semantic_seg'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(2048, 512),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True, min_size=512),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
data = dict(
    samples_per_gpu=1,
    workers_per_gpu=1,
    train=dict(
        type='ZeroPascalVOCDataset20',
        data_root='/mnt/fast/nobackup/scratch4weeks/ae01116/data/VOC2012',
        img_dir='JPEGImages',
        ann_dir=['SegmentationClass', 'SegmentationClassAug'],
        split=[
            'ImageSets/Segmentation/train.txt',
            'ImageSets/Segmentation/aug.txt'
        ],
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations', reduce_zero_label=True),
            dict(type='Resize', img_scale=(2048, 512), ratio_range=(0.5, 2.0)),
            dict(type='RandomCrop', crop_size=(512, 512), cat_max_ratio=0.75),
            dict(type='RandomFlip', prob=0.5),
            dict(type='PhotoMetricDistortion'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size=(512, 512), pad_val=0, seg_pad_val=255),
            dict(type='DefaultFormatBundle'),
            dict(type='Collect', keys=['img', 'gt_semantic_seg'])
        ]),
    val=dict(
        type='ZeroPascalVOCDataset20',
        data_root='/mnt/fast/nobackup/scratch4weeks/ae01116/data/VOC2012',
        img_dir='JPEGImages',
        ann_dir='SegmentationClass',
        split='ImageSets/Segmentation/val.txt',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(2048, 512),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True, min_size=512),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]),
    test=dict(
        type='ZeroPascalVOCDataset20',
        data_root='/mnt/fast/nobackup/scratch4weeks/ae01116/data/VOC2012',
        img_dir='JPEGImages',
        ann_dir='SegmentationClass',
        split='ImageSets/Segmentation/val.txt',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(2048, 512),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True, min_size=512),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]))
log_config = dict(
    interval=50, hooks=[dict(type='TextLoggerHook', by_epoch=False)])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
cudnn_benchmark = True
find_unused_parameters = True
optimizer = dict(
    type='AdamW',
    lr=2e-05,
    weight_decay=0.01,
    paramwise_cfg=dict(
        custom_keys=dict(
            backbone=dict(lr_mult=10.0),
            text_encoder=dict(lr_mult=0.0),
            norm=dict(decay_mult=0.0),
            ln=dict(decay_mult=0.0),
            head=dict(lr_mult=10.0))))
optimizer_config = dict()
lr_config = dict(
    policy='poly',
    power=0.9,
    min_lr=1e-06,
    by_epoch=False,
    warmup='linear',
    warmup_iters=1500,
    warmup_ratio=1e-06)
runner = dict(type='IterBasedRunner', max_iters=20000)
checkpoint_config = dict(by_epoch=False, interval=2000)
evaluation = dict(interval=20001, metric='mIoU')
base_class = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]
novel_class = [15, 16, 17, 18, 19]
both_class = [
    0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19
]
num_classes = 15
pretrained = '/mnt/fast/nobackup/scratch4weeks/ae01116/weights/ViT-B-16.pt'
work_dir = '/mnt/fast/nobackup/scratch4weeks/ae01116/data/VOC2012'
gpu_ids = range(0, 1)

2024-06-20 13:19:56,214 - mmseg - INFO - Loaded 1464 images
2024-06-20 13:19:56,222 - mmseg - INFO - Loaded 10582 images
2024-06-20 13:19:57,134 - mmseg - INFO - #Params: 164077824
/mnt/fast/nobackup/scratch4weeks/ae01116/zegenv/lib/python3.9/site-packages/torch/nn/functional.py:3631: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  warnings.warn(
/mnt/fast/nobackup/scratch4weeks/ae01116/zegenv/lib/python3.9/site-packages/torch/nn/functional.py:3631: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  warnings.warn(
/mnt/fast/nobackup/scratch4weeks/ae01116/zegenv/lib/python3.9/site-packages/torch/nn/functional.py:3631: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  warnings.warn(
/mnt/fast/nobackup/scratch4weeks/ae01116/zegenv/lib/python3.9/site-packages/torch/nn/functional.py:3631: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  warnings.warn(
2024-06-20 13:19:57,975 - mmseg - INFO - MultiScalesZegCLIP(
  (backbone): VPTCLIPVisionTransformer(
    (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
    (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (transformer): Transformer(
      (resblocks): Sequential(
        (0): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
        (1): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (drop_path): DropPath(p=0.00909090880304575)
        )
        (2): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (drop_path): DropPath(p=0.0181818176060915)
        )
        (3): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (drop_path): DropPath(p=0.027272727340459824)
        )
        (4): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (drop_path): DropPath(p=0.036363635212183)
        )
        (5): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (drop_path): DropPath(p=0.045454543083906174)
        )
        (6): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (drop_path): DropPath(p=0.054545458406209946)
        )
        (7): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (drop_path): DropPath(p=0.06363636255264282)
        )
        (8): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (drop_path): DropPath(p=0.0727272778749466)
        )
        (9): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (drop_path): DropPath(p=0.08181818574666977)
        )
        (10): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (drop_path): DropPath(p=0.09090909361839294)
        )
        (11): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (drop_path): DropPath(p=0.10000000149011612)
        )
      )
    )
    (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (prompt_proj): Linear(in_features=768, out_features=768, bias=True)
    (prompt_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (prompt_dropout): Dropout(p=0.1, inplace=False)
  )
  (decode_head): ATMSingleHeadSeg(
    input_transform=None, ignore_index=255, align_corners=False
    (loss_decode): SegLossPlus(
      (criterion): SegPlusCriterion()
    )
    (dropout): Dropout2d(p=0.1, inplace=False)
    (input_proj_1): Identity()
    (proj_norm_1): Identity()
    (decoder_1): TPN_Decoder(
      (layers): ModuleList(
        (0): TPN_DecoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (linear1): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=2048, out_features=512, bias=True)
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
          (dropout3): Dropout(p=0.1, inplace=False)
          (multihead_attn): Attention(
            (q): Linear(in_features=512, out_features=512, bias=True)
            (k): Linear(in_features=512, out_features=512, bias=True)
            (v): Linear(in_features=512, out_features=512, bias=True)
            (attn_drop): Dropout(p=0.1, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): TPN_DecoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (linear1): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=2048, out_features=512, bias=True)
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
          (dropout3): Dropout(p=0.1, inplace=False)
          (multihead_attn): Attention(
            (q): Linear(in_features=512, out_features=512, bias=True)
            (k): Linear(in_features=512, out_features=512, bias=True)
            (v): Linear(in_features=512, out_features=512, bias=True)
            (attn_drop): Dropout(p=0.1, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
        )
        (2): TPN_DecoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (linear1): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=2048, out_features=512, bias=True)
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
          (dropout3): Dropout(p=0.1, inplace=False)
          (multihead_attn): Attention(
            (q): Linear(in_features=512, out_features=512, bias=True)
            (k): Linear(in_features=512, out_features=512, bias=True)
            (v): Linear(in_features=512, out_features=512, bias=True)
            (attn_drop): Dropout(p=0.1, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
    (q_proj): Linear(in_features=1024, out_features=512, bias=True)
  )
  init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
  (text_encoder): CLIPTextEncoder(
    (transformer): Transformer(
      (resblocks): Sequential(
        (0): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
        (1): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
        (2): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
        (3): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
        (4): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
        (5): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
        (6): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
        (7): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
        (8): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
        (9): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
        (10): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
        (11): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
    )
    (token_embedding): Embedding(49408, 512)
    (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (_MultiScalesZegCLIP__multi_scale): MultiScales()
)
fatal: not a git repository (or any parent up to mount point /scratch/condor)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
fatal: not a git repository (or any parent up to mount point /scratch/condor)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
fatal: not a git repository (or any parent up to mount point /scratch/condor)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
fatal: not a git repository (or any parent up to mount point /scratch/condor)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2024-06-20 13:20:03,110 - mmseg - INFO - Loaded 1449 images
2024-06-20 13:20:03,250 - mmseg - INFO - Start running, host: ae01116@ae01116-172820.0-aisurrey11.surrey.ac.uk, work_dir: /mnt/fast/nobackup/scratch4weeks/ae01116/data/VOC2012
2024-06-20 13:20:03,250 - mmseg - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2024-06-20 13:20:03,251 - mmseg - INFO - workflow: [('train', 1)], max: 20000 iters
2024-06-20 13:20:03,251 - mmseg - INFO - Checkpoints will be saved to /mnt/fast/nobackup/scratch4weeks/ae01116/data/VOC2012 by HardDiskBackend.
/mnt/fast/nobackup/scratch4weeks/ae01116/zegenv/lib/python3.9/site-packages/torch/nn/functional.py:3631: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  warnings.warn(
/mnt/fast/nobackup/scratch4weeks/ae01116/zegenv/lib/python3.9/site-packages/torch/nn/functional.py:3631: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  warnings.warn(
/mnt/fast/nobackup/scratch4weeks/ae01116/zegenv/lib/python3.9/site-packages/torch/nn/functional.py:3631: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  warnings.warn(
/mnt/fast/nobackup/scratch4weeks/ae01116/zegenv/lib/python3.9/site-packages/torch/nn/functional.py:3631: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  warnings.warn(
2024-06-20 13:21:23,133 - mmseg - INFO - Iter [50/20000]	lr: 6.520e-07, eta: 8:14:35, time: 1.488, data_time: 0.004, memory: 10067, decode.loss_mask: 775.7882, decode.loss_dice: 2.9782, decode.acc_seg: 145.5054, loss: 778.7664
2024-06-20 13:22:36,437 - mmseg - INFO - Iter [100/20000]	lr: 1.314e-06, eta: 8:09:48, time: 1.466, data_time: 0.003, memory: 10067, decode.loss_mask: 675.5919, decode.loss_dice: 3.0003, decode.acc_seg: 170.6004, loss: 678.5922
2024-06-20 13:23:50,261 - mmseg - INFO - Iter [150/20000]	lr: 1.974e-06, eta: 8:08:32, time: 1.476, data_time: 0.003, memory: 10079, decode.loss_mask: 475.7044, decode.loss_dice: 3.0663, decode.acc_seg: 139.2703, loss: 478.7708
2024-06-20 13:25:03,605 - mmseg - INFO - Iter [200/20000]	lr: 2.631e-06, eta: 8:06:29, time: 1.467, data_time: 0.003, memory: 10079, decode.loss_mask: 245.9935, decode.loss_dice: 3.3768, decode.acc_seg: 125.2425, loss: 249.3703
2024-06-20 13:26:16,798 - mmseg - INFO - Iter [250/20000]	lr: 3.285e-06, eta: 8:04:35, time: 1.464, data_time: 0.003, memory: 10079, decode.loss_mask: 87.2733, decode.loss_dice: 3.5003, decode.acc_seg: 138.7179, loss: 90.7737
2024-06-20 13:27:30,329 - mmseg - INFO - Iter [300/20000]	lr: 3.936e-06, eta: 8:03:16, time: 1.471, data_time: 0.003, memory: 10079, decode.loss_mask: 59.9432, decode.loss_dice: 3.7654, decode.acc_seg: 125.4816, loss: 63.7086
2024-06-20 13:28:44,320 - mmseg - INFO - Iter [350/20000]	lr: 4.584e-06, eta: 8:02:25, time: 1.480, data_time: 0.003, memory: 10079, decode.loss_mask: 58.7440, decode.loss_dice: 3.6623, decode.acc_seg: 155.7011, loss: 62.4063
2024-06-20 13:29:58,055 - mmseg - INFO - Iter [400/20000]	lr: 5.229e-06, eta: 8:01:15, time: 1.475, data_time: 0.003, memory: 10079, decode.loss_mask: 53.2099, decode.loss_dice: 3.7441, decode.acc_seg: 160.1607, loss: 56.9540
2024-06-20 13:31:11,899 - mmseg - INFO - Iter [450/20000]	lr: 5.872e-06, eta: 8:00:09, time: 1.477, data_time: 0.003, memory: 10079, decode.loss_mask: 62.1468, decode.loss_dice: 3.3888, decode.acc_seg: 186.5543, loss: 65.5356
2024-06-20 13:32:25,758 - mmseg - INFO - Iter [500/20000]	lr: 6.511e-06, eta: 7:59:02, time: 1.477, data_time: 0.003, memory: 10079, decode.loss_mask: 56.4439, decode.loss_dice: 3.6783, decode.acc_seg: 203.9286, loss: 60.1222
2024-06-20 13:33:39,182 - mmseg - INFO - Iter [550/20000]	lr: 7.148e-06, eta: 7:57:39, time: 1.468, data_time: 0.003, memory: 10079, decode.loss_mask: 54.3631, decode.loss_dice: 3.5362, decode.acc_seg: 236.0108, loss: 57.8993
2024-06-20 13:34:52,800 - mmseg - INFO - Iter [600/20000]	lr: 7.782e-06, eta: 7:56:23, time: 1.472, data_time: 0.003, memory: 10079, decode.loss_mask: 47.1977, decode.loss_dice: 3.7911, decode.acc_seg: 234.0304, loss: 50.9888
2024-06-20 13:36:05,891 - mmseg - INFO - Iter [650/20000]	lr: 8.413e-06, eta: 7:54:53, time: 1.462, data_time: 0.003, memory: 10079, decode.loss_mask: 56.8498, decode.loss_dice: 3.6193, decode.acc_seg: 198.1379, loss: 60.4691
2024-06-20 13:37:19,515 - mmseg - INFO - Iter [700/20000]	lr: 9.041e-06, eta: 7:53:39, time: 1.472, data_time: 0.003, memory: 10079, decode.loss_mask: 52.1712, decode.loss_dice: 3.6169, decode.acc_seg: 218.8286, loss: 55.7881
2024-06-20 13:38:32,691 - mmseg - INFO - Iter [750/20000]	lr: 9.666e-06, eta: 7:52:14, time: 1.464, data_time: 0.003, memory: 10079, decode.loss_mask: 47.5646, decode.loss_dice: 3.2980, decode.acc_seg: 227.0685, loss: 50.8626
2024-06-20 13:39:45,615 - mmseg - INFO - Iter [800/20000]	lr: 1.029e-05, eta: 7:50:44, time: 1.458, data_time: 0.003, memory: 10079, decode.loss_mask: 48.6818, decode.loss_dice: 3.3966, decode.acc_seg: 204.2964, loss: 52.0784
2024-06-20 13:40:58,925 - mmseg - INFO - Iter [850/20000]	lr: 1.091e-05, eta: 7:49:25, time: 1.466, data_time: 0.003, memory: 10079, decode.loss_mask: 46.8828, decode.loss_dice: 3.4892, decode.acc_seg: 228.9400, loss: 50.3720
2024-06-20 13:42:12,216 - mmseg - INFO - Iter [900/20000]	lr: 1.152e-05, eta: 7:48:06, time: 1.466, data_time: 0.003, memory: 10079, decode.loss_mask: 40.8287, decode.loss_dice: 3.5938, decode.acc_seg: 212.1559, loss: 44.4225
2024-06-20 13:43:25,852 - mmseg - INFO - Iter [950/20000]	lr: 1.214e-05, eta: 7:46:55, time: 1.473, data_time: 0.003, memory: 10079, decode.loss_mask: 47.2542, decode.loss_dice: 3.5073, decode.acc_seg: 246.1489, loss: 50.7615
2024-06-20 13:44:39,093 - mmseg - INFO - Exp name: xxscales_input_vpt_seg_zero_vit-b_512x512_20k_12_10.py
2024-06-20 13:44:39,093 - mmseg - INFO - Iter [1000/20000]	lr: 1.275e-05, eta: 7:45:36, time: 1.465, data_time: 0.003, memory: 10079, decode.loss_mask: 46.7959, decode.loss_dice: 3.4827, decode.acc_seg: 208.0507, loss: 50.2786
2024-06-20 13:45:52,275 - mmseg - INFO - Iter [1050/20000]	lr: 1.336e-05, eta: 7:44:16, time: 1.464, data_time: 0.003, memory: 10079, decode.loss_mask: 43.1001, decode.loss_dice: 3.3109, decode.acc_seg: 205.9525, loss: 46.4110
2024-06-20 13:47:06,120 - mmseg - INFO - Iter [1100/20000]	lr: 1.396e-05, eta: 7:43:09, time: 1.477, data_time: 0.003, memory: 10079, decode.loss_mask: 41.5393, decode.loss_dice: 3.4864, decode.acc_seg: 227.2653, loss: 45.0257
2024-06-20 13:48:20,671 - mmseg - INFO - Iter [1150/20000]	lr: 1.457e-05, eta: 7:42:12, time: 1.491, data_time: 0.003, memory: 10085, decode.loss_mask: 48.0375, decode.loss_dice: 3.3924, decode.acc_seg: 231.3200, loss: 51.4299
2024-06-20 13:49:35,521 - mmseg - INFO - Iter [1200/20000]	lr: 1.516e-05, eta: 7:41:19, time: 1.497, data_time: 0.003, memory: 10085, decode.loss_mask: 43.8820, decode.loss_dice: 3.4473, decode.acc_seg: 218.7270, loss: 47.3293
2024-06-20 13:50:50,855 - mmseg - INFO - Iter [1250/20000]	lr: 1.576e-05, eta: 7:40:31, time: 1.507, data_time: 0.003, memory: 10085, decode.loss_mask: 39.9932, decode.loss_dice: 3.4162, decode.acc_seg: 215.4871, loss: 43.4094
2024-06-20 13:52:06,121 - mmseg - INFO - Iter [1300/20000]	lr: 1.635e-05, eta: 7:39:40, time: 1.505, data_time: 0.003, memory: 10085, decode.loss_mask: 45.3569, decode.loss_dice: 3.3292, decode.acc_seg: 247.7678, loss: 48.6861
2024-06-20 13:53:21,135 - mmseg - INFO - Iter [1350/20000]	lr: 1.695e-05, eta: 7:38:44, time: 1.500, data_time: 0.003, memory: 10085, decode.loss_mask: 40.5345, decode.loss_dice: 3.3426, decode.acc_seg: 260.3767, loss: 43.8772
2024-06-20 13:54:36,377 - mmseg - INFO - Iter [1400/20000]	lr: 1.753e-05, eta: 7:37:49, time: 1.505, data_time: 0.003, memory: 10093, decode.loss_mask: 39.0479, decode.loss_dice: 3.1764, decode.acc_seg: 292.7416, loss: 42.2243
2024-06-20 13:55:51,505 - mmseg - INFO - Iter [1450/20000]	lr: 1.812e-05, eta: 7:36:52, time: 1.503, data_time: 0.003, memory: 10093, decode.loss_mask: 44.5518, decode.loss_dice: 3.2988, decode.acc_seg: 256.2072, loss: 47.8506
2024-06-20 13:57:06,837 - mmseg - INFO - Iter [1500/20000]	lr: 1.870e-05, eta: 7:35:56, time: 1.507, data_time: 0.003, memory: 10093, decode.loss_mask: 35.8205, decode.loss_dice: 3.4379, decode.acc_seg: 250.7193, loss: 39.2584
2024-06-20 13:58:21,809 - mmseg - INFO - Iter [1550/20000]	lr: 1.867e-05, eta: 7:34:54, time: 1.499, data_time: 0.003, memory: 10093, decode.loss_mask: 37.3826, decode.loss_dice: 3.1206, decode.acc_seg: 282.1831, loss: 40.5032
2024-06-20 13:59:37,375 - mmseg - INFO - Iter [1600/20000]	lr: 1.863e-05, eta: 7:33:58, time: 1.511, data_time: 0.003, memory: 10093, decode.loss_mask: 35.9688, decode.loss_dice: 3.4538, decode.acc_seg: 264.4381, loss: 39.4225
2024-06-20 14:00:52,137 - mmseg - INFO - Iter [1650/20000]	lr: 1.858e-05, eta: 7:32:53, time: 1.495, data_time: 0.004, memory: 10093, decode.loss_mask: 38.2477, decode.loss_dice: 3.1784, decode.acc_seg: 253.4411, loss: 41.4261
2024-06-20 14:02:07,395 - mmseg - INFO - Iter [1700/20000]	lr: 1.854e-05, eta: 7:31:52, time: 1.505, data_time: 0.004, memory: 10093, decode.loss_mask: 30.3536, decode.loss_dice: 3.0706, decode.acc_seg: 290.6630, loss: 33.4243
2024-06-20 14:03:22,679 - mmseg - INFO - Iter [1750/20000]	lr: 1.850e-05, eta: 7:30:50, time: 1.506, data_time: 0.004, memory: 10093, decode.loss_mask: 40.7656, decode.loss_dice: 3.2414, decode.acc_seg: 257.2879, loss: 44.0070
2024-06-20 14:04:38,010 - mmseg - INFO - Iter [1800/20000]	lr: 1.845e-05, eta: 7:29:48, time: 1.507, data_time: 0.004, memory: 10093, decode.loss_mask: 33.9906, decode.loss_dice: 3.1975, decode.acc_seg: 278.6183, loss: 37.1881
2024-06-20 14:05:52,610 - mmseg - INFO - Iter [1850/20000]	lr: 1.841e-05, eta: 7:28:39, time: 1.492, data_time: 0.003, memory: 10093, decode.loss_mask: 32.0971, decode.loss_dice: 3.1115, decode.acc_seg: 264.4834, loss: 35.2086
2024-06-20 14:07:07,681 - mmseg - INFO - Iter [1900/20000]	lr: 1.837e-05, eta: 7:27:33, time: 1.501, data_time: 0.003, memory: 10093, decode.loss_mask: 31.0141, decode.loss_dice: 3.2665, decode.acc_seg: 270.0006, loss: 34.2806
2024-06-20 14:08:22,748 - mmseg - INFO - Iter [1950/20000]	lr: 1.833e-05, eta: 7:26:27, time: 1.501, data_time: 0.003, memory: 10093, decode.loss_mask: 33.9362, decode.loss_dice: 3.2676, decode.acc_seg: 286.4022, loss: 37.2038
2024-06-20 14:09:37,773 - mmseg - INFO - Saving checkpoint at 2000 iterations
2024-06-20 14:09:38,742 - mmseg - INFO - Exp name: xxscales_input_vpt_seg_zero_vit-b_512x512_20k_12_10.py
2024-06-20 14:09:38,742 - mmseg - INFO - Iter [2000/20000]	lr: 1.828e-05, eta: 7:25:29, time: 1.520, data_time: 0.003, memory: 10093, decode.loss_mask: 38.7886, decode.loss_dice: 3.3062, decode.acc_seg: 241.8596, loss: 42.0948
2024-06-20 14:10:53,422 - mmseg - INFO - Iter [2050/20000]	lr: 1.824e-05, eta: 7:24:19, time: 1.494, data_time: 0.003, memory: 10093, decode.loss_mask: 29.4892, decode.loss_dice: 3.2490, decode.acc_seg: 289.4223, loss: 32.7382
2024-06-20 14:12:08,629 - mmseg - INFO - Iter [2100/20000]	lr: 1.820e-05, eta: 7:23:13, time: 1.504, data_time: 0.003, memory: 10093, decode.loss_mask: 31.9985, decode.loss_dice: 3.0659, decode.acc_seg: 294.2029, loss: 35.0644
2024-06-20 14:13:23,889 - mmseg - INFO - Iter [2150/20000]	lr: 1.815e-05, eta: 7:22:06, time: 1.505, data_time: 0.003, memory: 10093, decode.loss_mask: 32.7449, decode.loss_dice: 3.2284, decode.acc_seg: 274.1985, loss: 35.9732
2024-06-20 14:14:38,948 - mmseg - INFO - Iter [2200/20000]	lr: 1.811e-05, eta: 7:20:58, time: 1.501, data_time: 0.003, memory: 10093, decode.loss_mask: 33.7938, decode.loss_dice: 3.0421, decode.acc_seg: 298.2223, loss: 36.8359
2024-06-20 14:15:54,272 - mmseg - INFO - Iter [2250/20000]	lr: 1.807e-05, eta: 7:19:52, time: 1.506, data_time: 0.003, memory: 10093, decode.loss_mask: 28.8103, decode.loss_dice: 3.1790, decode.acc_seg: 290.6571, loss: 31.9893
2024-06-20 14:17:09,372 - mmseg - INFO - Iter [2300/20000]	lr: 1.802e-05, eta: 7:18:43, time: 1.502, data_time: 0.003, memory: 10093, decode.loss_mask: 32.8598, decode.loss_dice: 3.1947, decode.acc_seg: 296.9820, loss: 36.0544
2024-06-20 14:18:24,496 - mmseg - INFO - Iter [2350/20000]	lr: 1.798e-05, eta: 7:17:35, time: 1.502, data_time: 0.003, memory: 10093, decode.loss_mask: 36.9951, decode.loss_dice: 3.3294, decode.acc_seg: 289.0693, loss: 40.3244
2024-06-20 14:19:40,009 - mmseg - INFO - Iter [2400/20000]	lr: 1.794e-05, eta: 7:16:29, time: 1.510, data_time: 0.003, memory: 10093, decode.loss_mask: 30.6221, decode.loss_dice: 3.0193, decode.acc_seg: 310.7287, loss: 33.6414
2024-06-20 14:20:55,519 - mmseg - INFO - Iter [2450/20000]	lr: 1.789e-05, eta: 7:15:22, time: 1.510, data_time: 0.003, memory: 10093, decode.loss_mask: 28.5907, decode.loss_dice: 3.2323, decode.acc_seg: 321.0090, loss: 31.8230
2024-06-20 14:22:10,845 - mmseg - INFO - Iter [2500/20000]	lr: 1.785e-05, eta: 7:14:14, time: 1.506, data_time: 0.003, memory: 10093, decode.loss_mask: 24.6640, decode.loss_dice: 3.1816, decode.acc_seg: 356.4296, loss: 27.8456
2024-06-20 14:23:25,947 - mmseg - INFO - Iter [2550/20000]	lr: 1.781e-05, eta: 7:13:04, time: 1.502, data_time: 0.003, memory: 10093, decode.loss_mask: 28.7750, decode.loss_dice: 3.0992, decode.acc_seg: 346.7284, loss: 31.8741
2024-06-20 14:24:40,730 - mmseg - INFO - Iter [2600/20000]	lr: 1.776e-05, eta: 7:11:52, time: 1.496, data_time: 0.003, memory: 10093, decode.loss_mask: 27.2977, decode.loss_dice: 3.2169, decode.acc_seg: 353.1269, loss: 30.5146
2024-06-20 14:25:55,525 - mmseg - INFO - Iter [2650/20000]	lr: 1.772e-05, eta: 7:10:40, time: 1.496, data_time: 0.003, memory: 10093, decode.loss_mask: 30.0108, decode.loss_dice: 3.2264, decode.acc_seg: 329.0390, loss: 33.2371
2024-06-20 14:27:08,808 - mmseg - INFO - Iter [2700/20000]	lr: 1.768e-05, eta: 7:09:17, time: 1.466, data_time: 0.003, memory: 10093, decode.loss_mask: 27.4076, decode.loss_dice: 2.9169, decode.acc_seg: 347.8638, loss: 30.3246
2024-06-20 14:28:23,450 - mmseg - INFO - Iter [2750/20000]	lr: 1.763e-05, eta: 7:08:04, time: 1.493, data_time: 0.003, memory: 10093, decode.loss_mask: 27.0049, decode.loss_dice: 3.0174, decode.acc_seg: 364.0518, loss: 30.0223
2024-06-20 14:29:37,964 - mmseg - INFO - Iter [2800/20000]	lr: 1.759e-05, eta: 7:06:50, time: 1.490, data_time: 0.003, memory: 10093, decode.loss_mask: 24.5738, decode.loss_dice: 2.8048, decode.acc_seg: 370.5865, loss: 27.3786
2024-06-20 14:30:52,721 - mmseg - INFO - Iter [2850/20000]	lr: 1.755e-05, eta: 7:05:38, time: 1.495, data_time: 0.003, memory: 10093, decode.loss_mask: 24.6192, decode.loss_dice: 2.9931, decode.acc_seg: 368.0780, loss: 27.6123
2024-06-20 14:32:07,905 - mmseg - INFO - Iter [2900/20000]	lr: 1.750e-05, eta: 7:04:27, time: 1.504, data_time: 0.003, memory: 10093, decode.loss_mask: 25.2807, decode.loss_dice: 2.9983, decode.acc_seg: 367.0694, loss: 28.2790
2024-06-20 14:33:23,113 - mmseg - INFO - Iter [2950/20000]	lr: 1.746e-05, eta: 7:03:17, time: 1.504, data_time: 0.003, memory: 10093, decode.loss_mask: 25.9628, decode.loss_dice: 3.1365, decode.acc_seg: 351.5162, loss: 29.0993
2024-06-20 14:34:38,339 - mmseg - INFO - Exp name: xxscales_input_vpt_seg_zero_vit-b_512x512_20k_12_10.py
2024-06-20 14:34:38,340 - mmseg - INFO - Iter [3000/20000]	lr: 1.742e-05, eta: 7:02:07, time: 1.505, data_time: 0.003, memory: 10093, decode.loss_mask: 25.7436, decode.loss_dice: 3.0326, decode.acc_seg: 357.9861, loss: 28.7761
2024-06-20 14:35:55,475 - mmseg - INFO - Iter [3050/20000]	lr: 1.737e-05, eta: 7:01:07, time: 1.543, data_time: 0.044, memory: 10093, decode.loss_mask: 23.6289, decode.loss_dice: 2.8516, decode.acc_seg: 386.3873, loss: 26.4805
2024-06-20 14:37:10,185 - mmseg - INFO - Iter [3100/20000]	lr: 1.733e-05, eta: 6:59:54, time: 1.494, data_time: 0.003, memory: 10093, decode.loss_mask: 23.1547, decode.loss_dice: 2.9158, decode.acc_seg: 374.8011, loss: 26.0705
2024-06-20 14:38:24,974 - mmseg - INFO - Iter [3150/20000]	lr: 1.729e-05, eta: 6:58:40, time: 1.496, data_time: 0.003, memory: 10093, decode.loss_mask: 21.9199, decode.loss_dice: 3.0199, decode.acc_seg: 394.6011, loss: 24.9398
2024-06-20 14:39:40,272 - mmseg - INFO - Iter [3200/20000]	lr: 1.724e-05, eta: 6:57:30, time: 1.506, data_time: 0.003, memory: 10093, decode.loss_mask: 21.7741, decode.loss_dice: 2.9271, decode.acc_seg: 382.0703, loss: 24.7012
2024-06-20 14:40:55,382 - mmseg - INFO - Iter [3250/20000]	lr: 1.720e-05, eta: 6:56:18, time: 1.502, data_time: 0.003, memory: 10093, decode.loss_mask: 22.4836, decode.loss_dice: 2.9597, decode.acc_seg: 397.2072, loss: 25.4433
2024-06-20 14:42:10,176 - mmseg - INFO - Iter [3300/20000]	lr: 1.715e-05, eta: 6:55:05, time: 1.496, data_time: 0.003, memory: 10093, decode.loss_mask: 25.4067, decode.loss_dice: 3.0536, decode.acc_seg: 386.0654, loss: 28.4604
2024-06-20 14:43:25,338 - mmseg - INFO - Iter [3350/20000]	lr: 1.711e-05, eta: 6:53:53, time: 1.503, data_time: 0.003, memory: 10093, decode.loss_mask: 20.5866, decode.loss_dice: 2.9377, decode.acc_seg: 398.7163, loss: 23.5243
2024-06-20 14:44:40,287 - mmseg - INFO - Iter [3400/20000]	lr: 1.707e-05, eta: 6:52:40, time: 1.499, data_time: 0.003, memory: 10093, decode.loss_mask: 20.0066, decode.loss_dice: 2.9123, decode.acc_seg: 403.0285, loss: 22.9189
2024-06-20 14:45:55,802 - mmseg - INFO - Iter [3450/20000]	lr: 1.702e-05, eta: 6:51:30, time: 1.510, data_time: 0.003, memory: 10093, decode.loss_mask: 26.7271, decode.loss_dice: 2.9125, decode.acc_seg: 374.2055, loss: 29.6395
2024-06-20 14:47:10,721 - mmseg - INFO - Iter [3500/20000]	lr: 1.698e-05, eta: 6:50:17, time: 1.498, data_time: 0.003, memory: 10093, decode.loss_mask: 23.7594, decode.loss_dice: 2.8441, decode.acc_seg: 400.1309, loss: 26.6035
2024-06-20 14:48:26,098 - mmseg - INFO - Iter [3550/20000]	lr: 1.694e-05, eta: 6:49:06, time: 1.508, data_time: 0.003, memory: 10093, decode.loss_mask: 21.0662, decode.loss_dice: 2.7639, decode.acc_seg: 404.4592, loss: 23.8302
2024-06-20 14:49:41,008 - mmseg - INFO - Iter [3600/20000]	lr: 1.689e-05, eta: 6:47:53, time: 1.498, data_time: 0.003, memory: 10093, decode.loss_mask: 19.5940, decode.loss_dice: 3.1535, decode.acc_seg: 406.7959, loss: 22.7475
2024-06-20 14:50:56,072 - mmseg - INFO - Iter [3650/20000]	lr: 1.685e-05, eta: 6:46:40, time: 1.501, data_time: 0.003, memory: 10093, decode.loss_mask: 20.5382, decode.loss_dice: 2.7152, decode.acc_seg: 411.8876, loss: 23.2534
2024-06-20 14:52:10,573 - mmseg - INFO - Iter [3700/20000]	lr: 1.681e-05, eta: 6:45:25, time: 1.490, data_time: 0.004, memory: 10093, decode.loss_mask: 20.9469, decode.loss_dice: 2.6453, decode.acc_seg: 413.9623, loss: 23.5922
2024-06-20 14:53:25,970 - mmseg - INFO - Iter [3750/20000]	lr: 1.676e-05, eta: 6:44:14, time: 1.508, data_time: 0.003, memory: 10093, decode.loss_mask: 23.7919, decode.loss_dice: 2.8224, decode.acc_seg: 409.3205, loss: 26.6143
2024-06-20 14:54:41,015 - mmseg - INFO - Iter [3800/20000]	lr: 1.672e-05, eta: 6:43:01, time: 1.501, data_time: 0.003, memory: 10093, decode.loss_mask: 23.8876, decode.loss_dice: 3.0629, decode.acc_seg: 403.8777, loss: 26.9505
2024-06-20 14:55:56,649 - mmseg - INFO - Iter [3850/20000]	lr: 1.667e-05, eta: 6:41:51, time: 1.513, data_time: 0.003, memory: 10099, decode.loss_mask: 19.9794, decode.loss_dice: 2.9377, decode.acc_seg: 413.2962, loss: 22.9171
2024-06-20 14:57:11,856 - mmseg - INFO - Iter [3900/20000]	lr: 1.663e-05, eta: 6:40:38, time: 1.504, data_time: 0.003, memory: 10099, decode.loss_mask: 17.5474, decode.loss_dice: 2.6589, decode.acc_seg: 424.6548, loss: 20.2063
2024-06-20 14:58:27,102 - mmseg - INFO - Iter [3950/20000]	lr: 1.659e-05, eta: 6:39:26, time: 1.505, data_time: 0.003, memory: 10099, decode.loss_mask: 18.9259, decode.loss_dice: 2.6930, decode.acc_seg: 421.5565, loss: 21.6189
2024-06-20 14:59:42,490 - mmseg - INFO - Saving checkpoint at 4000 iterations
2024-06-20 14:59:43,432 - mmseg - INFO - Exp name: xxscales_input_vpt_seg_zero_vit-b_512x512_20k_12_10.py
2024-06-20 14:59:43,433 - mmseg - INFO - Iter [4000/20000]	lr: 1.654e-05, eta: 6:38:18, time: 1.527, data_time: 0.003, memory: 10099, decode.loss_mask: 19.1692, decode.loss_dice: 2.7791, decode.acc_seg: 420.6346, loss: 21.9483
2024-06-20 15:00:58,298 - mmseg - INFO - Iter [4050/20000]	lr: 1.650e-05, eta: 6:37:04, time: 1.497, data_time: 0.003, memory: 10099, decode.loss_mask: 19.7474, decode.loss_dice: 2.7151, decode.acc_seg: 413.3925, loss: 22.4625
2024-06-20 15:02:13,344 - mmseg - INFO - Iter [4100/20000]	lr: 1.646e-05, eta: 6:35:51, time: 1.501, data_time: 0.003, memory: 10099, decode.loss_mask: 20.6478, decode.loss_dice: 2.8612, decode.acc_seg: 411.3727, loss: 23.5090
2024-06-20 15:03:28,338 - mmseg - INFO - Iter [4150/20000]	lr: 1.641e-05, eta: 6:34:37, time: 1.500, data_time: 0.003, memory: 10099, decode.loss_mask: 19.1222, decode.loss_dice: 2.9106, decode.acc_seg: 402.1660, loss: 22.0328
2024-06-20 15:04:43,703 - mmseg - INFO - Iter [4200/20000]	lr: 1.637e-05, eta: 6:33:25, time: 1.507, data_time: 0.003, memory: 10099, decode.loss_mask: 16.2830, decode.loss_dice: 2.8906, decode.acc_seg: 422.2314, loss: 19.1736
2024-06-20 15:05:58,361 - mmseg - INFO - Iter [4250/20000]	lr: 1.633e-05, eta: 6:32:10, time: 1.493, data_time: 0.003, memory: 10099, decode.loss_mask: 20.8406, decode.loss_dice: 2.5661, decode.acc_seg: 405.9219, loss: 23.4067
2024-06-20 15:07:12,401 - mmseg - INFO - Iter [4300/20000]	lr: 1.628e-05, eta: 6:30:53, time: 1.481, data_time: 0.003, memory: 10099, decode.loss_mask: 21.7560, decode.loss_dice: 2.8173, decode.acc_seg: 406.5230, loss: 24.5733
2024-06-20 15:08:28,036 - mmseg - INFO - Iter [4350/20000]	lr: 1.624e-05, eta: 6:29:42, time: 1.513, data_time: 0.003, memory: 10099, decode.loss_mask: 18.0590, decode.loss_dice: 2.7930, decode.acc_seg: 402.9508, loss: 20.8520
2024-06-20 15:09:43,388 - mmseg - INFO - Iter [4400/20000]	lr: 1.619e-05, eta: 6:28:29, time: 1.507, data_time: 0.003, memory: 10099, decode.loss_mask: 16.7098, decode.loss_dice: 2.8966, decode.acc_seg: 423.3424, loss: 19.6064
2024-06-20 15:10:58,327 - mmseg - INFO - Iter [4450/20000]	lr: 1.615e-05, eta: 6:27:16, time: 1.499, data_time: 0.003, memory: 10099, decode.loss_mask: 16.7367, decode.loss_dice: 2.6440, decode.acc_seg: 428.9281, loss: 19.3807
2024-06-20 15:12:13,290 - mmseg - INFO - Iter [4500/20000]	lr: 1.611e-05, eta: 6:26:02, time: 1.499, data_time: 0.003, memory: 10099, decode.loss_mask: 16.2261, decode.loss_dice: 2.7075, decode.acc_seg: 426.3766, loss: 18.9336
2024-06-20 15:13:28,610 - mmseg - INFO - Iter [4550/20000]	lr: 1.606e-05, eta: 6:24:49, time: 1.506, data_time: 0.003, memory: 10099, decode.loss_mask: 17.1405, decode.loss_dice: 2.5898, decode.acc_seg: 426.9965, loss: 19.7302
2024-06-20 15:14:43,788 - mmseg - INFO - Iter [4600/20000]	lr: 1.602e-05, eta: 6:23:36, time: 1.504, data_time: 0.003, memory: 10099, decode.loss_mask: 18.7855, decode.loss_dice: 2.8053, decode.acc_seg: 411.6580, loss: 21.5908
2024-06-20 15:15:58,604 - mmseg - INFO - Iter [4650/20000]	lr: 1.597e-05, eta: 6:22:21, time: 1.496, data_time: 0.003, memory: 10099, decode.loss_mask: 16.1690, decode.loss_dice: 2.8552, decode.acc_seg: 424.2311, loss: 19.0242
2024-06-20 15:17:14,029 - mmseg - INFO - Iter [4700/20000]	lr: 1.593e-05, eta: 6:21:09, time: 1.508, data_time: 0.003, memory: 10099, decode.loss_mask: 17.6005, decode.loss_dice: 2.8179, decode.acc_seg: 416.4703, loss: 20.4184
2024-06-20 15:18:29,290 - mmseg - INFO - Iter [4750/20000]	lr: 1.589e-05, eta: 6:19:56, time: 1.505, data_time: 0.003, memory: 10099, decode.loss_mask: 14.5263, decode.loss_dice: 2.5964, decode.acc_seg: 431.3646, loss: 17.1227
2024-06-20 15:19:44,367 - mmseg - INFO - Iter [4800/20000]	lr: 1.584e-05, eta: 6:18:42, time: 1.502, data_time: 0.003, memory: 10099, decode.loss_mask: 20.3813, decode.loss_dice: 2.7986, decode.acc_seg: 405.6207, loss: 23.1799
2024-06-20 15:20:59,267 - mmseg - INFO - Iter [4850/20000]	lr: 1.580e-05, eta: 6:17:28, time: 1.498, data_time: 0.003, memory: 10099, decode.loss_mask: 15.7500, decode.loss_dice: 2.8391, decode.acc_seg: 425.2988, loss: 18.5892
2024-06-20 15:22:14,190 - mmseg - INFO - Iter [4900/20000]	lr: 1.575e-05, eta: 6:16:14, time: 1.498, data_time: 0.003, memory: 10099, decode.loss_mask: 14.1751, decode.loss_dice: 2.8503, decode.acc_seg: 431.0273, loss: 17.0254
2024-06-20 15:23:29,323 - mmseg - INFO - Iter [4950/20000]	lr: 1.571e-05, eta: 6:15:00, time: 1.503, data_time: 0.003, memory: 10099, decode.loss_mask: 16.9377, decode.loss_dice: 2.9192, decode.acc_seg: 418.3679, loss: 19.8570
2024-06-20 15:24:44,265 - mmseg - INFO - Exp name: xxscales_input_vpt_seg_zero_vit-b_512x512_20k_12_10.py
2024-06-20 15:24:44,266 - mmseg - INFO - Iter [5000/20000]	lr: 1.567e-05, eta: 6:13:46, time: 1.499, data_time: 0.003, memory: 10099, decode.loss_mask: 17.5471, decode.loss_dice: 2.6580, decode.acc_seg: 432.7492, loss: 20.2051
2024-06-20 15:25:59,534 - mmseg - INFO - Iter [5050/20000]	lr: 1.562e-05, eta: 6:12:33, time: 1.505, data_time: 0.003, memory: 10099, decode.loss_mask: 17.3323, decode.loss_dice: 2.7674, decode.acc_seg: 416.5588, loss: 20.0997
2024-06-20 15:27:14,982 - mmseg - INFO - Iter [5100/20000]	lr: 1.558e-05, eta: 6:11:20, time: 1.509, data_time: 0.003, memory: 10099, decode.loss_mask: 16.1085, decode.loss_dice: 2.6355, decode.acc_seg: 427.8689, loss: 18.7440
2024-06-20 15:28:30,794 - mmseg - INFO - Iter [5150/20000]	lr: 1.553e-05, eta: 6:10:08, time: 1.516, data_time: 0.003, memory: 10099, decode.loss_mask: 15.0195, decode.loss_dice: 2.8478, decode.acc_seg: 416.2277, loss: 17.8673
2024-06-20 15:29:46,398 - mmseg - INFO - Iter [5200/20000]	lr: 1.549e-05, eta: 6:08:56, time: 1.512, data_time: 0.003, memory: 10099, decode.loss_mask: 15.5485, decode.loss_dice: 2.5260, decode.acc_seg: 435.2737, loss: 18.0745
2024-06-20 15:31:02,124 - mmseg - INFO - Iter [5250/20000]	lr: 1.545e-05, eta: 6:07:44, time: 1.514, data_time: 0.003, memory: 10099, decode.loss_mask: 18.9934, decode.loss_dice: 2.6694, decode.acc_seg: 422.2736, loss: 21.6628
2024-06-20 15:32:17,485 - mmseg - INFO - Iter [5300/20000]	lr: 1.540e-05, eta: 6:06:30, time: 1.507, data_time: 0.004, memory: 10099, decode.loss_mask: 15.1701, decode.loss_dice: 2.7407, decode.acc_seg: 429.4618, loss: 17.9108
2024-06-20 15:33:33,052 - mmseg - INFO - Iter [5350/20000]	lr: 1.536e-05, eta: 6:05:18, time: 1.511, data_time: 0.004, memory: 10099, decode.loss_mask: 17.0629, decode.loss_dice: 2.6257, decode.acc_seg: 430.3523, loss: 19.6886
2024-06-20 15:34:48,044 - mmseg - INFO - Iter [5400/20000]	lr: 1.531e-05, eta: 6:04:03, time: 1.500, data_time: 0.004, memory: 10099, decode.loss_mask: 18.6779, decode.loss_dice: 2.7818, decode.acc_seg: 415.0103, loss: 21.4597
2024-06-20 15:36:03,731 - mmseg - INFO - Iter [5450/20000]	lr: 1.527e-05, eta: 6:02:51, time: 1.514, data_time: 0.004, memory: 10099, decode.loss_mask: 14.4044, decode.loss_dice: 2.6772, decode.acc_seg: 428.2838, loss: 17.0816
2024-06-20 15:37:19,252 - mmseg - INFO - Iter [5500/20000]	lr: 1.523e-05, eta: 6:01:38, time: 1.510, data_time: 0.004, memory: 10099, decode.loss_mask: 15.7697, decode.loss_dice: 2.4974, decode.acc_seg: 432.4291, loss: 18.2671
2024-06-20 15:38:34,539 - mmseg - INFO - Iter [5550/20000]	lr: 1.518e-05, eta: 6:00:24, time: 1.506, data_time: 0.004, memory: 10102, decode.loss_mask: 16.7045, decode.loss_dice: 2.7663, decode.acc_seg: 430.7184, loss: 19.4709
2024-06-20 15:39:49,587 - mmseg - INFO - Iter [5600/20000]	lr: 1.514e-05, eta: 5:59:10, time: 1.501, data_time: 0.004, memory: 10102, decode.loss_mask: 15.4086, decode.loss_dice: 2.6847, decode.acc_seg: 425.4191, loss: 18.0933
2024-06-20 15:41:04,458 - mmseg - INFO - Iter [5650/20000]	lr: 1.509e-05, eta: 5:57:55, time: 1.497, data_time: 0.004, memory: 10102, decode.loss_mask: 13.8786, decode.loss_dice: 2.7020, decode.acc_seg: 425.2683, loss: 16.5806
2024-06-20 15:42:19,668 - mmseg - INFO - Iter [5700/20000]	lr: 1.505e-05, eta: 5:56:42, time: 1.504, data_time: 0.004, memory: 10102, decode.loss_mask: 18.8375, decode.loss_dice: 2.7672, decode.acc_seg: 419.7774, loss: 21.6047
2024-06-20 15:43:34,700 - mmseg - INFO - Iter [5750/20000]	lr: 1.501e-05, eta: 5:55:27, time: 1.501, data_time: 0.004, memory: 10102, decode.loss_mask: 13.2172, decode.loss_dice: 2.6582, decode.acc_seg: 441.4438, loss: 15.8754
2024-06-20 15:44:49,543 - mmseg - INFO - Iter [5800/20000]	lr: 1.496e-05, eta: 5:54:12, time: 1.497, data_time: 0.004, memory: 10102, decode.loss_mask: 16.0346, decode.loss_dice: 2.6958, decode.acc_seg: 432.6765, loss: 18.7304
2024-06-20 15:46:03,589 - mmseg - INFO - Iter [5850/20000]	lr: 1.492e-05, eta: 5:52:56, time: 1.481, data_time: 0.004, memory: 10102, decode.loss_mask: 18.5883, decode.loss_dice: 2.7421, decode.acc_seg: 425.7319, loss: 21.3305
2024-06-20 15:47:18,028 - mmseg - INFO - Iter [5900/20000]	lr: 1.487e-05, eta: 5:51:40, time: 1.489, data_time: 0.004, memory: 10102, decode.loss_mask: 18.2110, decode.loss_dice: 2.9207, decode.acc_seg: 411.2620, loss: 21.1317
2024-06-20 15:48:33,253 - mmseg - INFO - Iter [5950/20000]	lr: 1.483e-05, eta: 5:50:26, time: 1.504, data_time: 0.003, memory: 10102, decode.loss_mask: 18.4486, decode.loss_dice: 2.5477, decode.acc_seg: 430.5804, loss: 20.9964
2024-06-20 15:49:48,422 - mmseg - INFO - Saving checkpoint at 6000 iterations
2024-06-20 15:49:49,407 - mmseg - INFO - Exp name: xxscales_input_vpt_seg_zero_vit-b_512x512_20k_12_10.py
2024-06-20 15:49:49,407 - mmseg - INFO - Iter [6000/20000]	lr: 1.478e-05, eta: 5:49:14, time: 1.523, data_time: 0.003, memory: 10102, decode.loss_mask: 18.2229, decode.loss_dice: 2.7445, decode.acc_seg: 419.0257, loss: 20.9674
2024-06-20 15:51:06,816 - mmseg - INFO - Iter [6050/20000]	lr: 1.474e-05, eta: 5:48:05, time: 1.548, data_time: 0.044, memory: 10102, decode.loss_mask: 15.8458, decode.loss_dice: 2.3707, decode.acc_seg: 422.1804, loss: 18.2165
2024-06-20 15:52:22,218 - mmseg - INFO - Iter [6100/20000]	lr: 1.470e-05, eta: 5:46:52, time: 1.508, data_time: 0.003, memory: 10102, decode.loss_mask: 17.1689, decode.loss_dice: 2.8461, decode.acc_seg: 416.7523, loss: 20.0150
2024-06-20 15:53:37,698 - mmseg - INFO - Iter [6150/20000]	lr: 1.465e-05, eta: 5:45:38, time: 1.510, data_time: 0.003, memory: 10102, decode.loss_mask: 17.7470, decode.loss_dice: 2.9837, decode.acc_seg: 414.3099, loss: 20.7306
2024-06-20 15:54:52,854 - mmseg - INFO - Iter [6200/20000]	lr: 1.461e-05, eta: 5:44:24, time: 1.503, data_time: 0.003, memory: 10102, decode.loss_mask: 18.4416, decode.loss_dice: 2.4589, decode.acc_seg: 425.4081, loss: 20.9005
2024-06-20 15:56:08,185 - mmseg - INFO - Iter [6250/20000]	lr: 1.456e-05, eta: 5:43:10, time: 1.507, data_time: 0.003, memory: 10102, decode.loss_mask: 16.2206, decode.loss_dice: 2.8690, decode.acc_seg: 423.0548, loss: 19.0897
2024-06-20 15:57:23,167 - mmseg - INFO - Iter [6300/20000]	lr: 1.452e-05, eta: 5:41:55, time: 1.500, data_time: 0.003, memory: 10102, decode.loss_mask: 13.9829, decode.loss_dice: 2.6723, decode.acc_seg: 438.1784, loss: 16.6552
2024-06-20 15:58:38,327 - mmseg - INFO - Iter [6350/20000]	lr: 1.447e-05, eta: 5:40:41, time: 1.503, data_time: 0.003, memory: 10102, decode.loss_mask: 15.3263, decode.loss_dice: 2.6276, decode.acc_seg: 433.5825, loss: 17.9539
2024-06-20 15:59:53,287 - mmseg - INFO - Iter [6400/20000]	lr: 1.443e-05, eta: 5:39:27, time: 1.499, data_time: 0.003, memory: 10102, decode.loss_mask: 16.7815, decode.loss_dice: 2.7048, decode.acc_seg: 425.3058, loss: 19.4863
2024-06-20 16:01:08,157 - mmseg - INFO - Iter [6450/20000]	lr: 1.438e-05, eta: 5:38:12, time: 1.497, data_time: 0.003, memory: 10102, decode.loss_mask: 20.9766, decode.loss_dice: 2.7915, decode.acc_seg: 419.4826, loss: 23.7681
2024-06-20 16:02:23,799 - mmseg - INFO - Iter [6500/20000]	lr: 1.434e-05, eta: 5:36:58, time: 1.513, data_time: 0.003, memory: 10102, decode.loss_mask: 15.6438, decode.loss_dice: 2.6153, decode.acc_seg: 441.0817, loss: 18.2591
2024-06-20 16:03:39,479 - mmseg - INFO - Iter [6550/20000]	lr: 1.430e-05, eta: 5:35:45, time: 1.514, data_time: 0.003, memory: 10102, decode.loss_mask: 15.2462, decode.loss_dice: 2.6359, decode.acc_seg: 426.9875, loss: 17.8821
2024-06-20 16:04:54,719 - mmseg - INFO - Iter [6600/20000]	lr: 1.425e-05, eta: 5:34:31, time: 1.505, data_time: 0.003, memory: 10102, decode.loss_mask: 16.1705, decode.loss_dice: 2.4816, decode.acc_seg: 429.8372, loss: 18.6521
2024-06-20 16:06:10,264 - mmseg - INFO - Iter [6650/20000]	lr: 1.421e-05, eta: 5:33:17, time: 1.511, data_time: 0.003, memory: 10102, decode.loss_mask: 15.3907, decode.loss_dice: 2.4633, decode.acc_seg: 432.2349, loss: 17.8540
2024-06-20 16:07:25,365 - mmseg - INFO - Iter [6700/20000]	lr: 1.416e-05, eta: 5:32:03, time: 1.502, data_time: 0.003, memory: 10102, decode.loss_mask: 13.1509, decode.loss_dice: 2.3544, decode.acc_seg: 440.2569, loss: 15.5054
2024-06-20 16:08:40,001 - mmseg - INFO - Iter [6750/20000]	lr: 1.412e-05, eta: 5:30:47, time: 1.493, data_time: 0.003, memory: 10102, decode.loss_mask: 15.4823, decode.loss_dice: 2.5871, decode.acc_seg: 432.6033, loss: 18.0694
2024-06-20 16:09:54,966 - mmseg - INFO - Iter [6800/20000]	lr: 1.407e-05, eta: 5:29:33, time: 1.499, data_time: 0.003, memory: 10102, decode.loss_mask: 17.5089, decode.loss_dice: 2.4699, decode.acc_seg: 436.5127, loss: 19.9788
2024-06-20 16:11:10,372 - mmseg - INFO - Iter [6850/20000]	lr: 1.403e-05, eta: 5:28:19, time: 1.508, data_time: 0.003, memory: 10102, decode.loss_mask: 18.9506, decode.loss_dice: 2.7288, decode.acc_seg: 420.2575, loss: 21.6794
2024-06-20 16:12:25,832 - mmseg - INFO - Iter [6900/20000]	lr: 1.398e-05, eta: 5:27:05, time: 1.509, data_time: 0.003, memory: 10102, decode.loss_mask: 17.1155, decode.loss_dice: 2.5888, decode.acc_seg: 426.2656, loss: 19.7043
2024-06-20 16:13:41,130 - mmseg - INFO - Iter [6950/20000]	lr: 1.394e-05, eta: 5:25:51, time: 1.506, data_time: 0.003, memory: 10102, decode.loss_mask: 15.6111, decode.loss_dice: 2.5485, decode.acc_seg: 431.6535, loss: 18.1596
2024-06-20 16:14:56,389 - mmseg - INFO - Exp name: xxscales_input_vpt_seg_zero_vit-b_512x512_20k_12_10.py
2024-06-20 16:14:56,389 - mmseg - INFO - Iter [7000/20000]	lr: 1.389e-05, eta: 5:24:36, time: 1.505, data_time: 0.003, memory: 10102, decode.loss_mask: 16.6559, decode.loss_dice: 2.4645, decode.acc_seg: 432.6587, loss: 19.1204
2024-06-20 16:16:11,137 - mmseg - INFO - Iter [7050/20000]	lr: 1.385e-05, eta: 5:23:21, time: 1.495, data_time: 0.003, memory: 10102, decode.loss_mask: 15.0497, decode.loss_dice: 2.5171, decode.acc_seg: 438.2814, loss: 17.5668
2024-06-20 16:17:26,066 - mmseg - INFO - Iter [7100/20000]	lr: 1.381e-05, eta: 5:22:06, time: 1.499, data_time: 0.003, memory: 10102, decode.loss_mask: 15.5005, decode.loss_dice: 2.6977, decode.acc_seg: 420.7643, loss: 18.1981
2024-06-20 16:18:41,543 - mmseg - INFO - Iter [7150/20000]	lr: 1.376e-05, eta: 5:20:52, time: 1.510, data_time: 0.003, memory: 10102, decode.loss_mask: 16.9492, decode.loss_dice: 2.6581, decode.acc_seg: 424.0440, loss: 19.6073
2024-06-20 16:19:56,647 - mmseg - INFO - Iter [7200/20000]	lr: 1.372e-05, eta: 5:19:38, time: 1.502, data_time: 0.003, memory: 10102, decode.loss_mask: 14.3366, decode.loss_dice: 2.4690, decode.acc_seg: 445.9061, loss: 16.8055
2024-06-20 16:21:11,722 - mmseg - INFO - Iter [7250/20000]	lr: 1.367e-05, eta: 5:18:23, time: 1.501, data_time: 0.003, memory: 10102, decode.loss_mask: 16.9378, decode.loss_dice: 2.7317, decode.acc_seg: 433.6935, loss: 19.6695
2024-06-20 16:22:27,230 - mmseg - INFO - Iter [7300/20000]	lr: 1.363e-05, eta: 5:17:09, time: 1.510, data_time: 0.003, memory: 10102, decode.loss_mask: 17.3580, decode.loss_dice: 2.7703, decode.acc_seg: 437.3881, loss: 20.1283
2024-06-20 16:23:42,513 - mmseg - INFO - Iter [7350/20000]	lr: 1.358e-05, eta: 5:15:55, time: 1.506, data_time: 0.003, memory: 10102, decode.loss_mask: 15.0261, decode.loss_dice: 2.7197, decode.acc_seg: 435.8462, loss: 17.7458
2024-06-20 16:24:57,850 - mmseg - INFO - Iter [7400/20000]	lr: 1.354e-05, eta: 5:14:41, time: 1.507, data_time: 0.003, memory: 10102, decode.loss_mask: 16.2790, decode.loss_dice: 2.9821, decode.acc_seg: 428.5485, loss: 19.2611
2024-06-20 16:26:12,569 - mmseg - INFO - Iter [7450/20000]	lr: 1.349e-05, eta: 5:13:26, time: 1.494, data_time: 0.003, memory: 10102, decode.loss_mask: 15.7372, decode.loss_dice: 2.5285, decode.acc_seg: 433.6362, loss: 18.2657
2024-06-20 16:27:28,553 - mmseg - INFO - Iter [7500/20000]	lr: 1.345e-05, eta: 5:12:12, time: 1.520, data_time: 0.003, memory: 10102, decode.loss_mask: 14.0358, decode.loss_dice: 2.6085, decode.acc_seg: 435.2042, loss: 16.6443
2024-06-20 16:28:43,784 - mmseg - INFO - Iter [7550/20000]	lr: 1.340e-05, eta: 5:10:58, time: 1.505, data_time: 0.003, memory: 10102, decode.loss_mask: 16.0374, decode.loss_dice: 2.7019, decode.acc_seg: 429.9101, loss: 18.7393
2024-06-20 16:29:59,022 - mmseg - INFO - Iter [7600/20000]	lr: 1.336e-05, eta: 5:09:44, time: 1.505, data_time: 0.003, memory: 10102, decode.loss_mask: 14.0345, decode.loss_dice: 2.6170, decode.acc_seg: 432.3297, loss: 16.6515
2024-06-20 16:31:14,126 - mmseg - INFO - Iter [7650/20000]	lr: 1.331e-05, eta: 5:08:29, time: 1.502, data_time: 0.003, memory: 10102, decode.loss_mask: 14.4851, decode.loss_dice: 2.6287, decode.acc_seg: 439.4456, loss: 17.1138
2024-06-20 16:32:29,466 - mmseg - INFO - Iter [7700/20000]	lr: 1.327e-05, eta: 5:07:15, time: 1.507, data_time: 0.003, memory: 10102, decode.loss_mask: 18.6390, decode.loss_dice: 2.5572, decode.acc_seg: 426.6901, loss: 21.1963
2024-06-20 16:33:44,830 - mmseg - INFO - Iter [7750/20000]	lr: 1.322e-05, eta: 5:06:00, time: 1.507, data_time: 0.003, memory: 10102, decode.loss_mask: 14.9561, decode.loss_dice: 2.6794, decode.acc_seg: 433.6987, loss: 17.6355
2024-06-20 16:35:00,024 - mmseg - INFO - Iter [7800/20000]	lr: 1.318e-05, eta: 5:04:46, time: 1.504, data_time: 0.003, memory: 10102, decode.loss_mask: 14.1788, decode.loss_dice: 2.4797, decode.acc_seg: 439.9282, loss: 16.6585
2024-06-20 16:36:15,162 - mmseg - INFO - Iter [7850/20000]	lr: 1.313e-05, eta: 5:03:31, time: 1.503, data_time: 0.003, memory: 10102, decode.loss_mask: 15.3724, decode.loss_dice: 2.6664, decode.acc_seg: 436.8089, loss: 18.0388
2024-06-20 16:37:30,376 - mmseg - INFO - Iter [7900/20000]	lr: 1.309e-05, eta: 5:02:17, time: 1.504, data_time: 0.003, memory: 10102, decode.loss_mask: 16.7032, decode.loss_dice: 2.7002, decode.acc_seg: 418.5422, loss: 19.4033
2024-06-20 16:38:45,791 - mmseg - INFO - Iter [7950/20000]	lr: 1.304e-05, eta: 5:01:02, time: 1.508, data_time: 0.003, memory: 10102, decode.loss_mask: 13.9199, decode.loss_dice: 2.5494, decode.acc_seg: 433.8932, loss: 16.4693
2024-06-20 16:40:00,872 - mmseg - INFO - Saving checkpoint at 8000 iterations
2024-06-20 16:40:01,803 - mmseg - INFO - Exp name: xxscales_input_vpt_seg_zero_vit-b_512x512_20k_12_10.py
2024-06-20 16:40:01,803 - mmseg - INFO - Iter [8000/20000]	lr: 1.300e-05, eta: 4:59:49, time: 1.520, data_time: 0.003, memory: 10102, decode.loss_mask: 13.9083, decode.loss_dice: 2.5616, decode.acc_seg: 441.9531, loss: 16.4699
2024-06-20 16:41:17,030 - mmseg - INFO - Iter [8050/20000]	lr: 1.295e-05, eta: 4:58:34, time: 1.505, data_time: 0.003, memory: 10102, decode.loss_mask: 17.5741, decode.loss_dice: 2.5263, decode.acc_seg: 427.8697, loss: 20.1003
2024-06-20 16:42:32,095 - mmseg - INFO - Iter [8100/20000]	lr: 1.291e-05, eta: 4:57:20, time: 1.501, data_time: 0.003, memory: 10102, decode.loss_mask: 18.3964, decode.loss_dice: 2.6912, decode.acc_seg: 429.8011, loss: 21.0876
2024-06-20 16:43:47,183 - mmseg - INFO - Iter [8150/20000]	lr: 1.286e-05, eta: 4:56:05, time: 1.502, data_time: 0.003, memory: 10102, decode.loss_mask: 15.3030, decode.loss_dice: 2.4696, decode.acc_seg: 442.9002, loss: 17.7725
2024-06-20 16:45:02,364 - mmseg - INFO - Iter [8200/20000]	lr: 1.282e-05, eta: 4:54:50, time: 1.504, data_time: 0.003, memory: 10122, decode.loss_mask: 16.2150, decode.loss_dice: 2.7293, decode.acc_seg: 434.5107, loss: 18.9444
2024-06-20 16:46:17,475 - mmseg - INFO - Iter [8250/20000]	lr: 1.277e-05, eta: 4:53:35, time: 1.502, data_time: 0.003, memory: 10122, decode.loss_mask: 14.9280, decode.loss_dice: 2.6320, decode.acc_seg: 429.1667, loss: 17.5600
2024-06-20 16:47:32,583 - mmseg - INFO - Iter [8300/20000]	lr: 1.273e-05, eta: 4:52:21, time: 1.502, data_time: 0.003, memory: 10122, decode.loss_mask: 16.6600, decode.loss_dice: 2.7611, decode.acc_seg: 425.7862, loss: 19.4211
2024-06-20 16:48:47,596 - mmseg - INFO - Iter [8350/20000]	lr: 1.268e-05, eta: 4:51:06, time: 1.500, data_time: 0.003, memory: 10122, decode.loss_mask: 16.7695, decode.loss_dice: 2.6897, decode.acc_seg: 432.9943, loss: 19.4591
2024-06-20 16:50:02,858 - mmseg - INFO - Iter [8400/20000]	lr: 1.264e-05, eta: 4:49:51, time: 1.505, data_time: 0.003, memory: 10122, decode.loss_mask: 12.0869, decode.loss_dice: 2.4557, decode.acc_seg: 451.0961, loss: 14.5425
2024-06-20 16:51:17,888 - mmseg - INFO - Iter [8450/20000]	lr: 1.259e-05, eta: 4:48:36, time: 1.501, data_time: 0.003, memory: 10122, decode.loss_mask: 15.3074, decode.loss_dice: 2.6845, decode.acc_seg: 429.4453, loss: 17.9919
2024-06-20 16:52:32,696 - mmseg - INFO - Iter [8500/20000]	lr: 1.255e-05, eta: 4:47:21, time: 1.496, data_time: 0.003, memory: 10122, decode.loss_mask: 13.2212, decode.loss_dice: 2.5772, decode.acc_seg: 434.3974, loss: 15.7984
2024-06-20 16:53:47,568 - mmseg - INFO - Iter [8550/20000]	lr: 1.250e-05, eta: 4:46:06, time: 1.497, data_time: 0.003, memory: 10122, decode.loss_mask: 14.0371, decode.loss_dice: 2.3890, decode.acc_seg: 447.8040, loss: 16.4261
2024-06-20 16:55:02,978 - mmseg - INFO - Iter [8600/20000]	lr: 1.246e-05, eta: 4:44:52, time: 1.508, data_time: 0.003, memory: 10122, decode.loss_mask: 15.5064, decode.loss_dice: 2.7787, decode.acc_seg: 426.8249, loss: 18.2852
2024-06-20 16:56:18,189 - mmseg - INFO - Iter [8650/20000]	lr: 1.241e-05, eta: 4:43:37, time: 1.504, data_time: 0.003, memory: 10122, decode.loss_mask: 16.4046, decode.loss_dice: 2.6663, decode.acc_seg: 416.4183, loss: 19.0709
2024-06-20 16:57:33,112 - mmseg - INFO - Iter [8700/20000]	lr: 1.237e-05, eta: 4:42:22, time: 1.498, data_time: 0.003, memory: 10122, decode.loss_mask: 13.4348, decode.loss_dice: 2.4405, decode.acc_seg: 435.9135, loss: 15.8753
2024-06-20 16:58:48,732 - mmseg - INFO - Iter [8750/20000]	lr: 1.232e-05, eta: 4:41:08, time: 1.512, data_time: 0.003, memory: 10122, decode.loss_mask: 16.1163, decode.loss_dice: 2.5468, decode.acc_seg: 436.6996, loss: 18.6631
2024-06-20 17:00:04,290 - mmseg - INFO - Iter [8800/20000]	lr: 1.228e-05, eta: 4:39:54, time: 1.511, data_time: 0.003, memory: 10122, decode.loss_mask: 13.4750, decode.loss_dice: 2.3917, decode.acc_seg: 434.6583, loss: 15.8667
2024-06-20 17:01:19,503 - mmseg - INFO - Iter [8850/20000]	lr: 1.223e-05, eta: 4:38:39, time: 1.504, data_time: 0.003, memory: 10122, decode.loss_mask: 14.4107, decode.loss_dice: 2.6267, decode.acc_seg: 436.0987, loss: 17.0374
2024-06-20 17:02:34,961 - mmseg - INFO - Iter [8900/20000]	lr: 1.219e-05, eta: 4:37:25, time: 1.509, data_time: 0.003, memory: 10122, decode.loss_mask: 16.3804, decode.loss_dice: 2.5535, decode.acc_seg: 427.9292, loss: 18.9340
2024-06-20 17:03:50,457 - mmseg - INFO - Iter [8950/20000]	lr: 1.214e-05, eta: 4:36:10, time: 1.510, data_time: 0.003, memory: 10122, decode.loss_mask: 12.8908, decode.loss_dice: 2.4199, decode.acc_seg: 439.9877, loss: 15.3107
2024-06-20 17:05:05,197 - mmseg - INFO - Exp name: xxscales_input_vpt_seg_zero_vit-b_512x512_20k_12_10.py
2024-06-20 17:05:05,197 - mmseg - INFO - Iter [9000/20000]	lr: 1.209e-05, eta: 4:34:55, time: 1.495, data_time: 0.003, memory: 10122, decode.loss_mask: 17.2469, decode.loss_dice: 2.5828, decode.acc_seg: 425.2289, loss: 19.8297
2024-06-20 17:06:20,864 - mmseg - INFO - Iter [9050/20000]	lr: 1.205e-05, eta: 4:33:41, time: 1.513, data_time: 0.044, memory: 10122, decode.loss_mask: 15.7107, decode.loss_dice: 2.4130, decode.acc_seg: 434.5520, loss: 18.1237
2024-06-20 17:07:34,339 - mmseg - INFO - Iter [9100/20000]	lr: 1.200e-05, eta: 4:32:24, time: 1.469, data_time: 0.003, memory: 10122, decode.loss_mask: 14.3639, decode.loss_dice: 2.4951, decode.acc_seg: 432.3182, loss: 16.8590
2024-06-20 17:08:47,655 - mmseg - INFO - Iter [9150/20000]	lr: 1.196e-05, eta: 4:31:07, time: 1.466, data_time: 0.003, memory: 10122, decode.loss_mask: 12.3110, decode.loss_dice: 2.5597, decode.acc_seg: 442.5587, loss: 14.8707
2024-06-20 17:10:01,150 - mmseg - INFO - Iter [9200/20000]	lr: 1.191e-05, eta: 4:29:50, time: 1.470, data_time: 0.003, memory: 10122, decode.loss_mask: 14.2417, decode.loss_dice: 2.6151, decode.acc_seg: 433.1252, loss: 16.8568
2024-06-20 17:11:14,517 - mmseg - INFO - Iter [9250/20000]	lr: 1.187e-05, eta: 4:28:34, time: 1.467, data_time: 0.003, memory: 10122, decode.loss_mask: 14.1039, decode.loss_dice: 2.6398, decode.acc_seg: 427.5213, loss: 16.7437
2024-06-20 17:12:28,242 - mmseg - INFO - Iter [9300/20000]	lr: 1.182e-05, eta: 4:27:17, time: 1.474, data_time: 0.003, memory: 10122, decode.loss_mask: 12.0054, decode.loss_dice: 2.4886, decode.acc_seg: 441.0686, loss: 14.4941
2024-06-20 17:13:41,747 - mmseg - INFO - Iter [9350/20000]	lr: 1.178e-05, eta: 4:26:01, time: 1.470, data_time: 0.003, memory: 10122, decode.loss_mask: 15.4331, decode.loss_dice: 2.6707, decode.acc_seg: 421.9431, loss: 18.1039
2024-06-20 17:14:55,152 - mmseg - INFO - Iter [9400/20000]	lr: 1.173e-05, eta: 4:24:44, time: 1.468, data_time: 0.003, memory: 10122, decode.loss_mask: 13.2622, decode.loss_dice: 2.6125, decode.acc_seg: 436.4733, loss: 15.8747
2024-06-20 17:16:09,150 - mmseg - INFO - Iter [9450/20000]	lr: 1.169e-05, eta: 4:23:28, time: 1.480, data_time: 0.003, memory: 10122, decode.loss_mask: 18.5000, decode.loss_dice: 2.5903, decode.acc_seg: 433.1957, loss: 21.0904
2024-06-20 17:17:22,865 - mmseg - INFO - Iter [9500/20000]	lr: 1.164e-05, eta: 4:22:12, time: 1.474, data_time: 0.003, memory: 10122, decode.loss_mask: 12.4216, decode.loss_dice: 2.6101, decode.acc_seg: 439.2646, loss: 15.0318
2024-06-20 17:18:36,294 - mmseg - INFO - Iter [9550/20000]	lr: 1.159e-05, eta: 4:20:55, time: 1.469, data_time: 0.003, memory: 10122, decode.loss_mask: 13.3505, decode.loss_dice: 2.4780, decode.acc_seg: 445.1681, loss: 15.8286
2024-06-20 17:19:49,821 - mmseg - INFO - Iter [9600/20000]	lr: 1.155e-05, eta: 4:19:39, time: 1.471, data_time: 0.003, memory: 10122, decode.loss_mask: 16.4126, decode.loss_dice: 2.6623, decode.acc_seg: 421.7691, loss: 19.0749
2024-06-20 17:21:03,536 - mmseg - INFO - Iter [9650/20000]	lr: 1.150e-05, eta: 4:18:23, time: 1.474, data_time: 0.003, memory: 10122, decode.loss_mask: 14.5675, decode.loss_dice: 2.4613, decode.acc_seg: 439.9937, loss: 17.0288
2024-06-20 17:22:17,509 - mmseg - INFO - Iter [9700/20000]	lr: 1.146e-05, eta: 4:17:07, time: 1.479, data_time: 0.003, memory: 10122, decode.loss_mask: 14.3130, decode.loss_dice: 2.5156, decode.acc_seg: 441.9003, loss: 16.8286
2024-06-20 17:23:31,012 - mmseg - INFO - Iter [9750/20000]	lr: 1.141e-05, eta: 4:15:51, time: 1.470, data_time: 0.003, memory: 10122, decode.loss_mask: 12.7937, decode.loss_dice: 2.5034, decode.acc_seg: 437.0233, loss: 15.2970
2024-06-20 17:24:44,291 - mmseg - INFO - Iter [9800/20000]	lr: 1.137e-05, eta: 4:14:34, time: 1.466, data_time: 0.003, memory: 10122, decode.loss_mask: 14.6573, decode.loss_dice: 2.4593, decode.acc_seg: 436.6977, loss: 17.1166
2024-06-20 17:25:57,920 - mmseg - INFO - Iter [9850/20000]	lr: 1.132e-05, eta: 4:13:18, time: 1.473, data_time: 0.003, memory: 10122, decode.loss_mask: 12.0396, decode.loss_dice: 2.3684, decode.acc_seg: 443.6117, loss: 14.4079
2024-06-20 17:27:11,488 - mmseg - INFO - Iter [9900/20000]	lr: 1.127e-05, eta: 4:12:02, time: 1.471, data_time: 0.003, memory: 10122, decode.loss_mask: 13.9636, decode.loss_dice: 2.6500, decode.acc_seg: 434.7340, loss: 16.6136
2024-06-20 17:28:25,161 - mmseg - INFO - Iter [9950/20000]	lr: 1.123e-05, eta: 4:10:46, time: 1.473, data_time: 0.003, memory: 10122, decode.loss_mask: 14.5071, decode.loss_dice: 2.5349, decode.acc_seg: 437.5309, loss: 17.0420
2024-06-20 17:29:38,406 - mmseg - INFO - Saving checkpoint at 10000 iterations
2024-06-20 17:29:39,377 - mmseg - INFO - Exp name: xxscales_input_vpt_seg_zero_vit-b_512x512_20k_12_10.py
2024-06-20 17:29:39,378 - mmseg - INFO - Iter [10000/20000]	lr: 1.118e-05, eta: 4:09:30, time: 1.484, data_time: 0.003, memory: 10122, decode.loss_mask: 11.6472, decode.loss_dice: 2.5543, decode.acc_seg: 445.5824, loss: 14.2014
2024-06-20 17:30:52,945 - mmseg - INFO - Iter [10050/20000]	lr: 1.114e-05, eta: 4:08:14, time: 1.471, data_time: 0.003, memory: 10122, decode.loss_mask: 13.3844, decode.loss_dice: 2.4431, decode.acc_seg: 441.5862, loss: 15.8274
2024-06-20 17:32:06,542 - mmseg - INFO - Iter [10100/20000]	lr: 1.109e-05, eta: 4:06:58, time: 1.472, data_time: 0.003, memory: 10122, decode.loss_mask: 14.7291, decode.loss_dice: 2.7797, decode.acc_seg: 425.3081, loss: 17.5087
2024-06-20 17:33:22,077 - mmseg - INFO - Iter [10150/20000]	lr: 1.105e-05, eta: 4:05:44, time: 1.511, data_time: 0.003, memory: 10122, decode.loss_mask: 14.1554, decode.loss_dice: 2.5657, decode.acc_seg: 435.9598, loss: 16.7211
2024-06-20 17:34:37,068 - mmseg - INFO - Iter [10200/20000]	lr: 1.100e-05, eta: 4:04:29, time: 1.500, data_time: 0.003, memory: 10122, decode.loss_mask: 14.5999, decode.loss_dice: 2.4472, decode.acc_seg: 436.3936, loss: 17.0471
2024-06-20 17:35:52,453 - mmseg - INFO - Iter [10250/20000]	lr: 1.095e-05, eta: 4:03:15, time: 1.508, data_time: 0.003, memory: 10122, decode.loss_mask: 13.7889, decode.loss_dice: 2.4014, decode.acc_seg: 439.9762, loss: 16.1903
2024-06-20 17:37:07,325 - mmseg - INFO - Iter [10300/20000]	lr: 1.091e-05, eta: 4:02:00, time: 1.497, data_time: 0.003, memory: 10122, decode.loss_mask: 15.0508, decode.loss_dice: 2.4957, decode.acc_seg: 436.3234, loss: 17.5465
2024-06-20 17:38:22,556 - mmseg - INFO - Iter [10350/20000]	lr: 1.086e-05, eta: 4:00:45, time: 1.505, data_time: 0.003, memory: 10122, decode.loss_mask: 16.3922, decode.loss_dice: 2.5561, decode.acc_seg: 438.6551, loss: 18.9484
2024-06-20 17:39:37,613 - mmseg - INFO - Iter [10400/20000]	lr: 1.082e-05, eta: 3:59:31, time: 1.501, data_time: 0.003, memory: 10122, decode.loss_mask: 15.2650, decode.loss_dice: 2.3075, decode.acc_seg: 432.0609, loss: 17.5725
2024-06-20 17:40:52,628 - mmseg - INFO - Iter [10450/20000]	lr: 1.077e-05, eta: 3:58:16, time: 1.500, data_time: 0.003, memory: 10122, decode.loss_mask: 14.7258, decode.loss_dice: 2.6923, decode.acc_seg: 428.5522, loss: 17.4181
2024-06-20 17:42:07,540 - mmseg - INFO - Iter [10500/20000]	lr: 1.072e-05, eta: 3:57:01, time: 1.498, data_time: 0.003, memory: 10122, decode.loss_mask: 14.1109, decode.loss_dice: 2.5522, decode.acc_seg: 433.1744, loss: 16.6631
2024-06-20 17:43:22,474 - mmseg - INFO - Iter [10550/20000]	lr: 1.068e-05, eta: 3:55:46, time: 1.499, data_time: 0.003, memory: 10122, decode.loss_mask: 14.0017, decode.loss_dice: 2.5127, decode.acc_seg: 440.5117, loss: 16.5144
2024-06-20 17:44:36,983 - mmseg - INFO - Iter [10600/20000]	lr: 1.063e-05, eta: 3:54:31, time: 1.490, data_time: 0.003, memory: 10122, decode.loss_mask: 16.6968, decode.loss_dice: 2.3386, decode.acc_seg: 439.7439, loss: 19.0354
2024-06-20 17:45:51,800 - mmseg - INFO - Iter [10650/20000]	lr: 1.059e-05, eta: 3:53:16, time: 1.496, data_time: 0.003, memory: 10122, decode.loss_mask: 16.6871, decode.loss_dice: 2.6380, decode.acc_seg: 435.3373, loss: 19.3251
2024-06-20 17:47:07,051 - mmseg - INFO - Iter [10700/20000]	lr: 1.054e-05, eta: 3:52:02, time: 1.505, data_time: 0.003, memory: 10122, decode.loss_mask: 11.3190, decode.loss_dice: 2.7673, decode.acc_seg: 445.7589, loss: 14.0863
2024-06-20 17:48:21,827 - mmseg - INFO - Iter [10750/20000]	lr: 1.049e-05, eta: 3:50:47, time: 1.496, data_time: 0.004, memory: 10122, decode.loss_mask: 14.6136, decode.loss_dice: 2.6036, decode.acc_seg: 441.7521, loss: 17.2172
2024-06-20 17:49:36,785 - mmseg - INFO - Iter [10800/20000]	lr: 1.045e-05, eta: 3:49:32, time: 1.499, data_time: 0.003, memory: 10122, decode.loss_mask: 17.6364, decode.loss_dice: 2.6893, decode.acc_seg: 431.8991, loss: 20.3257
2024-06-20 17:50:51,965 - mmseg - INFO - Iter [10850/20000]	lr: 1.040e-05, eta: 3:48:18, time: 1.504, data_time: 0.004, memory: 10122, decode.loss_mask: 12.4554, decode.loss_dice: 2.4996, decode.acc_seg: 437.6555, loss: 14.9550
2024-06-20 17:52:06,378 - mmseg - INFO - Iter [10900/20000]	lr: 1.035e-05, eta: 3:47:02, time: 1.488, data_time: 0.003, memory: 10122, decode.loss_mask: 11.5490, decode.loss_dice: 2.4241, decode.acc_seg: 441.5968, loss: 13.9731
2024-06-20 17:53:21,601 - mmseg - INFO - Iter [10950/20000]	lr: 1.031e-05, eta: 3:45:48, time: 1.504, data_time: 0.003, memory: 10122, decode.loss_mask: 14.7590, decode.loss_dice: 2.4132, decode.acc_seg: 442.4493, loss: 17.1723
2024-06-20 17:54:37,085 - mmseg - INFO - Exp name: xxscales_input_vpt_seg_zero_vit-b_512x512_20k_12_10.py
2024-06-20 17:54:37,085 - mmseg - INFO - Iter [11000/20000]	lr: 1.026e-05, eta: 3:44:34, time: 1.510, data_time: 0.003, memory: 10122, decode.loss_mask: 15.6578, decode.loss_dice: 2.5069, decode.acc_seg: 440.2207, loss: 18.1647
2024-06-20 17:55:52,037 - mmseg - INFO - Iter [11050/20000]	lr: 1.022e-05, eta: 3:43:19, time: 1.499, data_time: 0.003, memory: 10122, decode.loss_mask: 13.8157, decode.loss_dice: 2.6201, decode.acc_seg: 431.4281, loss: 16.4358
2024-06-20 17:57:06,951 - mmseg - INFO - Iter [11100/20000]	lr: 1.017e-05, eta: 3:42:04, time: 1.498, data_time: 0.003, memory: 10122, decode.loss_mask: 14.0946, decode.loss_dice: 2.6732, decode.acc_seg: 423.3559, loss: 16.7678
2024-06-20 17:58:21,345 - mmseg - INFO - Iter [11150/20000]	lr: 1.012e-05, eta: 3:40:49, time: 1.488, data_time: 0.003, memory: 10122, decode.loss_mask: 13.6232, decode.loss_dice: 2.5362, decode.acc_seg: 438.0793, loss: 16.1594
2024-06-20 17:59:36,764 - mmseg - INFO - Iter [11200/20000]	lr: 1.008e-05, eta: 3:39:34, time: 1.508, data_time: 0.003, memory: 10122, decode.loss_mask: 14.9734, decode.loss_dice: 2.4408, decode.acc_seg: 445.5286, loss: 17.4142
2024-06-20 18:00:51,522 - mmseg - INFO - Iter [11250/20000]	lr: 1.003e-05, eta: 3:38:19, time: 1.495, data_time: 0.003, memory: 10122, decode.loss_mask: 14.7709, decode.loss_dice: 2.4661, decode.acc_seg: 432.3779, loss: 17.2369
2024-06-20 18:02:05,905 - mmseg - INFO - Iter [11300/20000]	lr: 9.983e-06, eta: 3:37:04, time: 1.488, data_time: 0.003, memory: 10122, decode.loss_mask: 15.0581, decode.loss_dice: 2.5345, decode.acc_seg: 437.1600, loss: 17.5926
2024-06-20 18:03:20,978 - mmseg - INFO - Iter [11350/20000]	lr: 9.937e-06, eta: 3:35:49, time: 1.501, data_time: 0.003, memory: 10122, decode.loss_mask: 13.3099, decode.loss_dice: 2.5274, decode.acc_seg: 441.5460, loss: 15.8373
2024-06-20 18:04:35,508 - mmseg - INFO - Iter [11400/20000]	lr: 9.890e-06, eta: 3:34:34, time: 1.491, data_time: 0.003, memory: 10122, decode.loss_mask: 14.4847, decode.loss_dice: 2.5405, decode.acc_seg: 438.6671, loss: 17.0252
2024-06-20 18:05:50,239 - mmseg - INFO - Iter [11450/20000]	lr: 9.844e-06, eta: 3:33:19, time: 1.495, data_time: 0.003, memory: 10122, decode.loss_mask: 16.5340, decode.loss_dice: 2.6191, decode.acc_seg: 424.1721, loss: 19.1531
2024-06-20 18:07:05,512 - mmseg - INFO - Iter [11500/20000]	lr: 9.797e-06, eta: 3:32:05, time: 1.505, data_time: 0.003, memory: 10122, decode.loss_mask: 14.3333, decode.loss_dice: 2.3797, decode.acc_seg: 439.7469, loss: 16.7131
2024-06-20 18:08:19,952 - mmseg - INFO - Iter [11550/20000]	lr: 9.751e-06, eta: 3:30:50, time: 1.489, data_time: 0.003, memory: 10122, decode.loss_mask: 11.9673, decode.loss_dice: 2.5639, decode.acc_seg: 445.0139, loss: 14.5311
2024-06-20 18:09:35,108 - mmseg - INFO - Iter [11600/20000]	lr: 9.704e-06, eta: 3:29:35, time: 1.503, data_time: 0.004, memory: 10122, decode.loss_mask: 13.4100, decode.loss_dice: 2.4107, decode.acc_seg: 445.3911, loss: 15.8207
2024-06-20 18:10:48,303 - mmseg - INFO - Iter [11650/20000]	lr: 9.657e-06, eta: 3:28:19, time: 1.464, data_time: 0.004, memory: 10122, decode.loss_mask: 16.8751, decode.loss_dice: 2.6886, decode.acc_seg: 431.8179, loss: 19.5636
2024-06-20 18:12:02,132 - mmseg - INFO - Iter [11700/20000]	lr: 9.611e-06, eta: 3:27:03, time: 1.477, data_time: 0.004, memory: 10122, decode.loss_mask: 15.3208, decode.loss_dice: 2.5882, decode.acc_seg: 431.1783, loss: 17.9090
2024-06-20 18:13:16,795 - mmseg - INFO - Iter [11750/20000]	lr: 9.564e-06, eta: 3:25:48, time: 1.493, data_time: 0.004, memory: 10122, decode.loss_mask: 14.7579, decode.loss_dice: 2.5665, decode.acc_seg: 438.5525, loss: 17.3245
2024-06-20 18:14:31,653 - mmseg - INFO - Iter [11800/20000]	lr: 9.517e-06, eta: 3:24:34, time: 1.497, data_time: 0.004, memory: 10122, decode.loss_mask: 15.6556, decode.loss_dice: 2.5409, decode.acc_seg: 442.0687, loss: 18.1965
2024-06-20 18:15:46,648 - mmseg - INFO - Iter [11850/20000]	lr: 9.471e-06, eta: 3:23:19, time: 1.500, data_time: 0.003, memory: 10122, decode.loss_mask: 13.9845, decode.loss_dice: 2.5623, decode.acc_seg: 441.9430, loss: 16.5468
2024-06-20 18:17:01,422 - mmseg - INFO - Iter [11900/20000]	lr: 9.424e-06, eta: 3:22:04, time: 1.495, data_time: 0.003, memory: 10122, decode.loss_mask: 14.2344, decode.loss_dice: 2.2901, decode.acc_seg: 443.1750, loss: 16.5245
2024-06-20 18:18:16,166 - mmseg - INFO - Iter [11950/20000]	lr: 9.377e-06, eta: 3:20:49, time: 1.495, data_time: 0.003, memory: 10122, decode.loss_mask: 15.4749, decode.loss_dice: 2.5519, decode.acc_seg: 442.1434, loss: 18.0268
2024-06-20 18:19:30,780 - mmseg - INFO - Saving checkpoint at 12000 iterations
2024-06-20 18:19:31,787 - mmseg - INFO - Exp name: xxscales_input_vpt_seg_zero_vit-b_512x512_20k_12_10.py
2024-06-20 18:19:31,788 - mmseg - INFO - Iter [12000/20000]	lr: 9.330e-06, eta: 3:19:35, time: 1.512, data_time: 0.003, memory: 10122, decode.loss_mask: 13.5182, decode.loss_dice: 2.6628, decode.acc_seg: 440.0590, loss: 16.1811
2024-06-20 18:20:48,301 - mmseg - INFO - Iter [12050/20000]	lr: 9.283e-06, eta: 3:18:21, time: 1.530, data_time: 0.044, memory: 10122, decode.loss_mask: 14.7903, decode.loss_dice: 2.7252, decode.acc_seg: 433.3320, loss: 17.5155
2024-06-20 18:22:03,450 - mmseg - INFO - Iter [12100/20000]	lr: 9.236e-06, eta: 3:17:06, time: 1.503, data_time: 0.003, memory: 10122, decode.loss_mask: 14.2350, decode.loss_dice: 2.5856, decode.acc_seg: 443.6220, loss: 16.8206
2024-06-20 18:23:18,582 - mmseg - INFO - Iter [12150/20000]	lr: 9.190e-06, eta: 3:15:52, time: 1.503, data_time: 0.003, memory: 10122, decode.loss_mask: 14.9850, decode.loss_dice: 2.2996, decode.acc_seg: 438.4543, loss: 17.2845
2024-06-20 18:24:33,900 - mmseg - INFO - Iter [12200/20000]	lr: 9.143e-06, eta: 3:14:37, time: 1.506, data_time: 0.003, memory: 10122, decode.loss_mask: 15.7297, decode.loss_dice: 2.4998, decode.acc_seg: 440.1456, loss: 18.2295
2024-06-20 18:25:48,910 - mmseg - INFO - Iter [12250/20000]	lr: 9.096e-06, eta: 3:13:22, time: 1.500, data_time: 0.003, memory: 10122, decode.loss_mask: 14.5407, decode.loss_dice: 2.5009, decode.acc_seg: 435.4259, loss: 17.0416
2024-06-20 18:27:04,040 - mmseg - INFO - Iter [12300/20000]	lr: 9.049e-06, eta: 3:12:08, time: 1.503, data_time: 0.003, memory: 10122, decode.loss_mask: 13.3396, decode.loss_dice: 2.3457, decode.acc_seg: 446.1150, loss: 15.6853
2024-06-20 18:28:19,028 - mmseg - INFO - Iter [12350/20000]	lr: 9.002e-06, eta: 3:10:53, time: 1.500, data_time: 0.003, memory: 10122, decode.loss_mask: 14.2935, decode.loss_dice: 2.6893, decode.acc_seg: 434.8034, loss: 16.9828
2024-06-20 18:29:33,602 - mmseg - INFO - Iter [12400/20000]	lr: 8.954e-06, eta: 3:09:38, time: 1.491, data_time: 0.003, memory: 10122, decode.loss_mask: 13.6932, decode.loss_dice: 2.7233, decode.acc_seg: 434.9339, loss: 16.4165
2024-06-20 18:30:48,642 - mmseg - INFO - Iter [12450/20000]	lr: 8.907e-06, eta: 3:08:23, time: 1.501, data_time: 0.003, memory: 10122, decode.loss_mask: 12.7456, decode.loss_dice: 2.6004, decode.acc_seg: 439.7817, loss: 15.3460
2024-06-20 18:32:03,832 - mmseg - INFO - Iter [12500/20000]	lr: 8.860e-06, eta: 3:07:08, time: 1.504, data_time: 0.003, memory: 10122, decode.loss_mask: 13.7359, decode.loss_dice: 2.5601, decode.acc_seg: 442.6492, loss: 16.2960
2024-06-20 18:33:18,790 - mmseg - INFO - Iter [12550/20000]	lr: 8.813e-06, eta: 3:05:54, time: 1.499, data_time: 0.003, memory: 10122, decode.loss_mask: 16.2576, decode.loss_dice: 2.5517, decode.acc_seg: 437.4553, loss: 18.8093
2024-06-20 18:34:34,007 - mmseg - INFO - Iter [12600/20000]	lr: 8.766e-06, eta: 3:04:39, time: 1.504, data_time: 0.003, memory: 10122, decode.loss_mask: 12.3862, decode.loss_dice: 2.5239, decode.acc_seg: 442.6784, loss: 14.9101
2024-06-20 18:35:48,925 - mmseg - INFO - Iter [12650/20000]	lr: 8.719e-06, eta: 3:03:24, time: 1.498, data_time: 0.003, memory: 10122, decode.loss_mask: 13.1008, decode.loss_dice: 2.5690, decode.acc_seg: 447.0203, loss: 15.6698
2024-06-20 18:37:03,550 - mmseg - INFO - Iter [12700/20000]	lr: 8.671e-06, eta: 3:02:09, time: 1.492, data_time: 0.003, memory: 10122, decode.loss_mask: 10.3774, decode.loss_dice: 2.3061, decode.acc_seg: 451.9037, loss: 12.6835
2024-06-20 18:38:18,297 - mmseg - INFO - Iter [12750/20000]	lr: 8.624e-06, eta: 3:00:54, time: 1.495, data_time: 0.003, memory: 10122, decode.loss_mask: 11.8752, decode.loss_dice: 2.5338, decode.acc_seg: 445.5126, loss: 14.4090
2024-06-20 18:39:33,393 - mmseg - INFO - Iter [12800/20000]	lr: 8.577e-06, eta: 2:59:40, time: 1.502, data_time: 0.003, memory: 10122, decode.loss_mask: 14.4807, decode.loss_dice: 2.3397, decode.acc_seg: 439.3460, loss: 16.8204
2024-06-20 18:40:48,263 - mmseg - INFO - Iter [12850/20000]	lr: 8.529e-06, eta: 2:58:25, time: 1.497, data_time: 0.003, memory: 10122, decode.loss_mask: 12.7443, decode.loss_dice: 2.4776, decode.acc_seg: 431.0101, loss: 15.2218
2024-06-20 18:42:03,073 - mmseg - INFO - Iter [12900/20000]	lr: 8.482e-06, eta: 2:57:10, time: 1.496, data_time: 0.003, memory: 10122, decode.loss_mask: 12.2230, decode.loss_dice: 2.4886, decode.acc_seg: 438.5560, loss: 14.7115
2024-06-20 18:43:17,950 - mmseg - INFO - Iter [12950/20000]	lr: 8.435e-06, eta: 2:55:55, time: 1.498, data_time: 0.003, memory: 10122, decode.loss_mask: 17.4071, decode.loss_dice: 2.6637, decode.acc_seg: 431.0584, loss: 20.0708
2024-06-20 18:44:32,946 - mmseg - INFO - Exp name: xxscales_input_vpt_seg_zero_vit-b_512x512_20k_12_10.py
2024-06-20 18:44:32,946 - mmseg - INFO - Iter [13000/20000]	lr: 8.387e-06, eta: 2:54:40, time: 1.500, data_time: 0.003, memory: 10122, decode.loss_mask: 17.1755, decode.loss_dice: 2.5029, decode.acc_seg: 437.3543, loss: 19.6784
2024-06-20 18:45:47,574 - mmseg - INFO - Iter [13050/20000]	lr: 8.340e-06, eta: 2:53:25, time: 1.493, data_time: 0.003, memory: 10122, decode.loss_mask: 15.0406, decode.loss_dice: 2.6015, decode.acc_seg: 440.7960, loss: 17.6420
2024-06-20 18:47:02,562 - mmseg - INFO - Iter [13100/20000]	lr: 8.292e-06, eta: 2:52:10, time: 1.500, data_time: 0.003, memory: 10122, decode.loss_mask: 11.2747, decode.loss_dice: 2.6039, decode.acc_seg: 441.2440, loss: 13.8786
2024-06-20 18:48:17,197 - mmseg - INFO - Iter [13150/20000]	lr: 8.244e-06, eta: 2:50:55, time: 1.493, data_time: 0.003, memory: 10122, decode.loss_mask: 15.1126, decode.loss_dice: 2.3946, decode.acc_seg: 445.9253, loss: 17.5072
2024-06-20 18:49:31,999 - mmseg - INFO - Iter [13200/20000]	lr: 8.197e-06, eta: 2:49:41, time: 1.496, data_time: 0.003, memory: 10122, decode.loss_mask: 15.4517, decode.loss_dice: 2.5314, decode.acc_seg: 434.3391, loss: 17.9831
2024-06-20 18:50:45,153 - mmseg - INFO - Iter [13250/20000]	lr: 8.149e-06, eta: 2:48:25, time: 1.463, data_time: 0.003, memory: 10122, decode.loss_mask: 11.0969, decode.loss_dice: 2.5523, decode.acc_seg: 447.4199, loss: 13.6492
2024-06-20 18:51:59,017 - mmseg - INFO - Iter [13300/20000]	lr: 8.102e-06, eta: 2:47:09, time: 1.477, data_time: 0.003, memory: 10122, decode.loss_mask: 13.6312, decode.loss_dice: 2.3481, decode.acc_seg: 439.7177, loss: 15.9794
2024-06-20 18:53:13,688 - mmseg - INFO - Iter [13350/20000]	lr: 8.054e-06, eta: 2:45:54, time: 1.493, data_time: 0.003, memory: 10122, decode.loss_mask: 13.1503, decode.loss_dice: 2.5419, decode.acc_seg: 439.0187, loss: 15.6922
2024-06-20 18:54:28,417 - mmseg - INFO - Iter [13400/20000]	lr: 8.006e-06, eta: 2:44:40, time: 1.495, data_time: 0.003, memory: 10122, decode.loss_mask: 12.4325, decode.loss_dice: 2.3241, decode.acc_seg: 444.5401, loss: 14.7566
2024-06-20 18:55:43,181 - mmseg - INFO - Iter [13450/20000]	lr: 7.958e-06, eta: 2:43:25, time: 1.495, data_time: 0.003, memory: 10122, decode.loss_mask: 14.2336, decode.loss_dice: 2.4116, decode.acc_seg: 441.6992, loss: 16.6452
2024-06-20 18:56:57,942 - mmseg - INFO - Iter [13500/20000]	lr: 7.910e-06, eta: 2:42:10, time: 1.495, data_time: 0.003, memory: 10122, decode.loss_mask: 13.9936, decode.loss_dice: 2.4850, decode.acc_seg: 439.2742, loss: 16.4786
2024-06-20 18:58:12,579 - mmseg - INFO - Iter [13550/20000]	lr: 7.863e-06, eta: 2:40:55, time: 1.493, data_time: 0.003, memory: 10122, decode.loss_mask: 14.7258, decode.loss_dice: 2.5980, decode.acc_seg: 438.6087, loss: 17.3239
2024-06-20 18:59:27,114 - mmseg - INFO - Iter [13600/20000]	lr: 7.815e-06, eta: 2:39:40, time: 1.491, data_time: 0.003, memory: 10122, decode.loss_mask: 12.6115, decode.loss_dice: 2.3644, decode.acc_seg: 439.2706, loss: 14.9759
2024-06-20 19:00:42,044 - mmseg - INFO - Iter [13650/20000]	lr: 7.767e-06, eta: 2:38:25, time: 1.499, data_time: 0.003, memory: 10122, decode.loss_mask: 15.1490, decode.loss_dice: 2.6627, decode.acc_seg: 439.1836, loss: 17.8118
2024-06-20 19:01:56,763 - mmseg - INFO - Iter [13700/20000]	lr: 7.719e-06, eta: 2:37:10, time: 1.494, data_time: 0.003, memory: 10122, decode.loss_mask: 12.3815, decode.loss_dice: 2.5111, decode.acc_seg: 442.8413, loss: 14.8926
2024-06-20 19:03:11,314 - mmseg - INFO - Iter [13750/20000]	lr: 7.671e-06, eta: 2:35:55, time: 1.491, data_time: 0.003, memory: 10122, decode.loss_mask: 14.7873, decode.loss_dice: 2.4343, decode.acc_seg: 439.7355, loss: 17.2216
2024-06-20 19:04:26,236 - mmseg - INFO - Iter [13800/20000]	lr: 7.623e-06, eta: 2:34:40, time: 1.498, data_time: 0.003, memory: 10122, decode.loss_mask: 14.3591, decode.loss_dice: 2.4514, decode.acc_seg: 434.0850, loss: 16.8105
2024-06-20 19:05:41,136 - mmseg - INFO - Iter [13850/20000]	lr: 7.575e-06, eta: 2:33:26, time: 1.498, data_time: 0.003, memory: 10122, decode.loss_mask: 12.9502, decode.loss_dice: 2.3559, decode.acc_seg: 446.1426, loss: 15.3061
2024-06-20 19:06:55,577 - mmseg - INFO - Iter [13900/20000]	lr: 7.527e-06, eta: 2:32:11, time: 1.489, data_time: 0.003, memory: 10122, decode.loss_mask: 14.3119, decode.loss_dice: 2.6061, decode.acc_seg: 432.5891, loss: 16.9180
2024-06-20 19:08:10,152 - mmseg - INFO - Iter [13950/20000]	lr: 7.478e-06, eta: 2:30:56, time: 1.492, data_time: 0.003, memory: 10122, decode.loss_mask: 10.5390, decode.loss_dice: 2.3938, decode.acc_seg: 447.4600, loss: 12.9328
2024-06-20 19:09:24,227 - mmseg - INFO - Saving checkpoint at 14000 iterations
2024-06-20 19:09:25,189 - mmseg - INFO - Exp name: xxscales_input_vpt_seg_zero_vit-b_512x512_20k_12_10.py
2024-06-20 19:09:25,190 - mmseg - INFO - Iter [14000/20000]	lr: 7.430e-06, eta: 2:29:41, time: 1.501, data_time: 0.003, memory: 10122, decode.loss_mask: 14.3411, decode.loss_dice: 2.5398, decode.acc_seg: 436.9442, loss: 16.8809
2024-06-20 19:10:40,090 - mmseg - INFO - Iter [14050/20000]	lr: 7.382e-06, eta: 2:28:26, time: 1.498, data_time: 0.003, memory: 10122, decode.loss_mask: 11.8737, decode.loss_dice: 2.3083, decode.acc_seg: 444.1570, loss: 14.1820
2024-06-20 19:11:55,017 - mmseg - INFO - Iter [14100/20000]	lr: 7.334e-06, eta: 2:27:11, time: 1.499, data_time: 0.003, memory: 10122, decode.loss_mask: 15.3036, decode.loss_dice: 2.3053, decode.acc_seg: 437.4876, loss: 17.6088
2024-06-20 19:13:09,865 - mmseg - INFO - Iter [14150/20000]	lr: 7.285e-06, eta: 2:25:56, time: 1.497, data_time: 0.003, memory: 10122, decode.loss_mask: 14.7058, decode.loss_dice: 2.6481, decode.acc_seg: 437.5152, loss: 17.3539
2024-06-20 19:14:24,218 - mmseg - INFO - Iter [14200/20000]	lr: 7.237e-06, eta: 2:24:41, time: 1.487, data_time: 0.003, memory: 10122, decode.loss_mask: 12.8742, decode.loss_dice: 2.6825, decode.acc_seg: 441.3509, loss: 15.5567
2024-06-20 19:15:38,840 - mmseg - INFO - Iter [14250/20000]	lr: 7.189e-06, eta: 2:23:26, time: 1.492, data_time: 0.003, memory: 10122, decode.loss_mask: 14.9338, decode.loss_dice: 2.3330, decode.acc_seg: 436.9014, loss: 17.2668
2024-06-20 19:16:53,413 - mmseg - INFO - Iter [14300/20000]	lr: 7.140e-06, eta: 2:22:11, time: 1.491, data_time: 0.003, memory: 10122, decode.loss_mask: 13.0364, decode.loss_dice: 2.4232, decode.acc_seg: 442.6327, loss: 15.4596
2024-06-20 19:18:08,133 - mmseg - INFO - Iter [14350/20000]	lr: 7.092e-06, eta: 2:20:56, time: 1.494, data_time: 0.003, memory: 10122, decode.loss_mask: 14.4482, decode.loss_dice: 2.6503, decode.acc_seg: 436.0769, loss: 17.0985
2024-06-20 19:19:22,849 - mmseg - INFO - Iter [14400/20000]	lr: 7.043e-06, eta: 2:19:42, time: 1.494, data_time: 0.003, memory: 10122, decode.loss_mask: 15.0226, decode.loss_dice: 2.4828, decode.acc_seg: 438.9903, loss: 17.5054
2024-06-20 19:20:37,559 - mmseg - INFO - Iter [14450/20000]	lr: 6.995e-06, eta: 2:18:27, time: 1.494, data_time: 0.003, memory: 10122, decode.loss_mask: 13.9175, decode.loss_dice: 2.5394, decode.acc_seg: 443.4177, loss: 16.4569
2024-06-20 19:21:52,282 - mmseg - INFO - Iter [14500/20000]	lr: 6.946e-06, eta: 2:17:12, time: 1.494, data_time: 0.003, memory: 10122, decode.loss_mask: 14.0240, decode.loss_dice: 2.4544, decode.acc_seg: 440.8025, loss: 16.4784
2024-06-20 19:23:07,042 - mmseg - INFO - Iter [14550/20000]	lr: 6.897e-06, eta: 2:15:57, time: 1.495, data_time: 0.003, memory: 10122, decode.loss_mask: 11.8380, decode.loss_dice: 2.5347, decode.acc_seg: 439.3270, loss: 14.3727
2024-06-20 19:24:21,395 - mmseg - INFO - Iter [14600/20000]	lr: 6.849e-06, eta: 2:14:42, time: 1.487, data_time: 0.003, memory: 10122, decode.loss_mask: 14.2596, decode.loss_dice: 2.5362, decode.acc_seg: 447.0637, loss: 16.7957
2024-06-20 19:25:36,039 - mmseg - INFO - Iter [14650/20000]	lr: 6.800e-06, eta: 2:13:27, time: 1.493, data_time: 0.003, memory: 10122, decode.loss_mask: 14.0483, decode.loss_dice: 2.5333, decode.acc_seg: 436.9360, loss: 16.5816
2024-06-20 19:26:50,142 - mmseg - INFO - Iter [14700/20000]	lr: 6.751e-06, eta: 2:12:12, time: 1.482, data_time: 0.003, memory: 10122, decode.loss_mask: 10.8364, decode.loss_dice: 2.3287, decode.acc_seg: 443.1665, loss: 13.1651
2024-06-20 19:28:04,283 - mmseg - INFO - Iter [14750/20000]	lr: 6.702e-06, eta: 2:10:57, time: 1.483, data_time: 0.003, memory: 10122, decode.loss_mask: 15.2044, decode.loss_dice: 2.3986, decode.acc_seg: 435.4859, loss: 17.6030
2024-06-20 19:29:19,124 - mmseg - INFO - Iter [14800/20000]	lr: 6.653e-06, eta: 2:09:42, time: 1.497, data_time: 0.003, memory: 10122, decode.loss_mask: 13.5753, decode.loss_dice: 2.6220, decode.acc_seg: 440.8373, loss: 16.1974
2024-06-20 19:30:32,629 - mmseg - INFO - Iter [14850/20000]	lr: 6.604e-06, eta: 2:08:27, time: 1.470, data_time: 0.003, memory: 10122, decode.loss_mask: 12.9392, decode.loss_dice: 2.3497, decode.acc_seg: 451.1548, loss: 15.2889
2024-06-20 19:31:47,196 - mmseg - INFO - Iter [14900/20000]	lr: 6.555e-06, eta: 2:07:12, time: 1.491, data_time: 0.003, memory: 10122, decode.loss_mask: 10.5142, decode.loss_dice: 2.5581, decode.acc_seg: 448.1159, loss: 13.0722
2024-06-20 19:33:01,524 - mmseg - INFO - Iter [14950/20000]	lr: 6.506e-06, eta: 2:05:57, time: 1.487, data_time: 0.003, memory: 10122, decode.loss_mask: 14.5351, decode.loss_dice: 2.4591, decode.acc_seg: 447.0191, loss: 16.9942
2024-06-20 19:34:16,003 - mmseg - INFO - Exp name: xxscales_input_vpt_seg_zero_vit-b_512x512_20k_12_10.py
2024-06-20 19:34:16,003 - mmseg - INFO - Iter [15000/20000]	lr: 6.457e-06, eta: 2:04:42, time: 1.490, data_time: 0.003, memory: 10122, decode.loss_mask: 13.8885, decode.loss_dice: 2.6575, decode.acc_seg: 439.8217, loss: 16.5460
2024-06-20 19:35:30,645 - mmseg - INFO - Iter [15050/20000]	lr: 6.408e-06, eta: 2:03:27, time: 1.493, data_time: 0.003, memory: 10122, decode.loss_mask: 14.1318, decode.loss_dice: 2.5094, decode.acc_seg: 436.5313, loss: 16.6413
2024-06-20 19:36:47,304 - mmseg - INFO - Iter [15100/20000]	lr: 6.359e-06, eta: 2:02:13, time: 1.533, data_time: 0.044, memory: 10122, decode.loss_mask: 12.6413, decode.loss_dice: 2.4406, decode.acc_seg: 453.4955, loss: 15.0819
2024-06-20 19:38:01,881 - mmseg - INFO - Iter [15150/20000]	lr: 6.310e-06, eta: 2:00:58, time: 1.492, data_time: 0.003, memory: 10122, decode.loss_mask: 15.2420, decode.loss_dice: 2.7067, decode.acc_seg: 429.6532, loss: 17.9487
2024-06-20 19:39:16,296 - mmseg - INFO - Iter [15200/20000]	lr: 6.260e-06, eta: 1:59:43, time: 1.488, data_time: 0.003, memory: 10122, decode.loss_mask: 12.2288, decode.loss_dice: 2.4952, decode.acc_seg: 446.1255, loss: 14.7240
2024-06-20 19:40:30,852 - mmseg - INFO - Iter [15250/20000]	lr: 6.211e-06, eta: 1:58:28, time: 1.491, data_time: 0.003, memory: 10122, decode.loss_mask: 12.2665, decode.loss_dice: 2.5116, decode.acc_seg: 439.2305, loss: 14.7781
2024-06-20 19:41:45,743 - mmseg - INFO - Iter [15300/20000]	lr: 6.162e-06, eta: 1:57:13, time: 1.498, data_time: 0.003, memory: 10122, decode.loss_mask: 12.8485, decode.loss_dice: 2.4978, decode.acc_seg: 451.3810, loss: 15.3464
2024-06-20 19:43:00,325 - mmseg - INFO - Iter [15350/20000]	lr: 6.112e-06, eta: 1:55:58, time: 1.492, data_time: 0.003, memory: 10122, decode.loss_mask: 11.5255, decode.loss_dice: 2.5467, decode.acc_seg: 450.3673, loss: 14.0722
2024-06-20 19:44:14,599 - mmseg - INFO - Iter [15400/20000]	lr: 6.063e-06, eta: 1:54:43, time: 1.485, data_time: 0.003, memory: 10122, decode.loss_mask: 13.1221, decode.loss_dice: 2.5627, decode.acc_seg: 442.4562, loss: 15.6847
2024-06-20 19:45:29,130 - mmseg - INFO - Iter [15450/20000]	lr: 6.013e-06, eta: 1:53:28, time: 1.491, data_time: 0.003, memory: 10122, decode.loss_mask: 15.0871, decode.loss_dice: 2.5801, decode.acc_seg: 433.6925, loss: 17.6672
2024-06-20 19:46:43,114 - mmseg - INFO - Iter [15500/20000]	lr: 5.964e-06, eta: 1:52:13, time: 1.480, data_time: 0.003, memory: 10122, decode.loss_mask: 13.9773, decode.loss_dice: 2.6786, decode.acc_seg: 433.3031, loss: 16.6559
2024-06-20 19:47:57,353 - mmseg - INFO - Iter [15550/20000]	lr: 5.914e-06, eta: 1:50:58, time: 1.485, data_time: 0.003, memory: 10122, decode.loss_mask: 11.4970, decode.loss_dice: 2.5715, decode.acc_seg: 442.5229, loss: 14.0685
2024-06-20 19:49:12,190 - mmseg - INFO - Iter [15600/20000]	lr: 5.864e-06, eta: 1:49:44, time: 1.497, data_time: 0.003, memory: 10122, decode.loss_mask: 13.6325, decode.loss_dice: 2.4452, decode.acc_seg: 443.7749, loss: 16.0777
2024-06-20 19:50:26,662 - mmseg - INFO - Iter [15650/20000]	lr: 5.815e-06, eta: 1:48:29, time: 1.489, data_time: 0.003, memory: 10122, decode.loss_mask: 13.7719, decode.loss_dice: 2.2744, decode.acc_seg: 453.0281, loss: 16.0463
2024-06-20 19:51:41,912 - mmseg - INFO - Iter [15700/20000]	lr: 5.765e-06, eta: 1:47:14, time: 1.505, data_time: 0.003, memory: 10122, decode.loss_mask: 12.7214, decode.loss_dice: 2.5142, decode.acc_seg: 440.4546, loss: 15.2356
2024-06-20 19:52:56,456 - mmseg - INFO - Iter [15750/20000]	lr: 5.715e-06, eta: 1:45:59, time: 1.491, data_time: 0.003, memory: 10122, decode.loss_mask: 12.8894, decode.loss_dice: 2.5349, decode.acc_seg: 442.4438, loss: 15.4244
2024-06-20 19:54:10,934 - mmseg - INFO - Iter [15800/20000]	lr: 5.665e-06, eta: 1:44:44, time: 1.490, data_time: 0.003, memory: 10122, decode.loss_mask: 13.4198, decode.loss_dice: 2.5989, decode.acc_seg: 440.6643, loss: 16.0188
2024-06-20 19:55:25,543 - mmseg - INFO - Iter [15850/20000]	lr: 5.615e-06, eta: 1:43:29, time: 1.492, data_time: 0.003, memory: 10122, decode.loss_mask: 11.8679, decode.loss_dice: 2.2885, decode.acc_seg: 434.7076, loss: 14.1564
2024-06-20 19:56:39,894 - mmseg - INFO - Iter [15900/20000]	lr: 5.565e-06, eta: 1:42:14, time: 1.487, data_time: 0.003, memory: 10122, decode.loss_mask: 13.6471, decode.loss_dice: 2.4313, decode.acc_seg: 440.1949, loss: 16.0784
2024-06-20 19:57:54,666 - mmseg - INFO - Iter [15950/20000]	lr: 5.515e-06, eta: 1:40:59, time: 1.495, data_time: 0.003, memory: 10122, decode.loss_mask: 15.5347, decode.loss_dice: 2.3522, decode.acc_seg: 443.6714, loss: 17.8869
2024-06-20 19:59:09,080 - mmseg - INFO - Saving checkpoint at 16000 iterations
2024-06-20 19:59:10,009 - mmseg - INFO - Exp name: xxscales_input_vpt_seg_zero_vit-b_512x512_20k_12_10.py
2024-06-20 19:59:10,009 - mmseg - INFO - Iter [16000/20000]	lr: 5.465e-06, eta: 1:39:45, time: 1.507, data_time: 0.003, memory: 10122, decode.loss_mask: 13.1258, decode.loss_dice: 2.4074, decode.acc_seg: 443.5095, loss: 15.5331
2024-06-20 20:00:23,999 - mmseg - INFO - Iter [16050/20000]	lr: 5.414e-06, eta: 1:38:30, time: 1.480, data_time: 0.003, memory: 10122, decode.loss_mask: 12.3006, decode.loss_dice: 2.6197, decode.acc_seg: 447.7701, loss: 14.9203
2024-06-20 20:01:37,981 - mmseg - INFO - Iter [16100/20000]	lr: 5.364e-06, eta: 1:37:15, time: 1.480, data_time: 0.003, memory: 10122, decode.loss_mask: 10.9397, decode.loss_dice: 2.2541, decode.acc_seg: 457.6323, loss: 13.1939
2024-06-20 20:02:52,530 - mmseg - INFO - Iter [16150/20000]	lr: 5.314e-06, eta: 1:36:00, time: 1.491, data_time: 0.003, memory: 10122, decode.loss_mask: 14.3454, decode.loss_dice: 2.4676, decode.acc_seg: 436.4638, loss: 16.8131
2024-06-20 20:04:07,033 - mmseg - INFO - Iter [16200/20000]	lr: 5.263e-06, eta: 1:34:45, time: 1.490, data_time: 0.003, memory: 10122, decode.loss_mask: 13.0590, decode.loss_dice: 2.2290, decode.acc_seg: 452.5709, loss: 15.2880
2024-06-20 20:05:21,580 - mmseg - INFO - Iter [16250/20000]	lr: 5.213e-06, eta: 1:33:30, time: 1.491, data_time: 0.003, memory: 10122, decode.loss_mask: 13.1460, decode.loss_dice: 2.4666, decode.acc_seg: 441.8947, loss: 15.6126
2024-06-20 20:06:36,338 - mmseg - INFO - Iter [16300/20000]	lr: 5.162e-06, eta: 1:32:15, time: 1.495, data_time: 0.003, memory: 10122, decode.loss_mask: 16.7180, decode.loss_dice: 2.4859, decode.acc_seg: 432.8212, loss: 19.2039
2024-06-20 20:07:51,235 - mmseg - INFO - Iter [16350/20000]	lr: 5.111e-06, eta: 1:31:01, time: 1.498, data_time: 0.003, memory: 10122, decode.loss_mask: 10.9399, decode.loss_dice: 2.4866, decode.acc_seg: 439.3078, loss: 13.4266
2024-06-20 20:09:05,635 - mmseg - INFO - Iter [16400/20000]	lr: 5.061e-06, eta: 1:29:46, time: 1.488, data_time: 0.003, memory: 10122, decode.loss_mask: 13.0746, decode.loss_dice: 2.5027, decode.acc_seg: 441.6721, loss: 15.5772
2024-06-20 20:10:18,926 - mmseg - INFO - Iter [16450/20000]	lr: 5.010e-06, eta: 1:28:30, time: 1.466, data_time: 0.003, memory: 10122, decode.loss_mask: 15.0083, decode.loss_dice: 2.3886, decode.acc_seg: 441.9698, loss: 17.3969
2024-06-20 20:11:32,679 - mmseg - INFO - Iter [16500/20000]	lr: 4.959e-06, eta: 1:27:15, time: 1.475, data_time: 0.003, memory: 10122, decode.loss_mask: 12.7955, decode.loss_dice: 2.2166, decode.acc_seg: 444.6535, loss: 15.0121
2024-06-20 20:12:46,712 - mmseg - INFO - Iter [16550/20000]	lr: 4.908e-06, eta: 1:26:00, time: 1.481, data_time: 0.003, memory: 10122, decode.loss_mask: 13.8906, decode.loss_dice: 2.6592, decode.acc_seg: 424.5206, loss: 16.5498
2024-06-20 20:14:01,541 - mmseg - INFO - Iter [16600/20000]	lr: 4.857e-06, eta: 1:24:46, time: 1.497, data_time: 0.003, memory: 10122, decode.loss_mask: 14.1888, decode.loss_dice: 2.5179, decode.acc_seg: 443.1424, loss: 16.7067
2024-06-20 20:15:16,191 - mmseg - INFO - Iter [16650/20000]	lr: 4.806e-06, eta: 1:23:31, time: 1.493, data_time: 0.003, memory: 10122, decode.loss_mask: 12.5982, decode.loss_dice: 2.5115, decode.acc_seg: 442.9670, loss: 15.1097
2024-06-20 20:16:31,185 - mmseg - INFO - Iter [16700/20000]	lr: 4.755e-06, eta: 1:22:16, time: 1.500, data_time: 0.003, memory: 10122, decode.loss_mask: 13.3333, decode.loss_dice: 2.3401, decode.acc_seg: 451.1270, loss: 15.6734
2024-06-20 20:17:45,730 - mmseg - INFO - Iter [16750/20000]	lr: 4.704e-06, eta: 1:21:01, time: 1.491, data_time: 0.003, memory: 10122, decode.loss_mask: 14.4704, decode.loss_dice: 2.2772, decode.acc_seg: 432.7717, loss: 16.7476
2024-06-20 20:19:00,438 - mmseg - INFO - Iter [16800/20000]	lr: 4.652e-06, eta: 1:19:46, time: 1.494, data_time: 0.003, memory: 10122, decode.loss_mask: 14.0179, decode.loss_dice: 2.5350, decode.acc_seg: 435.6479, loss: 16.5529
2024-06-20 20:20:15,070 - mmseg - INFO - Iter [16850/20000]	lr: 4.601e-06, eta: 1:18:32, time: 1.493, data_time: 0.003, memory: 10122, decode.loss_mask: 12.7671, decode.loss_dice: 2.2766, decode.acc_seg: 449.4196, loss: 15.0437
2024-06-20 20:21:29,858 - mmseg - INFO - Iter [16900/20000]	lr: 4.550e-06, eta: 1:17:17, time: 1.496, data_time: 0.003, memory: 10122, decode.loss_mask: 12.1682, decode.loss_dice: 2.3139, decode.acc_seg: 453.9285, loss: 14.4821
2024-06-20 20:22:44,405 - mmseg - INFO - Iter [16950/20000]	lr: 4.498e-06, eta: 1:16:02, time: 1.491, data_time: 0.003, memory: 10122, decode.loss_mask: 12.2121, decode.loss_dice: 2.5552, decode.acc_seg: 437.6692, loss: 14.7673
2024-06-20 20:23:58,900 - mmseg - INFO - Exp name: xxscales_input_vpt_seg_zero_vit-b_512x512_20k_12_10.py
2024-06-20 20:23:58,900 - mmseg - INFO - Iter [17000/20000]	lr: 4.446e-06, eta: 1:14:47, time: 1.490, data_time: 0.003, memory: 10122, decode.loss_mask: 14.3544, decode.loss_dice: 2.7120, decode.acc_seg: 431.7338, loss: 17.0664
2024-06-20 20:25:13,352 - mmseg - INFO - Iter [17050/20000]	lr: 4.395e-06, eta: 1:13:32, time: 1.489, data_time: 0.003, memory: 10122, decode.loss_mask: 11.4206, decode.loss_dice: 2.5837, decode.acc_seg: 433.9994, loss: 14.0042
2024-06-20 20:26:28,042 - mmseg - INFO - Iter [17100/20000]	lr: 4.343e-06, eta: 1:12:17, time: 1.494, data_time: 0.003, memory: 10122, decode.loss_mask: 10.9745, decode.loss_dice: 2.4180, decode.acc_seg: 442.5541, loss: 13.3925
2024-06-20 20:27:42,637 - mmseg - INFO - Iter [17150/20000]	lr: 4.291e-06, eta: 1:11:03, time: 1.492, data_time: 0.003, memory: 10122, decode.loss_mask: 15.0450, decode.loss_dice: 2.3283, decode.acc_seg: 437.7525, loss: 17.3733
2024-06-20 20:28:57,368 - mmseg - INFO - Iter [17200/20000]	lr: 4.239e-06, eta: 1:09:48, time: 1.495, data_time: 0.003, memory: 10122, decode.loss_mask: 14.8580, decode.loss_dice: 2.4888, decode.acc_seg: 438.8668, loss: 17.3468
2024-06-20 20:30:11,988 - mmseg - INFO - Iter [17250/20000]	lr: 4.187e-06, eta: 1:08:33, time: 1.492, data_time: 0.003, memory: 10122, decode.loss_mask: 13.0954, decode.loss_dice: 2.6204, decode.acc_seg: 443.3216, loss: 15.7159
2024-06-20 20:31:26,313 - mmseg - INFO - Iter [17300/20000]	lr: 4.135e-06, eta: 1:07:18, time: 1.487, data_time: 0.003, memory: 10122, decode.loss_mask: 13.0620, decode.loss_dice: 2.6529, decode.acc_seg: 428.6101, loss: 15.7148
2024-06-20 20:32:40,823 - mmseg - INFO - Iter [17350/20000]	lr: 4.082e-06, eta: 1:06:03, time: 1.490, data_time: 0.003, memory: 10122, decode.loss_mask: 10.9986, decode.loss_dice: 2.4016, decode.acc_seg: 446.9748, loss: 13.4002
2024-06-20 20:33:55,393 - mmseg - INFO - Iter [17400/20000]	lr: 4.030e-06, eta: 1:04:49, time: 1.491, data_time: 0.003, memory: 10122, decode.loss_mask: 13.3723, decode.loss_dice: 2.3382, decode.acc_seg: 444.8799, loss: 15.7105
2024-06-20 20:35:09,966 - mmseg - INFO - Iter [17450/20000]	lr: 3.978e-06, eta: 1:03:34, time: 1.491, data_time: 0.003, memory: 10122, decode.loss_mask: 13.7175, decode.loss_dice: 2.5266, decode.acc_seg: 438.5873, loss: 16.2442
2024-06-20 20:36:24,280 - mmseg - INFO - Iter [17500/20000]	lr: 3.925e-06, eta: 1:02:19, time: 1.486, data_time: 0.003, memory: 10122, decode.loss_mask: 12.5626, decode.loss_dice: 2.5663, decode.acc_seg: 444.5305, loss: 15.1289
2024-06-20 20:37:38,986 - mmseg - INFO - Iter [17550/20000]	lr: 3.872e-06, eta: 1:01:04, time: 1.494, data_time: 0.003, memory: 10122, decode.loss_mask: 9.3384, decode.loss_dice: 2.4834, decode.acc_seg: 447.7287, loss: 11.8218
2024-06-20 20:38:53,477 - mmseg - INFO - Iter [17600/20000]	lr: 3.820e-06, eta: 0:59:49, time: 1.490, data_time: 0.003, memory: 10122, decode.loss_mask: 13.5120, decode.loss_dice: 2.4155, decode.acc_seg: 451.2451, loss: 15.9275
2024-06-20 20:40:08,008 - mmseg - INFO - Iter [17650/20000]	lr: 3.767e-06, eta: 0:58:34, time: 1.491, data_time: 0.003, memory: 10122, decode.loss_mask: 11.6037, decode.loss_dice: 2.5430, decode.acc_seg: 439.4688, loss: 14.1467
2024-06-20 20:41:22,469 - mmseg - INFO - Iter [17700/20000]	lr: 3.714e-06, eta: 0:57:20, time: 1.489, data_time: 0.003, memory: 10122, decode.loss_mask: 13.0941, decode.loss_dice: 2.4469, decode.acc_seg: 443.3306, loss: 15.5410
2024-06-20 20:42:37,373 - mmseg - INFO - Iter [17750/20000]	lr: 3.661e-06, eta: 0:56:05, time: 1.498, data_time: 0.003, memory: 10122, decode.loss_mask: 11.2472, decode.loss_dice: 2.1896, decode.acc_seg: 450.7181, loss: 13.4367
2024-06-20 20:43:51,831 - mmseg - INFO - Iter [17800/20000]	lr: 3.607e-06, eta: 0:54:50, time: 1.489, data_time: 0.003, memory: 10122, decode.loss_mask: 12.7072, decode.loss_dice: 2.2780, decode.acc_seg: 450.7347, loss: 14.9852
2024-06-20 20:45:06,579 - mmseg - INFO - Iter [17850/20000]	lr: 3.554e-06, eta: 0:53:35, time: 1.495, data_time: 0.003, memory: 10122, decode.loss_mask: 11.4062, decode.loss_dice: 2.3021, decode.acc_seg: 448.3275, loss: 13.7083
2024-06-20 20:46:21,386 - mmseg - INFO - Iter [17900/20000]	lr: 3.500e-06, eta: 0:52:20, time: 1.496, data_time: 0.003, memory: 10122, decode.loss_mask: 11.0716, decode.loss_dice: 2.2275, decode.acc_seg: 453.4677, loss: 13.2991
2024-06-20 20:47:35,455 - mmseg - INFO - Iter [17950/20000]	lr: 3.447e-06, eta: 0:51:06, time: 1.481, data_time: 0.003, memory: 10122, decode.loss_mask: 13.1085, decode.loss_dice: 2.2834, decode.acc_seg: 443.7411, loss: 15.3919
2024-06-20 20:48:49,581 - mmseg - INFO - Saving checkpoint at 18000 iterations
2024-06-20 20:48:50,518 - mmseg - INFO - Exp name: xxscales_input_vpt_seg_zero_vit-b_512x512_20k_12_10.py
2024-06-20 20:48:50,518 - mmseg - INFO - Iter [18000/20000]	lr: 3.393e-06, eta: 0:49:51, time: 1.501, data_time: 0.003, memory: 10122, decode.loss_mask: 13.2365, decode.loss_dice: 2.5000, decode.acc_seg: 442.8134, loss: 15.7365
2024-06-20 20:50:03,613 - mmseg - INFO - Iter [18050/20000]	lr: 3.339e-06, eta: 0:48:36, time: 1.462, data_time: 0.003, memory: 10122, decode.loss_mask: 12.9324, decode.loss_dice: 2.2984, decode.acc_seg: 440.8536, loss: 15.2308
2024-06-20 20:51:18,791 - mmseg - INFO - Iter [18100/20000]	lr: 3.285e-06, eta: 0:47:21, time: 1.504, data_time: 0.043, memory: 10122, decode.loss_mask: 10.5419, decode.loss_dice: 2.3201, decode.acc_seg: 452.7920, loss: 12.8620
2024-06-20 20:52:31,897 - mmseg - INFO - Iter [18150/20000]	lr: 3.231e-06, eta: 0:46:06, time: 1.462, data_time: 0.003, memory: 10122, decode.loss_mask: 12.5719, decode.loss_dice: 2.3271, decode.acc_seg: 440.1215, loss: 14.8989
2024-06-20 20:53:44,702 - mmseg - INFO - Iter [18200/20000]	lr: 3.177e-06, eta: 0:44:51, time: 1.456, data_time: 0.003, memory: 10122, decode.loss_mask: 12.8901, decode.loss_dice: 2.5757, decode.acc_seg: 448.9005, loss: 15.4658
2024-06-20 20:54:58,019 - mmseg - INFO - Iter [18250/20000]	lr: 3.122e-06, eta: 0:43:36, time: 1.466, data_time: 0.003, memory: 10122, decode.loss_mask: 12.2685, decode.loss_dice: 2.5622, decode.acc_seg: 443.0880, loss: 14.8307
2024-06-20 20:56:10,988 - mmseg - INFO - Iter [18300/20000]	lr: 3.068e-06, eta: 0:42:21, time: 1.459, data_time: 0.003, memory: 10122, decode.loss_mask: 11.8604, decode.loss_dice: 2.5848, decode.acc_seg: 439.8041, loss: 14.4452
2024-06-20 20:57:23,573 - mmseg - INFO - Iter [18350/20000]	lr: 3.013e-06, eta: 0:41:06, time: 1.452, data_time: 0.003, memory: 10122, decode.loss_mask: 12.4386, decode.loss_dice: 2.5291, decode.acc_seg: 441.5688, loss: 14.9677
2024-06-20 20:58:36,278 - mmseg - INFO - Iter [18400/20000]	lr: 2.958e-06, eta: 0:39:51, time: 1.454, data_time: 0.003, memory: 10122, decode.loss_mask: 12.5681, decode.loss_dice: 2.3963, decode.acc_seg: 441.6903, loss: 14.9644
2024-06-20 20:59:49,263 - mmseg - INFO - Iter [18450/20000]	lr: 2.903e-06, eta: 0:38:37, time: 1.460, data_time: 0.003, memory: 10122, decode.loss_mask: 12.1089, decode.loss_dice: 2.2887, decode.acc_seg: 439.4756, loss: 14.3976
2024-06-20 21:01:02,069 - mmseg - INFO - Iter [18500/20000]	lr: 2.847e-06, eta: 0:37:22, time: 1.456, data_time: 0.003, memory: 10122, decode.loss_mask: 13.3439, decode.loss_dice: 2.3973, decode.acc_seg: 445.5973, loss: 15.7412
2024-06-20 21:02:15,098 - mmseg - INFO - Iter [18550/20000]	lr: 2.792e-06, eta: 0:36:07, time: 1.461, data_time: 0.003, memory: 10122, decode.loss_mask: 13.3674, decode.loss_dice: 2.3930, decode.acc_seg: 434.3442, loss: 15.7603
2024-06-20 21:03:28,096 - mmseg - INFO - Iter [18600/20000]	lr: 2.736e-06, eta: 0:34:52, time: 1.460, data_time: 0.003, memory: 10122, decode.loss_mask: 12.7040, decode.loss_dice: 2.4676, decode.acc_seg: 442.0413, loss: 15.1716
2024-06-20 21:04:41,155 - mmseg - INFO - Iter [18650/20000]	lr: 2.680e-06, eta: 0:33:37, time: 1.461, data_time: 0.003, memory: 10122, decode.loss_mask: 14.8817, decode.loss_dice: 2.7022, decode.acc_seg: 436.8330, loss: 17.5839
2024-06-20 21:05:54,256 - mmseg - INFO - Iter [18700/20000]	lr: 2.624e-06, eta: 0:32:22, time: 1.462, data_time: 0.003, memory: 10122, decode.loss_mask: 13.0402, decode.loss_dice: 2.4293, decode.acc_seg: 444.5055, loss: 15.4695
2024-06-20 21:07:06,837 - mmseg - INFO - Iter [18750/20000]	lr: 2.568e-06, eta: 0:31:07, time: 1.452, data_time: 0.003, memory: 10122, decode.loss_mask: 12.1489, decode.loss_dice: 2.3758, decode.acc_seg: 450.3981, loss: 14.5247
2024-06-20 21:08:19,838 - mmseg - INFO - Iter [18800/20000]	lr: 2.512e-06, eta: 0:29:53, time: 1.460, data_time: 0.003, memory: 10122, decode.loss_mask: 13.4999, decode.loss_dice: 2.2937, decode.acc_seg: 450.7332, loss: 15.7936
2024-06-20 21:09:32,738 - mmseg - INFO - Iter [18850/20000]	lr: 2.455e-06, eta: 0:28:38, time: 1.458, data_time: 0.003, memory: 10122, decode.loss_mask: 12.4822, decode.loss_dice: 2.3941, decode.acc_seg: 446.2399, loss: 14.8762
2024-06-20 21:10:46,040 - mmseg - INFO - Iter [18900/20000]	lr: 2.398e-06, eta: 0:27:23, time: 1.466, data_time: 0.003, memory: 10122, decode.loss_mask: 13.5934, decode.loss_dice: 2.2993, decode.acc_seg: 447.6077, loss: 15.8927
2024-06-20 21:11:58,614 - mmseg - INFO - Iter [18950/20000]	lr: 2.341e-06, eta: 0:26:08, time: 1.451, data_time: 0.003, memory: 10122, decode.loss_mask: 12.1046, decode.loss_dice: 2.3016, decode.acc_seg: 444.7491, loss: 14.4062
2024-06-20 21:13:11,390 - mmseg - INFO - Exp name: xxscales_input_vpt_seg_zero_vit-b_512x512_20k_12_10.py
2024-06-20 21:13:11,391 - mmseg - INFO - Iter [19000/20000]	lr: 2.283e-06, eta: 0:24:53, time: 1.456, data_time: 0.003, memory: 10122, decode.loss_mask: 11.7633, decode.loss_dice: 2.2998, decode.acc_seg: 444.9568, loss: 14.0631
2024-06-20 21:14:24,467 - mmseg - INFO - Iter [19050/20000]	lr: 2.225e-06, eta: 0:23:39, time: 1.462, data_time: 0.003, memory: 10122, decode.loss_mask: 11.2413, decode.loss_dice: 2.5550, decode.acc_seg: 446.7101, loss: 13.7963
2024-06-20 21:15:38,560 - mmseg - INFO - Iter [19100/20000]	lr: 2.167e-06, eta: 0:22:24, time: 1.482, data_time: 0.003, memory: 10122, decode.loss_mask: 14.3130, decode.loss_dice: 2.5118, decode.acc_seg: 437.5743, loss: 16.8248
2024-06-20 21:16:54,246 - mmseg - INFO - Iter [19150/20000]	lr: 2.109e-06, eta: 0:21:09, time: 1.514, data_time: 0.003, memory: 10122, decode.loss_mask: 11.5630, decode.loss_dice: 2.4241, decode.acc_seg: 451.0349, loss: 13.9871
2024-06-20 21:18:08,774 - mmseg - INFO - Iter [19200/20000]	lr: 2.050e-06, eta: 0:19:54, time: 1.491, data_time: 0.003, memory: 10122, decode.loss_mask: 13.7993, decode.loss_dice: 2.7304, decode.acc_seg: 430.5255, loss: 16.5297
2024-06-20 21:19:23,004 - mmseg - INFO - Iter [19250/20000]	lr: 1.991e-06, eta: 0:18:40, time: 1.485, data_time: 0.003, memory: 10122, decode.loss_mask: 11.8171, decode.loss_dice: 2.4342, decode.acc_seg: 457.7162, loss: 14.2513
2024-06-20 21:20:37,455 - mmseg - INFO - Iter [19300/20000]	lr: 1.931e-06, eta: 0:17:25, time: 1.489, data_time: 0.003, memory: 10122, decode.loss_mask: 11.2218, decode.loss_dice: 2.3466, decode.acc_seg: 450.0117, loss: 13.5684
2024-06-20 21:21:51,613 - mmseg - INFO - Iter [19350/20000]	lr: 1.871e-06, eta: 0:16:10, time: 1.483, data_time: 0.003, memory: 10122, decode.loss_mask: 12.2087, decode.loss_dice: 2.3107, decode.acc_seg: 451.8565, loss: 14.5194
2024-06-20 21:23:06,342 - mmseg - INFO - Iter [19400/20000]	lr: 1.811e-06, eta: 0:14:56, time: 1.495, data_time: 0.003, memory: 10122, decode.loss_mask: 12.9167, decode.loss_dice: 2.4126, decode.acc_seg: 446.8905, loss: 15.3294
2024-06-20 21:24:20,778 - mmseg - INFO - Iter [19450/20000]	lr: 1.750e-06, eta: 0:13:41, time: 1.489, data_time: 0.003, memory: 10122, decode.loss_mask: 14.0134, decode.loss_dice: 2.4286, decode.acc_seg: 443.2941, loss: 16.4420
2024-06-20 21:25:35,381 - mmseg - INFO - Iter [19500/20000]	lr: 1.688e-06, eta: 0:12:26, time: 1.492, data_time: 0.003, memory: 10122, decode.loss_mask: 12.6786, decode.loss_dice: 2.3893, decode.acc_seg: 446.4489, loss: 15.0679
2024-06-20 21:26:49,824 - mmseg - INFO - Iter [19550/20000]	lr: 1.626e-06, eta: 0:11:12, time: 1.489, data_time: 0.003, memory: 10122, decode.loss_mask: 17.0299, decode.loss_dice: 2.4968, decode.acc_seg: 425.5540, loss: 19.5267
2024-06-20 21:28:04,284 - mmseg - INFO - Iter [19600/20000]	lr: 1.563e-06, eta: 0:09:57, time: 1.489, data_time: 0.003, memory: 10122, decode.loss_mask: 14.4836, decode.loss_dice: 2.5663, decode.acc_seg: 446.1920, loss: 17.0499
2024-06-20 21:29:18,887 - mmseg - INFO - Iter [19650/20000]	lr: 1.500e-06, eta: 0:08:42, time: 1.492, data_time: 0.003, memory: 10122, decode.loss_mask: 11.0901, decode.loss_dice: 2.4737, decode.acc_seg: 437.3057, loss: 13.5638
2024-06-20 21:30:33,662 - mmseg - INFO - Iter [19700/20000]	lr: 1.435e-06, eta: 0:07:28, time: 1.496, data_time: 0.003, memory: 10122, decode.loss_mask: 11.7675, decode.loss_dice: 2.3802, decode.acc_seg: 447.4563, loss: 14.1477
2024-06-20 21:31:48,201 - mmseg - INFO - Iter [19750/20000]	lr: 1.369e-06, eta: 0:06:13, time: 1.491, data_time: 0.003, memory: 10122, decode.loss_mask: 12.1380, decode.loss_dice: 2.5714, decode.acc_seg: 446.9853, loss: 14.7094
2024-06-20 21:33:02,859 - mmseg - INFO - Iter [19800/20000]	lr: 1.302e-06, eta: 0:04:58, time: 1.493, data_time: 0.003, memory: 10122, decode.loss_mask: 13.6282, decode.loss_dice: 2.5170, decode.acc_seg: 445.5930, loss: 16.1452
2024-06-20 21:34:16,818 - mmseg - INFO - Iter [19850/20000]	lr: 1.234e-06, eta: 0:03:44, time: 1.479, data_time: 0.003, memory: 10122, decode.loss_mask: 12.1992, decode.loss_dice: 2.3850, decode.acc_seg: 445.7388, loss: 14.5841
2024-06-20 21:35:31,521 - mmseg - INFO - Iter [19900/20000]	lr: 1.163e-06, eta: 0:02:29, time: 1.494, data_time: 0.003, memory: 10122, decode.loss_mask: 10.7560, decode.loss_dice: 2.3924, decode.acc_seg: 447.9230, loss: 13.1484
2024-06-20 21:36:46,294 - mmseg - INFO - Iter [19950/20000]	lr: 1.088e-06, eta: 0:01:14, time: 1.495, data_time: 0.003, memory: 10122, decode.loss_mask: 13.6348, decode.loss_dice: 2.4077, decode.acc_seg: 456.6964, loss: 16.0425
2024-06-20 21:38:01,117 - mmseg - INFO - Saving checkpoint at 20000 iterations
2024-06-20 21:38:02,032 - mmseg - INFO - Exp name: xxscales_input_vpt_seg_zero_vit-b_512x512_20k_12_10.py
2024-06-20 21:38:02,032 - mmseg - INFO - Iter [20000/20000]	lr: 1.003e-06, eta: 0:00:00, time: 1.515, data_time: 0.003, memory: 10122, decode.loss_mask: 11.0686, decode.loss_dice: 2.4401, decode.acc_seg: 452.2490, loss: 13.5086
