/mnt/fast/nobackup/scratch4weeks/ae01116/zegenv/lib/python3.9/site-packages/torch/distributed/launch.py:178: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
2024-06-23 15:18:38,307 - mmseg - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.9.19 (main, May  6 2024, 19:43:03) [GCC 11.2.0]
CUDA available: True
GPU 0,1,2,3: NVIDIA GeForce RTX 3090
CUDA_HOME: /usr/local/cuda
NVCC: Build cuda_11.0_bu.TC445_37.28845127_0
GCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
PyTorch: 1.10.1+cu111
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

TorchVision: 0.11.2+cu111
OpenCV: 4.10.0
MMCV: 1.4.4
MMCV Compiler: GCC 7.3
MMCV CUDA Compiler: 11.1
------------------------------------------------------------

2024-06-23 15:18:38,307 - mmseg - INFO - Distributed training: True
2024-06-23 15:18:39,185 - mmseg - INFO - Config:
norm_cfg = dict(type='SyncBN', requires_grad=True)
img_size = 512
in_channels = 512
out_indices = [11]
model = dict(
    type='MultiScalesZegCLIP',
    pretrained='/mnt/fast/nobackup/scratch4weeks/ae01116/weights/ViT-B-16.pt',
    context_length=77,
    backbone=dict(
        type='VPTCLIPVisionTransformer',
        layers=12,
        style='pytorch',
        patch_size=16,
        width=768,
        output_dim=512,
        get_embeddings=True,
        drop_path_rate=0.1,
        input_resolution=512,
        out_indices=[11],
        num_tokens=10,
        prompt_dim=768,
        total_d_layer=11),
    text_encoder=dict(
        type='CLIPTextEncoder',
        context_length=77,
        style='pytorch',
        embed_dim=512,
        transformer_width=512,
        transformer_heads=8,
        transformer_layers=12),
    decode_head=dict(
        type='ATMSingleHeadSeg',
        img_size=512,
        in_channels=512,
        channels=512,
        num_classes=15,
        num_layers=3,
        num_heads=8,
        use_stages=1,
        embed_dims=512,
        loss_decode=dict(
            type='SegLossPlus',
            num_classes=15,
            dec_layers=3,
            loss_weight=1.0,
            mask_weight=100.0,
            dice_weight=1.0),
        seen_idx=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14],
        all_idx=[
            0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18,
            19
        ],
        use_proj=False),
    train_cfg=dict(),
    test_cfg=dict(mode='slide', crop_size=(512, 512), stride=(426, 426)),
    pretrained_text=
    '/mnt/fast/nobackup/scratch4weeks/ae01116/weights/ViT-B-16.pt',
    multi_scale=dict(type='MultiScales', divisions=[2]),
    base_class=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14],
    novel_class=[15, 16, 17, 18, 19],
    both_class=[
        0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19
    ],
    ft_backbone=False,
    exclude_key='prompt',
    load_text_embedding=
    '/mnt/fast/nobackup/users/ae01116/multi-modal-dissertation-uos/configs/_base_/datasets/text_embedding/voc12_single.npy'
)
dataset_type = 'ZeroPascalVOCDataset20'
base = '/mnt/fast/nobackup/users/ae01116/multi-modal-dissertation-uos'
base_scratch = '/mnt/fast/nobackup/scratch4weeks/ae01116'
data_root = '/mnt/fast/nobackup/scratch4weeks/ae01116/data/VOC2012'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
crop_size = (512, 512)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations', reduce_zero_label=True),
    dict(type='Resize', img_scale=(2048, 512), ratio_range=(0.5, 2.0)),
    dict(type='RandomCrop', crop_size=(512, 512), cat_max_ratio=0.75),
    dict(type='RandomFlip', prob=0.5),
    dict(type='PhotoMetricDistortion'),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='Pad', size=(512, 512), pad_val=0, seg_pad_val=255),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_semantic_seg'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(2048, 512),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True, min_size=512),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
data = dict(
    samples_per_gpu=2,
    workers_per_gpu=2,
    train=dict(
        type='ZeroPascalVOCDataset20',
        data_root='/mnt/fast/nobackup/scratch4weeks/ae01116/data/VOC2012',
        img_dir='JPEGImages',
        ann_dir=['SegmentationClass', 'SegmentationClassAug'],
        split=[
            'ImageSets/Segmentation/train.txt',
            'ImageSets/Segmentation/aug.txt'
        ],
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations', reduce_zero_label=True),
            dict(type='Resize', img_scale=(2048, 512), ratio_range=(0.5, 2.0)),
            dict(type='RandomCrop', crop_size=(512, 512), cat_max_ratio=0.75),
            dict(type='RandomFlip', prob=0.5),
            dict(type='PhotoMetricDistortion'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size=(512, 512), pad_val=0, seg_pad_val=255),
            dict(type='DefaultFormatBundle'),
            dict(type='Collect', keys=['img', 'gt_semantic_seg'])
        ]),
    val=dict(
        type='ZeroPascalVOCDataset20',
        data_root='/mnt/fast/nobackup/scratch4weeks/ae01116/data/VOC2012',
        img_dir='JPEGImages',
        ann_dir='SegmentationClass',
        split='ImageSets/Segmentation/val.txt',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(2048, 512),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True, min_size=512),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]),
    test=dict(
        type='ZeroPascalVOCDataset20',
        data_root='/mnt/fast/nobackup/scratch4weeks/ae01116/data/VOC2012',
        img_dir='JPEGImages',
        ann_dir='SegmentationClass',
        split='ImageSets/Segmentation/val.txt',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(2048, 512),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True, min_size=512),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]))
log_config = dict(
    interval=50, hooks=[dict(type='TextLoggerHook', by_epoch=False)])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
cudnn_benchmark = True
find_unused_parameters = True
optimizer = dict(
    type='AdamW',
    lr=2e-05,
    weight_decay=0.01,
    paramwise_cfg=dict(
        custom_keys=dict(
            backbone=dict(lr_mult=10.0),
            text_encoder=dict(lr_mult=0.0),
            norm=dict(decay_mult=0.0),
            ln=dict(decay_mult=0.0),
            head=dict(lr_mult=10.0))))
optimizer_config = dict()
lr_config = dict(
    policy='poly',
    power=0.9,
    min_lr=1e-06,
    by_epoch=False,
    warmup='linear',
    warmup_iters=1500,
    warmup_ratio=1e-06)
runner = dict(type='IterBasedRunner', max_iters=20000)
checkpoint_config = dict(by_epoch=False, interval=2000)
evaluation = dict(interval=20001, metric='mIoU')
base_class = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]
novel_class = [15, 16, 17, 18, 19]
both_class = [
    0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19
]
num_classes = 15
pretrained = '/mnt/fast/nobackup/scratch4weeks/ae01116/weights/ViT-B-16.pt'
work_dir = '/mnt/fast/nobackup/scratch4weeks/ae01116/data/VOC2012'
gpu_ids = range(0, 1)

2024-06-23 15:18:39,187 - mmseg - INFO - Loaded 1464 images
2024-06-23 15:18:39,195 - mmseg - INFO - Loaded 10582 images
2024-06-23 15:18:40,100 - mmseg - INFO - #Params: 164077824
/mnt/fast/nobackup/scratch4weeks/ae01116/zegenv/lib/python3.9/site-packages/torch/nn/functional.py:3631: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  warnings.warn(
/mnt/fast/nobackup/scratch4weeks/ae01116/zegenv/lib/python3.9/site-packages/torch/nn/functional.py:3631: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  warnings.warn(
/mnt/fast/nobackup/scratch4weeks/ae01116/zegenv/lib/python3.9/site-packages/torch/nn/functional.py:3631: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  warnings.warn(
/mnt/fast/nobackup/scratch4weeks/ae01116/zegenv/lib/python3.9/site-packages/torch/nn/functional.py:3631: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  warnings.warn(
fatal: not a git repository (or any parent up to mount point /scratch/condor)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2024-06-23 15:18:40,950 - mmseg - INFO - MultiScalesZegCLIP(
  (backbone): VPTCLIPVisionTransformer(
    (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
    (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (transformer): Transformer(
      (resblocks): Sequential(
        (0): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
        (1): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (drop_path): DropPath(p=0.00909090880304575)
        )
        (2): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (drop_path): DropPath(p=0.0181818176060915)
        )
        (3): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (drop_path): DropPath(p=0.027272727340459824)
        )
        (4): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (drop_path): DropPath(p=0.036363635212183)
        )
        (5): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (drop_path): DropPath(p=0.045454543083906174)
        )
        (6): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (drop_path): DropPath(p=0.054545458406209946)
        )
        (7): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (drop_path): DropPath(p=0.06363636255264282)
        )
        (8): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (drop_path): DropPath(p=0.0727272778749466)
        )
        (9): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (drop_path): DropPath(p=0.08181818574666977)
        )
        (10): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (drop_path): DropPath(p=0.09090909361839294)
        )
        (11): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (drop_path): DropPath(p=0.10000000149011612)
        )
      )
    )
    (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (prompt_proj): Linear(in_features=768, out_features=768, bias=True)
    (prompt_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (prompt_dropout): Dropout(p=0.1, inplace=False)
  )
  (decode_head): ATMSingleHeadSeg(
    input_transform=None, ignore_index=255, align_corners=False
    (loss_decode): SegLossPlus(
      (criterion): SegPlusCriterion()
    )
    (dropout): Dropout2d(p=0.1, inplace=False)
    (input_proj_1): Identity()
    (proj_norm_1): Identity()
    (decoder_1): TPN_Decoder(
      (layers): ModuleList(
        (0): TPN_DecoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (linear1): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=2048, out_features=512, bias=True)
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
          (dropout3): Dropout(p=0.1, inplace=False)
          (multihead_attn): Attention(
            (q): Linear(in_features=512, out_features=512, bias=True)
            (k): Linear(in_features=512, out_features=512, bias=True)
            (v): Linear(in_features=512, out_features=512, bias=True)
            (attn_drop): Dropout(p=0.1, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): TPN_DecoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (linear1): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=2048, out_features=512, bias=True)
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
          (dropout3): Dropout(p=0.1, inplace=False)
          (multihead_attn): Attention(
            (q): Linear(in_features=512, out_features=512, bias=True)
            (k): Linear(in_features=512, out_features=512, bias=True)
            (v): Linear(in_features=512, out_features=512, bias=True)
            (attn_drop): Dropout(p=0.1, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
        )
        (2): TPN_DecoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (linear1): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=2048, out_features=512, bias=True)
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
          (dropout3): Dropout(p=0.1, inplace=False)
          (multihead_attn): Attention(
            (q): Linear(in_features=512, out_features=512, bias=True)
            (k): Linear(in_features=512, out_features=512, bias=True)
            (v): Linear(in_features=512, out_features=512, bias=True)
            (attn_drop): Dropout(p=0.1, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
    (q_proj): Linear(in_features=1024, out_features=512, bias=True)
  )
  init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
  (text_encoder): CLIPTextEncoder(
    (transformer): Transformer(
      (resblocks): Sequential(
        (0): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
        (1): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
        (2): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
        (3): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
        (4): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
        (5): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
        (6): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
        (7): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
        (8): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
        (9): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
        (10): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
        (11): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
    )
    (token_embedding): Embedding(49408, 512)
    (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (_MultiScalesZegCLIP__multi_scale): MultiScales()
)
fatal: not a git repository (or any parent up to mount point /scratch/condor)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
fatal: not a git repository (or any parent up to mount point /scratch/condor)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
fatal: not a git repository (or any parent up to mount point /scratch/condor)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2024-06-23 15:18:45,604 - mmseg - INFO - Loaded 1449 images
2024-06-23 15:18:46,071 - mmseg - INFO - Start running, host: ae01116@ae01116-173169.0-aisurrey18.surrey.ac.uk, work_dir: /mnt/fast/nobackup/scratch4weeks/ae01116/data/VOC2012
2024-06-23 15:18:46,071 - mmseg - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2024-06-23 15:18:46,071 - mmseg - INFO - workflow: [('train', 1)], max: 20000 iters
2024-06-23 15:18:46,071 - mmseg - INFO - Checkpoints will be saved to /mnt/fast/nobackup/scratch4weeks/ae01116/data/VOC2012 by HardDiskBackend.
/mnt/fast/nobackup/scratch4weeks/ae01116/zegenv/lib/python3.9/site-packages/torch/nn/functional.py:3631: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  warnings.warn(
/mnt/fast/nobackup/scratch4weeks/ae01116/zegenv/lib/python3.9/site-packages/torch/nn/functional.py:3631: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  warnings.warn(
/mnt/fast/nobackup/scratch4weeks/ae01116/zegenv/lib/python3.9/site-packages/torch/nn/functional.py:3631: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  warnings.warn(
/mnt/fast/nobackup/scratch4weeks/ae01116/zegenv/lib/python3.9/site-packages/torch/nn/functional.py:3631: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  warnings.warn(
2024-06-23 15:20:19,403 - mmseg - INFO - Iter [50/20000]	lr: 6.520e-07, eta: 9:13:15, time: 1.664, data_time: 0.006, memory: 18995, decode.loss_mask: 912.2705, decode.loss_dice: 3.5926, decode.acc_seg: 47.7857, loss: 915.8631
2024-06-23 15:21:43,242 - mmseg - INFO - Iter [100/20000]	lr: 1.314e-06, eta: 9:13:59, time: 1.677, data_time: 0.005, memory: 18995, decode.loss_mask: 713.7176, decode.loss_dice: 3.7492, decode.acc_seg: 59.4701, loss: 717.4667
2024-06-23 15:23:08,510 - mmseg - INFO - Iter [150/20000]	lr: 1.974e-06, eta: 9:16:28, time: 1.705, data_time: 0.004, memory: 19000, decode.loss_mask: 543.1208, decode.loss_dice: 3.7545, decode.acc_seg: 53.3115, loss: 546.8753
2024-06-23 15:24:33,463 - mmseg - INFO - Iter [200/20000]	lr: 2.631e-06, eta: 9:16:27, time: 1.699, data_time: 0.004, memory: 19000, decode.loss_mask: 243.4472, decode.loss_dice: 3.9215, decode.acc_seg: 51.5305, loss: 247.3687
2024-06-23 15:25:58,778 - mmseg - INFO - Iter [250/20000]	lr: 3.285e-06, eta: 9:16:22, time: 1.706, data_time: 0.004, memory: 19000, decode.loss_mask: 96.6747, decode.loss_dice: 4.1322, decode.acc_seg: 72.0953, loss: 100.8068
2024-06-23 15:27:23,678 - mmseg - INFO - Iter [300/20000]	lr: 3.936e-06, eta: 9:15:23, time: 1.698, data_time: 0.005, memory: 19000, decode.loss_mask: 74.2370, decode.loss_dice: 4.2589, decode.acc_seg: 65.3733, loss: 78.4959
2024-06-23 15:28:48,471 - mmseg - INFO - Iter [350/20000]	lr: 4.584e-06, eta: 9:14:11, time: 1.696, data_time: 0.004, memory: 19004, decode.loss_mask: 65.5372, decode.loss_dice: 4.3423, decode.acc_seg: 72.7023, loss: 69.8794
2024-06-23 15:30:13,384 - mmseg - INFO - Iter [400/20000]	lr: 5.229e-06, eta: 9:13:01, time: 1.698, data_time: 0.004, memory: 19004, decode.loss_mask: 63.1418, decode.loss_dice: 4.3663, decode.acc_seg: 106.2559, loss: 67.5081
2024-06-23 15:31:38,325 - mmseg - INFO - Iter [450/20000]	lr: 5.872e-06, eta: 9:11:49, time: 1.699, data_time: 0.005, memory: 19004, decode.loss_mask: 64.9179, decode.loss_dice: 4.3248, decode.acc_seg: 170.6444, loss: 69.2427
2024-06-23 15:33:03,870 - mmseg - INFO - Iter [500/20000]	lr: 6.511e-06, eta: 9:10:58, time: 1.711, data_time: 0.004, memory: 19029, decode.loss_mask: 62.2418, decode.loss_dice: 4.3197, decode.acc_seg: 165.6999, loss: 66.5615
2024-06-23 15:34:28,749 - mmseg - INFO - Iter [550/20000]	lr: 7.148e-06, eta: 9:09:37, time: 1.698, data_time: 0.004, memory: 19029, decode.loss_mask: 60.9646, decode.loss_dice: 4.3270, decode.acc_seg: 166.6528, loss: 65.2916
2024-06-23 15:35:54,476 - mmseg - INFO - Iter [600/20000]	lr: 7.782e-06, eta: 9:08:43, time: 1.715, data_time: 0.004, memory: 19029, decode.loss_mask: 60.7673, decode.loss_dice: 4.3124, decode.acc_seg: 144.8528, loss: 65.0797
2024-06-23 15:37:20,144 - mmseg - INFO - Iter [650/20000]	lr: 8.413e-06, eta: 9:07:43, time: 1.713, data_time: 0.004, memory: 19029, decode.loss_mask: 63.5111, decode.loss_dice: 4.2391, decode.acc_seg: 155.9812, loss: 67.7502
2024-06-23 15:38:45,971 - mmseg - INFO - Iter [700/20000]	lr: 9.041e-06, eta: 9:06:43, time: 1.717, data_time: 0.004, memory: 19029, decode.loss_mask: 63.3982, decode.loss_dice: 4.2026, decode.acc_seg: 169.5128, loss: 67.6008
2024-06-23 15:40:11,109 - mmseg - INFO - Iter [750/20000]	lr: 9.666e-06, eta: 9:05:22, time: 1.703, data_time: 0.004, memory: 19029, decode.loss_mask: 66.4042, decode.loss_dice: 4.2578, decode.acc_seg: 176.4155, loss: 70.6620
2024-06-23 15:41:37,043 - mmseg - INFO - Iter [800/20000]	lr: 1.029e-05, eta: 9:04:19, time: 1.719, data_time: 0.004, memory: 19029, decode.loss_mask: 57.1173, decode.loss_dice: 4.2159, decode.acc_seg: 185.2782, loss: 61.3332
2024-06-23 15:43:01,171 - mmseg - INFO - Iter [850/20000]	lr: 1.091e-05, eta: 9:02:34, time: 1.683, data_time: 0.004, memory: 19029, decode.loss_mask: 56.0220, decode.loss_dice: 4.2575, decode.acc_seg: 150.8519, loss: 60.2795
2024-06-23 15:44:25,361 - mmseg - INFO - Iter [900/20000]	lr: 1.152e-05, eta: 9:00:51, time: 1.684, data_time: 0.004, memory: 19029, decode.loss_mask: 54.8897, decode.loss_dice: 4.2525, decode.acc_seg: 150.4475, loss: 59.1423
2024-06-23 15:45:49,892 - mmseg - INFO - Iter [950/20000]	lr: 1.214e-05, eta: 8:59:18, time: 1.691, data_time: 0.004, memory: 19029, decode.loss_mask: 57.1194, decode.loss_dice: 4.1647, decode.acc_seg: 149.8698, loss: 61.2841
2024-06-23 15:47:13,912 - mmseg - INFO - Exp name: xxscales_input_vpt_seg_zero_vit-b_512x512_20k_12_10.py
2024-06-23 15:47:13,912 - mmseg - INFO - Iter [1000/20000]	lr: 1.275e-05, eta: 8:57:36, time: 1.680, data_time: 0.004, memory: 19029, decode.loss_mask: 54.5682, decode.loss_dice: 4.0607, decode.acc_seg: 196.7809, loss: 58.6289
2024-06-23 15:48:38,533 - mmseg - INFO - Iter [1050/20000]	lr: 1.336e-05, eta: 8:56:06, time: 1.692, data_time: 0.004, memory: 19029, decode.loss_mask: 48.3900, decode.loss_dice: 4.1730, decode.acc_seg: 163.3909, loss: 52.5630
2024-06-23 15:50:02,366 - mmseg - INFO - Iter [1100/20000]	lr: 1.396e-05, eta: 8:54:23, time: 1.677, data_time: 0.004, memory: 19029, decode.loss_mask: 46.3240, decode.loss_dice: 4.1274, decode.acc_seg: 171.6878, loss: 50.4514
2024-06-23 15:51:26,799 - mmseg - INFO - Iter [1150/20000]	lr: 1.457e-05, eta: 8:52:52, time: 1.689, data_time: 0.005, memory: 19029, decode.loss_mask: 50.8203, decode.loss_dice: 4.0525, decode.acc_seg: 179.8256, loss: 54.8727
2024-06-23 15:52:50,713 - mmseg - INFO - Iter [1200/20000]	lr: 1.516e-05, eta: 8:51:13, time: 1.678, data_time: 0.004, memory: 19029, decode.loss_mask: 51.5058, decode.loss_dice: 4.0541, decode.acc_seg: 171.3470, loss: 55.5599
2024-06-23 15:54:14,441 - mmseg - INFO - Iter [1250/20000]	lr: 1.576e-05, eta: 8:49:33, time: 1.675, data_time: 0.005, memory: 19029, decode.loss_mask: 46.2333, decode.loss_dice: 3.9976, decode.acc_seg: 195.4154, loss: 50.2309
2024-06-23 15:55:38,723 - mmseg - INFO - Iter [1300/20000]	lr: 1.635e-05, eta: 8:48:02, time: 1.686, data_time: 0.005, memory: 19029, decode.loss_mask: 46.3144, decode.loss_dice: 3.9914, decode.acc_seg: 208.5887, loss: 50.3058
2024-06-23 15:57:02,606 - mmseg - INFO - Iter [1350/20000]	lr: 1.695e-05, eta: 8:46:26, time: 1.678, data_time: 0.005, memory: 19029, decode.loss_mask: 42.8544, decode.loss_dice: 3.9835, decode.acc_seg: 226.0733, loss: 46.8379
2024-06-23 15:58:26,662 - mmseg - INFO - Iter [1400/20000]	lr: 1.753e-05, eta: 8:44:53, time: 1.681, data_time: 0.005, memory: 19031, decode.loss_mask: 45.9154, decode.loss_dice: 3.9519, decode.acc_seg: 214.1782, loss: 49.8673
2024-06-23 15:59:50,457 - mmseg - INFO - Iter [1450/20000]	lr: 1.812e-05, eta: 8:43:17, time: 1.676, data_time: 0.005, memory: 19031, decode.loss_mask: 39.5683, decode.loss_dice: 3.9264, decode.acc_seg: 266.3679, loss: 43.4947
2024-06-23 16:01:14,217 - mmseg - INFO - Iter [1500/20000]	lr: 1.870e-05, eta: 8:41:41, time: 1.675, data_time: 0.005, memory: 19047, decode.loss_mask: 42.1020, decode.loss_dice: 3.9994, decode.acc_seg: 213.4415, loss: 46.1013
2024-06-23 16:02:41,201 - mmseg - INFO - Iter [1550/20000]	lr: 1.867e-05, eta: 8:40:45, time: 1.740, data_time: 0.045, memory: 19047, decode.loss_mask: 39.9905, decode.loss_dice: 3.9554, decode.acc_seg: 235.3571, loss: 43.9459
2024-06-23 16:04:04,591 - mmseg - INFO - Iter [1600/20000]	lr: 1.863e-05, eta: 8:39:06, time: 1.668, data_time: 0.005, memory: 19047, decode.loss_mask: 40.6120, decode.loss_dice: 3.9101, decode.acc_seg: 260.1066, loss: 44.5221
2024-06-23 16:05:22,510 - mmseg - INFO - Iter [1650/20000]	lr: 1.858e-05, eta: 8:36:26, time: 1.558, data_time: 0.005, memory: 19047, decode.loss_mask: 38.7730, decode.loss_dice: 3.8813, decode.acc_seg: 237.7048, loss: 42.6543
2024-06-23 16:06:40,027 - mmseg - INFO - Iter [1700/20000]	lr: 1.854e-05, eta: 8:33:48, time: 1.550, data_time: 0.004, memory: 19047, decode.loss_mask: 32.9865, decode.loss_dice: 3.8807, decode.acc_seg: 273.7057, loss: 36.8672
2024-06-23 16:07:57,365 - mmseg - INFO - Iter [1750/20000]	lr: 1.850e-05, eta: 8:31:11, time: 1.547, data_time: 0.004, memory: 19047, decode.loss_mask: 37.0041, decode.loss_dice: 3.8509, decode.acc_seg: 271.1171, loss: 40.8550
2024-06-23 16:09:14,444 - mmseg - INFO - Iter [1800/20000]	lr: 1.845e-05, eta: 8:28:37, time: 1.542, data_time: 0.005, memory: 19047, decode.loss_mask: 36.0895, decode.loss_dice: 3.8053, decode.acc_seg: 257.3818, loss: 39.8948
2024-06-23 16:10:31,812 - mmseg - INFO - Iter [1850/20000]	lr: 1.841e-05, eta: 8:26:10, time: 1.547, data_time: 0.004, memory: 19047, decode.loss_mask: 32.5669, decode.loss_dice: 3.7245, decode.acc_seg: 281.9522, loss: 36.2914
2024-06-23 16:11:49,088 - mmseg - INFO - Iter [1900/20000]	lr: 1.837e-05, eta: 8:23:45, time: 1.546, data_time: 0.004, memory: 19047, decode.loss_mask: 35.6143, decode.loss_dice: 3.7076, decode.acc_seg: 286.6737, loss: 39.3219
2024-06-23 16:13:06,515 - mmseg - INFO - Iter [1950/20000]	lr: 1.833e-05, eta: 8:21:26, time: 1.549, data_time: 0.004, memory: 19047, decode.loss_mask: 36.8224, decode.loss_dice: 3.7041, decode.acc_seg: 298.0381, loss: 40.5266
2024-06-23 16:14:24,228 - mmseg - INFO - Saving checkpoint at 2000 iterations
2024-06-23 16:14:25,097 - mmseg - INFO - Exp name: xxscales_input_vpt_seg_zero_vit-b_512x512_20k_12_10.py
2024-06-23 16:14:25,098 - mmseg - INFO - Iter [2000/20000]	lr: 1.828e-05, eta: 8:19:19, time: 1.572, data_time: 0.004, memory: 19047, decode.loss_mask: 33.8780, decode.loss_dice: 3.7149, decode.acc_seg: 297.8388, loss: 37.5929
2024-06-23 16:15:42,485 - mmseg - INFO - Iter [2050/20000]	lr: 1.824e-05, eta: 8:17:05, time: 1.548, data_time: 0.004, memory: 19047, decode.loss_mask: 35.6644, decode.loss_dice: 3.5675, decode.acc_seg: 304.6744, loss: 39.2318
2024-06-23 16:17:00,024 - mmseg - INFO - Iter [2100/20000]	lr: 1.820e-05, eta: 8:14:55, time: 1.551, data_time: 0.005, memory: 19047, decode.loss_mask: 32.2318, decode.loss_dice: 3.6583, decode.acc_seg: 303.6891, loss: 35.8900
2024-06-23 16:18:18,041 - mmseg - INFO - Iter [2150/20000]	lr: 1.815e-05, eta: 8:12:51, time: 1.560, data_time: 0.004, memory: 19047, decode.loss_mask: 34.0204, decode.loss_dice: 3.6905, decode.acc_seg: 325.9147, loss: 37.7109
2024-06-23 16:19:35,849 - mmseg - INFO - Iter [2200/20000]	lr: 1.811e-05, eta: 8:10:47, time: 1.556, data_time: 0.005, memory: 19047, decode.loss_mask: 32.3594, decode.loss_dice: 3.6030, decode.acc_seg: 331.1399, loss: 35.9624
2024-06-23 16:20:53,601 - mmseg - INFO - Iter [2250/20000]	lr: 1.807e-05, eta: 8:08:45, time: 1.555, data_time: 0.005, memory: 19047, decode.loss_mask: 28.7134, decode.loss_dice: 3.6715, decode.acc_seg: 329.2468, loss: 32.3849
2024-06-23 16:22:11,508 - mmseg - INFO - Iter [2300/20000]	lr: 1.802e-05, eta: 8:06:47, time: 1.558, data_time: 0.004, memory: 19047, decode.loss_mask: 31.6262, decode.loss_dice: 3.6034, decode.acc_seg: 346.9662, loss: 35.2296
2024-06-23 16:23:29,306 - mmseg - INFO - Iter [2350/20000]	lr: 1.798e-05, eta: 8:04:49, time: 1.556, data_time: 0.004, memory: 19047, decode.loss_mask: 29.6128, decode.loss_dice: 3.5642, decode.acc_seg: 356.0897, loss: 33.1769
2024-06-23 16:24:47,671 - mmseg - INFO - Iter [2400/20000]	lr: 1.794e-05, eta: 8:02:57, time: 1.567, data_time: 0.004, memory: 19047, decode.loss_mask: 25.6160, decode.loss_dice: 3.5812, decode.acc_seg: 374.9301, loss: 29.1972
2024-06-23 16:26:05,476 - mmseg - INFO - Iter [2450/20000]	lr: 1.789e-05, eta: 8:01:02, time: 1.556, data_time: 0.004, memory: 19047, decode.loss_mask: 27.5962, decode.loss_dice: 3.6286, decode.acc_seg: 363.0153, loss: 31.2248
2024-06-23 16:27:23,355 - mmseg - INFO - Iter [2500/20000]	lr: 1.785e-05, eta: 7:59:09, time: 1.558, data_time: 0.004, memory: 19047, decode.loss_mask: 26.8636, decode.loss_dice: 3.4873, decode.acc_seg: 382.0634, loss: 30.3510
2024-06-23 16:28:41,197 - mmseg - INFO - Iter [2550/20000]	lr: 1.781e-05, eta: 7:57:18, time: 1.557, data_time: 0.004, memory: 19047, decode.loss_mask: 25.5579, decode.loss_dice: 3.5370, decode.acc_seg: 395.1714, loss: 29.0949
2024-06-23 16:29:59,786 - mmseg - INFO - Iter [2600/20000]	lr: 1.776e-05, eta: 7:55:33, time: 1.572, data_time: 0.004, memory: 19047, decode.loss_mask: 26.5466, decode.loss_dice: 3.4200, decode.acc_seg: 397.5219, loss: 29.9666
2024-06-23 16:31:17,414 - mmseg - INFO - Iter [2650/20000]	lr: 1.772e-05, eta: 7:53:42, time: 1.553, data_time: 0.004, memory: 19047, decode.loss_mask: 24.3037, decode.loss_dice: 3.4964, decode.acc_seg: 382.7686, loss: 27.8001
2024-06-23 16:32:35,479 - mmseg - INFO - Iter [2700/20000]	lr: 1.768e-05, eta: 7:51:55, time: 1.561, data_time: 0.004, memory: 19047, decode.loss_mask: 25.9624, decode.loss_dice: 3.3933, decode.acc_seg: 388.2179, loss: 29.3557
2024-06-23 16:33:52,777 - mmseg - INFO - Iter [2750/20000]	lr: 1.763e-05, eta: 7:50:05, time: 1.546, data_time: 0.004, memory: 19047, decode.loss_mask: 23.2299, decode.loss_dice: 3.5741, decode.acc_seg: 385.2391, loss: 26.8039
2024-06-23 16:35:10,371 - mmseg - INFO - Iter [2800/20000]	lr: 1.759e-05, eta: 7:48:18, time: 1.552, data_time: 0.004, memory: 19047, decode.loss_mask: 25.6123, decode.loss_dice: 3.5031, decode.acc_seg: 396.1971, loss: 29.1154
2024-06-23 16:36:27,953 - mmseg - INFO - Iter [2850/20000]	lr: 1.755e-05, eta: 7:46:31, time: 1.552, data_time: 0.004, memory: 19047, decode.loss_mask: 23.2830, decode.loss_dice: 3.5561, decode.acc_seg: 396.3652, loss: 26.8390
2024-06-23 16:37:45,643 - mmseg - INFO - Iter [2900/20000]	lr: 1.750e-05, eta: 7:44:47, time: 1.554, data_time: 0.005, memory: 19047, decode.loss_mask: 22.9275, decode.loss_dice: 3.4255, decode.acc_seg: 404.7472, loss: 26.3531
2024-06-23 16:39:03,363 - mmseg - INFO - Iter [2950/20000]	lr: 1.746e-05, eta: 7:43:03, time: 1.554, data_time: 0.005, memory: 19047, decode.loss_mask: 21.4396, decode.loss_dice: 3.4233, decode.acc_seg: 405.3683, loss: 24.8629
2024-06-23 16:40:21,230 - mmseg - INFO - Exp name: xxscales_input_vpt_seg_zero_vit-b_512x512_20k_12_10.py
2024-06-23 16:40:21,231 - mmseg - INFO - Iter [3000/20000]	lr: 1.742e-05, eta: 7:41:21, time: 1.557, data_time: 0.004, memory: 19047, decode.loss_mask: 21.6504, decode.loss_dice: 3.3734, decode.acc_seg: 399.9446, loss: 25.0238
2024-06-23 16:41:41,599 - mmseg - INFO - Iter [3050/20000]	lr: 1.737e-05, eta: 7:39:54, time: 1.607, data_time: 0.046, memory: 19047, decode.loss_mask: 21.7881, decode.loss_dice: 3.3227, decode.acc_seg: 400.9036, loss: 25.1109
2024-06-23 16:42:59,676 - mmseg - INFO - Iter [3100/20000]	lr: 1.733e-05, eta: 7:38:14, time: 1.562, data_time: 0.004, memory: 19047, decode.loss_mask: 22.5546, decode.loss_dice: 3.4069, decode.acc_seg: 404.3084, loss: 25.9615
2024-06-23 16:44:17,874 - mmseg - INFO - Iter [3150/20000]	lr: 1.729e-05, eta: 7:36:36, time: 1.564, data_time: 0.004, memory: 19047, decode.loss_mask: 23.5360, decode.loss_dice: 3.3784, decode.acc_seg: 409.6276, loss: 26.9144
2024-06-23 16:45:36,131 - mmseg - INFO - Iter [3200/20000]	lr: 1.724e-05, eta: 7:34:59, time: 1.565, data_time: 0.004, memory: 19047, decode.loss_mask: 21.5367, decode.loss_dice: 3.3818, decode.acc_seg: 415.1877, loss: 24.9185
2024-06-23 16:46:54,287 - mmseg - INFO - Iter [3250/20000]	lr: 1.720e-05, eta: 7:33:22, time: 1.563, data_time: 0.004, memory: 19047, decode.loss_mask: 19.4527, decode.loss_dice: 3.3489, decode.acc_seg: 422.4933, loss: 22.8016
2024-06-23 16:48:12,297 - mmseg - INFO - Iter [3300/20000]	lr: 1.715e-05, eta: 7:31:44, time: 1.560, data_time: 0.005, memory: 19047, decode.loss_mask: 20.0707, decode.loss_dice: 3.3530, decode.acc_seg: 416.2373, loss: 23.4237
2024-06-23 16:49:30,673 - mmseg - INFO - Iter [3350/20000]	lr: 1.711e-05, eta: 7:30:09, time: 1.568, data_time: 0.005, memory: 19047, decode.loss_mask: 21.6710, decode.loss_dice: 3.4322, decode.acc_seg: 400.9154, loss: 25.1032
2024-06-23 16:50:49,161 - mmseg - INFO - Iter [3400/20000]	lr: 1.707e-05, eta: 7:28:36, time: 1.570, data_time: 0.005, memory: 19047, decode.loss_mask: 20.6889, decode.loss_dice: 3.4200, decode.acc_seg: 406.2298, loss: 24.1089
2024-06-23 16:52:07,672 - mmseg - INFO - Iter [3450/20000]	lr: 1.702e-05, eta: 7:27:02, time: 1.570, data_time: 0.005, memory: 19047, decode.loss_mask: 20.9553, decode.loss_dice: 3.3886, decode.acc_seg: 406.5706, loss: 24.3438
2024-06-23 16:53:25,024 - mmseg - INFO - Iter [3500/20000]	lr: 1.698e-05, eta: 7:25:24, time: 1.547, data_time: 0.005, memory: 19047, decode.loss_mask: 22.1443, decode.loss_dice: 3.3190, decode.acc_seg: 407.1703, loss: 25.4633
2024-06-23 16:54:42,351 - mmseg - INFO - Iter [3550/20000]	lr: 1.694e-05, eta: 7:23:46, time: 1.547, data_time: 0.005, memory: 19047, decode.loss_mask: 21.6501, decode.loss_dice: 3.3430, decode.acc_seg: 412.4239, loss: 24.9930
2024-06-23 16:56:00,056 - mmseg - INFO - Iter [3600/20000]	lr: 1.689e-05, eta: 7:22:10, time: 1.554, data_time: 0.005, memory: 19047, decode.loss_mask: 18.3605, decode.loss_dice: 3.3476, decode.acc_seg: 419.2855, loss: 21.7081
2024-06-23 16:57:19,847 - mmseg - INFO - Iter [3650/20000]	lr: 1.685e-05, eta: 7:20:44, time: 1.596, data_time: 0.005, memory: 19047, decode.loss_mask: 18.2906, decode.loss_dice: 3.3351, decode.acc_seg: 420.2926, loss: 21.6256
2024-06-23 16:58:38,641 - mmseg - INFO - Iter [3700/20000]	lr: 1.681e-05, eta: 7:19:14, time: 1.576, data_time: 0.005, memory: 19047, decode.loss_mask: 20.2998, decode.loss_dice: 3.1839, decode.acc_seg: 421.4987, loss: 23.4836
2024-06-23 16:59:56,582 - mmseg - INFO - Iter [3750/20000]	lr: 1.676e-05, eta: 7:17:41, time: 1.559, data_time: 0.005, memory: 19047, decode.loss_mask: 18.3541, decode.loss_dice: 3.3682, decode.acc_seg: 422.8336, loss: 21.7223
2024-06-23 17:01:14,526 - mmseg - INFO - Iter [3800/20000]	lr: 1.672e-05, eta: 7:16:08, time: 1.559, data_time: 0.005, memory: 19047, decode.loss_mask: 20.3306, decode.loss_dice: 3.3343, decode.acc_seg: 414.9424, loss: 23.6649
2024-06-23 17:02:32,167 - mmseg - INFO - Iter [3850/20000]	lr: 1.667e-05, eta: 7:14:34, time: 1.553, data_time: 0.005, memory: 19047, decode.loss_mask: 22.2765, decode.loss_dice: 3.3700, decode.acc_seg: 414.5345, loss: 25.6465
2024-06-23 17:03:49,804 - mmseg - INFO - Iter [3900/20000]	lr: 1.663e-05, eta: 7:13:01, time: 1.553, data_time: 0.005, memory: 19047, decode.loss_mask: 19.7299, decode.loss_dice: 3.3731, decode.acc_seg: 414.1850, loss: 23.1030
2024-06-23 17:05:07,783 - mmseg - INFO - Iter [3950/20000]	lr: 1.659e-05, eta: 7:11:29, time: 1.560, data_time: 0.005, memory: 19047, decode.loss_mask: 22.7328, decode.loss_dice: 3.2645, decode.acc_seg: 409.3213, loss: 25.9973
2024-06-23 17:06:25,650 - mmseg - INFO - Saving checkpoint at 4000 iterations
2024-06-23 17:06:26,695 - mmseg - INFO - Exp name: xxscales_input_vpt_seg_zero_vit-b_512x512_20k_12_10.py
2024-06-23 17:06:26,696 - mmseg - INFO - Iter [4000/20000]	lr: 1.654e-05, eta: 7:10:01, time: 1.578, data_time: 0.005, memory: 19051, decode.loss_mask: 19.7246, decode.loss_dice: 3.2009, decode.acc_seg: 422.5151, loss: 22.9256
2024-06-23 17:07:44,849 - mmseg - INFO - Iter [4050/20000]	lr: 1.650e-05, eta: 7:08:31, time: 1.563, data_time: 0.005, memory: 19051, decode.loss_mask: 17.9978, decode.loss_dice: 3.1666, decode.acc_seg: 429.7681, loss: 21.1645
2024-06-23 17:09:02,876 - mmseg - INFO - Iter [4100/20000]	lr: 1.646e-05, eta: 7:07:00, time: 1.561, data_time: 0.005, memory: 19051, decode.loss_mask: 20.8320, decode.loss_dice: 3.3350, decode.acc_seg: 414.1334, loss: 24.1671
2024-06-23 17:10:20,575 - mmseg - INFO - Iter [4150/20000]	lr: 1.641e-05, eta: 7:05:29, time: 1.554, data_time: 0.004, memory: 19051, decode.loss_mask: 20.1021, decode.loss_dice: 3.1126, decode.acc_seg: 433.4271, loss: 23.2146
2024-06-23 17:11:38,060 - mmseg - INFO - Iter [4200/20000]	lr: 1.637e-05, eta: 7:03:57, time: 1.550, data_time: 0.005, memory: 19051, decode.loss_mask: 17.7282, decode.loss_dice: 3.0915, decode.acc_seg: 425.9381, loss: 20.8197
2024-06-23 17:12:56,145 - mmseg - INFO - Iter [4250/20000]	lr: 1.633e-05, eta: 7:02:27, time: 1.562, data_time: 0.005, memory: 19051, decode.loss_mask: 23.6881, decode.loss_dice: 3.2976, decode.acc_seg: 409.8095, loss: 26.9857
2024-06-23 17:14:14,184 - mmseg - INFO - Iter [4300/20000]	lr: 1.628e-05, eta: 7:00:58, time: 1.561, data_time: 0.005, memory: 19051, decode.loss_mask: 20.6616, decode.loss_dice: 3.1734, decode.acc_seg: 410.0608, loss: 23.8351
2024-06-23 17:15:32,680 - mmseg - INFO - Iter [4350/20000]	lr: 1.624e-05, eta: 6:59:31, time: 1.570, data_time: 0.005, memory: 19051, decode.loss_mask: 17.9454, decode.loss_dice: 3.2432, decode.acc_seg: 416.0903, loss: 21.1886
2024-06-23 17:16:50,722 - mmseg - INFO - Iter [4400/20000]	lr: 1.619e-05, eta: 6:58:02, time: 1.561, data_time: 0.005, memory: 19051, decode.loss_mask: 20.1960, decode.loss_dice: 3.2292, decode.acc_seg: 415.7720, loss: 23.4252
2024-06-23 17:18:10,506 - mmseg - INFO - Iter [4450/20000]	lr: 1.615e-05, eta: 6:56:39, time: 1.596, data_time: 0.005, memory: 19051, decode.loss_mask: 21.6221, decode.loss_dice: 3.2080, decode.acc_seg: 414.0058, loss: 24.8301
2024-06-23 17:19:28,265 - mmseg - INFO - Iter [4500/20000]	lr: 1.611e-05, eta: 6:55:10, time: 1.555, data_time: 0.005, memory: 19051, decode.loss_mask: 18.7994, decode.loss_dice: 3.2400, decode.acc_seg: 414.0733, loss: 22.0395
2024-06-23 17:20:48,012 - mmseg - INFO - Iter [4550/20000]	lr: 1.606e-05, eta: 6:53:47, time: 1.595, data_time: 0.046, memory: 19051, decode.loss_mask: 19.1479, decode.loss_dice: 3.2789, decode.acc_seg: 420.0902, loss: 22.4269
2024-06-23 17:22:06,033 - mmseg - INFO - Iter [4600/20000]	lr: 1.602e-05, eta: 6:52:19, time: 1.560, data_time: 0.005, memory: 19051, decode.loss_mask: 19.5994, decode.loss_dice: 3.2801, decode.acc_seg: 422.5464, loss: 22.8796
2024-06-23 17:23:24,310 - mmseg - INFO - Iter [4650/20000]	lr: 1.597e-05, eta: 6:50:52, time: 1.566, data_time: 0.005, memory: 19051, decode.loss_mask: 17.7766, decode.loss_dice: 3.2506, decode.acc_seg: 424.0213, loss: 21.0273
2024-06-23 17:24:44,025 - mmseg - INFO - Iter [4700/20000]	lr: 1.593e-05, eta: 6:49:30, time: 1.594, data_time: 0.005, memory: 19051, decode.loss_mask: 17.7601, decode.loss_dice: 3.1881, decode.acc_seg: 418.2237, loss: 20.9481
2024-06-23 17:26:02,143 - mmseg - INFO - Iter [4750/20000]	lr: 1.589e-05, eta: 6:48:03, time: 1.562, data_time: 0.005, memory: 19051, decode.loss_mask: 17.5049, decode.loss_dice: 3.1112, decode.acc_seg: 428.3379, loss: 20.6161
2024-06-23 17:27:20,304 - mmseg - INFO - Iter [4800/20000]	lr: 1.584e-05, eta: 6:46:36, time: 1.563, data_time: 0.005, memory: 19051, decode.loss_mask: 20.1920, decode.loss_dice: 3.2762, decode.acc_seg: 417.8311, loss: 23.4683
2024-06-23 17:28:38,838 - mmseg - INFO - Iter [4850/20000]	lr: 1.580e-05, eta: 6:45:10, time: 1.571, data_time: 0.005, memory: 19051, decode.loss_mask: 17.5375, decode.loss_dice: 3.0279, decode.acc_seg: 430.7403, loss: 20.5654
2024-06-23 17:29:56,953 - mmseg - INFO - Iter [4900/20000]	lr: 1.575e-05, eta: 6:43:43, time: 1.562, data_time: 0.005, memory: 19051, decode.loss_mask: 19.0625, decode.loss_dice: 3.3107, decode.acc_seg: 419.6008, loss: 22.3732
2024-06-23 17:31:15,204 - mmseg - INFO - Iter [4950/20000]	lr: 1.571e-05, eta: 6:42:17, time: 1.565, data_time: 0.004, memory: 19051, decode.loss_mask: 19.7825, decode.loss_dice: 3.2609, decode.acc_seg: 414.6540, loss: 23.0434
2024-06-23 17:32:34,583 - mmseg - INFO - Exp name: xxscales_input_vpt_seg_zero_vit-b_512x512_20k_12_10.py
2024-06-23 17:32:34,584 - mmseg - INFO - Iter [5000/20000]	lr: 1.567e-05, eta: 6:40:55, time: 1.588, data_time: 0.005, memory: 19051, decode.loss_mask: 16.1849, decode.loss_dice: 3.2257, decode.acc_seg: 434.5532, loss: 19.4105
2024-06-23 17:33:55,137 - mmseg - INFO - Iter [5050/20000]	lr: 1.562e-05, eta: 6:39:35, time: 1.611, data_time: 0.005, memory: 19051, decode.loss_mask: 19.4589, decode.loss_dice: 3.1958, decode.acc_seg: 418.0703, loss: 22.6548
2024-06-23 17:35:14,324 - mmseg - INFO - Iter [5100/20000]	lr: 1.558e-05, eta: 6:38:12, time: 1.584, data_time: 0.005, memory: 19051, decode.loss_mask: 19.8535, decode.loss_dice: 3.0922, decode.acc_seg: 420.1670, loss: 22.9457
2024-06-23 17:36:32,660 - mmseg - INFO - Iter [5150/20000]	lr: 1.553e-05, eta: 6:36:47, time: 1.567, data_time: 0.005, memory: 19051, decode.loss_mask: 18.7215, decode.loss_dice: 3.1844, decode.acc_seg: 429.2863, loss: 21.9059
2024-06-23 17:37:50,207 - mmseg - INFO - Iter [5200/20000]	lr: 1.549e-05, eta: 6:35:19, time: 1.551, data_time: 0.004, memory: 19051, decode.loss_mask: 18.1081, decode.loss_dice: 3.1284, decode.acc_seg: 432.9687, loss: 21.2365
2024-06-23 17:39:07,849 - mmseg - INFO - Iter [5250/20000]	lr: 1.545e-05, eta: 6:33:52, time: 1.553, data_time: 0.005, memory: 19051, decode.loss_mask: 21.0122, decode.loss_dice: 3.3372, decode.acc_seg: 405.5041, loss: 24.3494
2024-06-23 17:40:25,220 - mmseg - INFO - Iter [5300/20000]	lr: 1.540e-05, eta: 6:32:24, time: 1.547, data_time: 0.005, memory: 19051, decode.loss_mask: 19.5108, decode.loss_dice: 3.1461, decode.acc_seg: 416.9433, loss: 22.6569
2024-06-23 17:41:43,187 - mmseg - INFO - Iter [5350/20000]	lr: 1.536e-05, eta: 6:30:59, time: 1.559, data_time: 0.004, memory: 19051, decode.loss_mask: 18.1203, decode.loss_dice: 3.1494, decode.acc_seg: 417.3474, loss: 21.2696
2024-06-23 17:43:00,783 - mmseg - INFO - Iter [5400/20000]	lr: 1.531e-05, eta: 6:29:32, time: 1.552, data_time: 0.004, memory: 19051, decode.loss_mask: 18.3412, decode.loss_dice: 3.1534, decode.acc_seg: 425.8317, loss: 21.4946
2024-06-23 17:44:20,201 - mmseg - INFO - Iter [5450/20000]	lr: 1.527e-05, eta: 6:28:10, time: 1.588, data_time: 0.004, memory: 19051, decode.loss_mask: 15.6711, decode.loss_dice: 3.1525, decode.acc_seg: 430.3292, loss: 18.8237
2024-06-23 17:45:37,737 - mmseg - INFO - Iter [5500/20000]	lr: 1.523e-05, eta: 6:26:43, time: 1.551, data_time: 0.004, memory: 19051, decode.loss_mask: 20.0803, decode.loss_dice: 3.0106, decode.acc_seg: 425.8528, loss: 23.0909
2024-06-23 17:46:55,231 - mmseg - INFO - Iter [5550/20000]	lr: 1.518e-05, eta: 6:25:17, time: 1.550, data_time: 0.004, memory: 19051, decode.loss_mask: 17.3456, decode.loss_dice: 3.1972, decode.acc_seg: 430.4634, loss: 20.5427
2024-06-23 17:48:12,572 - mmseg - INFO - Iter [5600/20000]	lr: 1.514e-05, eta: 6:23:50, time: 1.547, data_time: 0.004, memory: 19051, decode.loss_mask: 15.2152, decode.loss_dice: 3.1315, decode.acc_seg: 437.2072, loss: 18.3467
2024-06-23 17:49:29,975 - mmseg - INFO - Iter [5650/20000]	lr: 1.509e-05, eta: 6:22:24, time: 1.548, data_time: 0.004, memory: 19051, decode.loss_mask: 19.7529, decode.loss_dice: 3.1661, decode.acc_seg: 417.8545, loss: 22.9190
2024-06-23 17:50:48,666 - mmseg - INFO - Iter [5700/20000]	lr: 1.505e-05, eta: 6:21:00, time: 1.574, data_time: 0.004, memory: 19051, decode.loss_mask: 19.8171, decode.loss_dice: 3.1864, decode.acc_seg: 423.9979, loss: 23.0035
2024-06-23 17:52:06,952 - mmseg - INFO - Iter [5750/20000]	lr: 1.501e-05, eta: 6:19:36, time: 1.566, data_time: 0.004, memory: 19051, decode.loss_mask: 16.1199, decode.loss_dice: 3.1181, decode.acc_seg: 435.5004, loss: 19.2380
2024-06-23 17:53:24,832 - mmseg - INFO - Iter [5800/20000]	lr: 1.496e-05, eta: 6:18:12, time: 1.558, data_time: 0.004, memory: 19051, decode.loss_mask: 17.0728, decode.loss_dice: 2.9493, decode.acc_seg: 433.4323, loss: 20.0220
2024-06-23 17:54:42,846 - mmseg - INFO - Iter [5850/20000]	lr: 1.492e-05, eta: 6:16:47, time: 1.560, data_time: 0.004, memory: 19051, decode.loss_mask: 16.5980, decode.loss_dice: 3.2735, decode.acc_seg: 421.3496, loss: 19.8715
2024-06-23 17:56:00,848 - mmseg - INFO - Iter [5900/20000]	lr: 1.487e-05, eta: 6:15:23, time: 1.560, data_time: 0.004, memory: 19051, decode.loss_mask: 15.6503, decode.loss_dice: 3.1318, decode.acc_seg: 429.5931, loss: 18.7820
2024-06-23 17:57:19,035 - mmseg - INFO - Iter [5950/20000]	lr: 1.483e-05, eta: 6:13:59, time: 1.564, data_time: 0.005, memory: 19051, decode.loss_mask: 18.8291, decode.loss_dice: 3.0738, decode.acc_seg: 426.8705, loss: 21.9029
2024-06-23 17:58:36,943 - mmseg - INFO - Saving checkpoint at 6000 iterations
2024-06-23 17:58:37,834 - mmseg - INFO - Exp name: xxscales_input_vpt_seg_zero_vit-b_512x512_20k_12_10.py
2024-06-23 17:58:37,835 - mmseg - INFO - Iter [6000/20000]	lr: 1.478e-05, eta: 6:12:37, time: 1.576, data_time: 0.004, memory: 19051, decode.loss_mask: 17.9255, decode.loss_dice: 3.1319, decode.acc_seg: 425.2642, loss: 21.0574
2024-06-23 17:59:57,872 - mmseg - INFO - Iter [6050/20000]	lr: 1.474e-05, eta: 6:11:17, time: 1.601, data_time: 0.046, memory: 19051, decode.loss_mask: 18.8132, decode.loss_dice: 3.2410, decode.acc_seg: 421.3545, loss: 22.0541
2024-06-23 18:01:16,508 - mmseg - INFO - Iter [6100/20000]	lr: 1.470e-05, eta: 6:09:55, time: 1.573, data_time: 0.004, memory: 19051, decode.loss_mask: 19.6791, decode.loss_dice: 3.1345, decode.acc_seg: 422.4062, loss: 22.8136
2024-06-23 18:02:34,440 - mmseg - INFO - Iter [6150/20000]	lr: 1.465e-05, eta: 6:08:30, time: 1.559, data_time: 0.004, memory: 19051, decode.loss_mask: 18.4106, decode.loss_dice: 3.0498, decode.acc_seg: 435.0763, loss: 21.4604
2024-06-23 18:03:52,586 - mmseg - INFO - Iter [6200/20000]	lr: 1.461e-05, eta: 6:07:07, time: 1.563, data_time: 0.004, memory: 19051, decode.loss_mask: 20.2248, decode.loss_dice: 3.2011, decode.acc_seg: 417.2971, loss: 23.4259
2024-06-23 18:05:10,177 - mmseg - INFO - Iter [6250/20000]	lr: 1.456e-05, eta: 6:05:42, time: 1.552, data_time: 0.004, memory: 19051, decode.loss_mask: 17.2252, decode.loss_dice: 3.1151, decode.acc_seg: 421.7650, loss: 20.3403
2024-06-23 18:06:28,002 - mmseg - INFO - Iter [6300/20000]	lr: 1.452e-05, eta: 6:04:18, time: 1.556, data_time: 0.004, memory: 19051, decode.loss_mask: 17.0258, decode.loss_dice: 2.9927, decode.acc_seg: 427.8405, loss: 20.0185
2024-06-23 18:07:46,328 - mmseg - INFO - Iter [6350/20000]	lr: 1.447e-05, eta: 6:02:55, time: 1.567, data_time: 0.004, memory: 19051, decode.loss_mask: 15.7619, decode.loss_dice: 3.1005, decode.acc_seg: 430.6528, loss: 18.8624
2024-06-23 18:09:04,084 - mmseg - INFO - Iter [6400/20000]	lr: 1.443e-05, eta: 6:01:31, time: 1.555, data_time: 0.004, memory: 19051, decode.loss_mask: 16.0639, decode.loss_dice: 3.1310, decode.acc_seg: 430.8160, loss: 19.1949
2024-06-23 18:10:23,149 - mmseg - INFO - Iter [6450/20000]	lr: 1.438e-05, eta: 6:00:10, time: 1.581, data_time: 0.004, memory: 19051, decode.loss_mask: 18.2459, decode.loss_dice: 3.1969, decode.acc_seg: 421.9002, loss: 21.4429
2024-06-23 18:11:41,945 - mmseg - INFO - Iter [6500/20000]	lr: 1.434e-05, eta: 5:58:48, time: 1.576, data_time: 0.004, memory: 19051, decode.loss_mask: 18.9018, decode.loss_dice: 3.0837, decode.acc_seg: 435.0513, loss: 21.9855
2024-06-23 18:12:59,444 - mmseg - INFO - Iter [6550/20000]	lr: 1.430e-05, eta: 5:57:24, time: 1.550, data_time: 0.004, memory: 19051, decode.loss_mask: 18.1536, decode.loss_dice: 3.0038, decode.acc_seg: 425.9393, loss: 21.1574
2024-06-23 18:14:16,981 - mmseg - INFO - Iter [6600/20000]	lr: 1.425e-05, eta: 5:56:00, time: 1.551, data_time: 0.004, memory: 19051, decode.loss_mask: 17.5859, decode.loss_dice: 3.0898, decode.acc_seg: 423.9702, loss: 20.6757
2024-06-23 18:15:35,203 - mmseg - INFO - Iter [6650/20000]	lr: 1.421e-05, eta: 5:54:37, time: 1.564, data_time: 0.005, memory: 19051, decode.loss_mask: 17.2568, decode.loss_dice: 2.9967, decode.acc_seg: 438.6996, loss: 20.2535
2024-06-23 18:16:54,534 - mmseg - INFO - Iter [6700/20000]	lr: 1.416e-05, eta: 5:53:17, time: 1.587, data_time: 0.005, memory: 19051, decode.loss_mask: 16.7644, decode.loss_dice: 3.1373, decode.acc_seg: 429.4523, loss: 19.9017
2024-06-23 18:18:12,335 - mmseg - INFO - Iter [6750/20000]	lr: 1.412e-05, eta: 5:51:53, time: 1.556, data_time: 0.005, memory: 19051, decode.loss_mask: 15.1179, decode.loss_dice: 3.1579, decode.acc_seg: 432.5717, loss: 18.2757
2024-06-23 18:19:30,680 - mmseg - INFO - Iter [6800/20000]	lr: 1.407e-05, eta: 5:50:31, time: 1.567, data_time: 0.005, memory: 19051, decode.loss_mask: 16.2480, decode.loss_dice: 3.0478, decode.acc_seg: 441.6683, loss: 19.2958
2024-06-23 18:20:48,738 - mmseg - INFO - Iter [6850/20000]	lr: 1.403e-05, eta: 5:49:08, time: 1.561, data_time: 0.005, memory: 19051, decode.loss_mask: 16.0103, decode.loss_dice: 3.0640, decode.acc_seg: 428.1606, loss: 19.0743
2024-06-23 18:22:08,216 - mmseg - INFO - Iter [6900/20000]	lr: 1.398e-05, eta: 5:47:48, time: 1.590, data_time: 0.005, memory: 19051, decode.loss_mask: 15.7653, decode.loss_dice: 3.0127, decode.acc_seg: 433.1094, loss: 18.7780
2024-06-23 18:23:27,691 - mmseg - INFO - Iter [6950/20000]	lr: 1.394e-05, eta: 5:46:28, time: 1.589, data_time: 0.005, memory: 19051, decode.loss_mask: 16.8254, decode.loss_dice: 2.9668, decode.acc_seg: 430.1652, loss: 19.7922
2024-06-23 18:24:46,639 - mmseg - INFO - Exp name: xxscales_input_vpt_seg_zero_vit-b_512x512_20k_12_10.py
2024-06-23 18:24:46,640 - mmseg - INFO - Iter [7000/20000]	lr: 1.389e-05, eta: 5:45:07, time: 1.579, data_time: 0.005, memory: 19051, decode.loss_mask: 16.4870, decode.loss_dice: 3.0116, decode.acc_seg: 434.0692, loss: 19.4986
2024-06-23 18:26:04,792 - mmseg - INFO - Iter [7050/20000]	lr: 1.385e-05, eta: 5:43:45, time: 1.563, data_time: 0.005, memory: 19051, decode.loss_mask: 15.5990, decode.loss_dice: 3.0518, decode.acc_seg: 433.7550, loss: 18.6507
2024-06-23 18:27:22,546 - mmseg - INFO - Iter [7100/20000]	lr: 1.381e-05, eta: 5:42:22, time: 1.555, data_time: 0.005, memory: 19051, decode.loss_mask: 17.3864, decode.loss_dice: 3.0411, decode.acc_seg: 435.1173, loss: 20.4275
2024-06-23 18:28:40,031 - mmseg - INFO - Iter [7150/20000]	lr: 1.376e-05, eta: 5:40:58, time: 1.550, data_time: 0.005, memory: 19051, decode.loss_mask: 18.2127, decode.loss_dice: 3.0623, decode.acc_seg: 429.2070, loss: 21.2750
2024-06-23 18:29:57,430 - mmseg - INFO - Iter [7200/20000]	lr: 1.372e-05, eta: 5:39:35, time: 1.548, data_time: 0.005, memory: 19051, decode.loss_mask: 14.4833, decode.loss_dice: 3.0408, decode.acc_seg: 441.1700, loss: 17.5242
2024-06-23 18:31:14,937 - mmseg - INFO - Iter [7250/20000]	lr: 1.367e-05, eta: 5:38:12, time: 1.550, data_time: 0.005, memory: 19051, decode.loss_mask: 19.2549, decode.loss_dice: 3.1087, decode.acc_seg: 416.4966, loss: 22.3636
2024-06-23 18:32:32,613 - mmseg - INFO - Iter [7300/20000]	lr: 1.363e-05, eta: 5:36:49, time: 1.554, data_time: 0.005, memory: 19051, decode.loss_mask: 17.1274, decode.loss_dice: 3.1241, decode.acc_seg: 432.5005, loss: 20.2515
2024-06-23 18:33:50,769 - mmseg - INFO - Iter [7350/20000]	lr: 1.358e-05, eta: 5:35:27, time: 1.563, data_time: 0.005, memory: 19051, decode.loss_mask: 16.2959, decode.loss_dice: 2.9685, decode.acc_seg: 434.5741, loss: 19.2644
2024-06-23 18:35:08,612 - mmseg - INFO - Iter [7400/20000]	lr: 1.354e-05, eta: 5:34:04, time: 1.557, data_time: 0.005, memory: 19051, decode.loss_mask: 19.8579, decode.loss_dice: 2.9715, decode.acc_seg: 434.8332, loss: 22.8294
2024-06-23 18:36:26,641 - mmseg - INFO - Iter [7450/20000]	lr: 1.349e-05, eta: 5:32:42, time: 1.561, data_time: 0.005, memory: 19051, decode.loss_mask: 19.9051, decode.loss_dice: 3.0569, decode.acc_seg: 425.6913, loss: 22.9620
2024-06-23 18:37:46,144 - mmseg - INFO - Iter [7500/20000]	lr: 1.345e-05, eta: 5:31:23, time: 1.590, data_time: 0.005, memory: 19051, decode.loss_mask: 16.4001, decode.loss_dice: 3.1926, decode.acc_seg: 427.5994, loss: 19.5927
2024-06-23 18:39:07,208 - mmseg - INFO - Iter [7550/20000]	lr: 1.340e-05, eta: 5:30:06, time: 1.621, data_time: 0.047, memory: 19051, decode.loss_mask: 16.5975, decode.loss_dice: 3.0492, decode.acc_seg: 432.3880, loss: 19.6467
2024-06-23 18:40:24,851 - mmseg - INFO - Iter [7600/20000]	lr: 1.336e-05, eta: 5:28:43, time: 1.553, data_time: 0.005, memory: 19051, decode.loss_mask: 18.2675, decode.loss_dice: 3.1459, decode.acc_seg: 413.1013, loss: 21.4134
2024-06-23 18:41:42,786 - mmseg - INFO - Iter [7650/20000]	lr: 1.331e-05, eta: 5:27:21, time: 1.559, data_time: 0.005, memory: 19051, decode.loss_mask: 14.9761, decode.loss_dice: 3.0033, decode.acc_seg: 427.5926, loss: 17.9794
2024-06-23 18:43:01,722 - mmseg - INFO - Iter [7700/20000]	lr: 1.327e-05, eta: 5:26:00, time: 1.579, data_time: 0.005, memory: 19051, decode.loss_mask: 18.1718, decode.loss_dice: 3.0120, decode.acc_seg: 427.6463, loss: 21.1838
2024-06-23 18:44:19,849 - mmseg - INFO - Iter [7750/20000]	lr: 1.322e-05, eta: 5:24:39, time: 1.563, data_time: 0.005, memory: 19051, decode.loss_mask: 18.7703, decode.loss_dice: 3.1001, decode.acc_seg: 422.1337, loss: 21.8704
2024-06-23 18:45:42,801 - mmseg - INFO - Iter [7800/20000]	lr: 1.318e-05, eta: 5:23:25, time: 1.659, data_time: 0.006, memory: 19051, decode.loss_mask: 16.4904, decode.loss_dice: 2.9494, decode.acc_seg: 435.9888, loss: 19.4398
2024-06-23 18:47:06,884 - mmseg - INFO - Iter [7850/20000]	lr: 1.313e-05, eta: 5:22:12, time: 1.682, data_time: 0.005, memory: 19051, decode.loss_mask: 17.5569, decode.loss_dice: 3.0630, decode.acc_seg: 431.1697, loss: 20.6199
2024-06-23 18:48:31,293 - mmseg - INFO - Iter [7900/20000]	lr: 1.309e-05, eta: 5:21:00, time: 1.688, data_time: 0.005, memory: 19051, decode.loss_mask: 14.7201, decode.loss_dice: 3.0023, decode.acc_seg: 436.0011, loss: 17.7224
2024-06-23 18:49:55,494 - mmseg - INFO - Iter [7950/20000]	lr: 1.304e-05, eta: 5:19:47, time: 1.684, data_time: 0.006, memory: 19051, decode.loss_mask: 16.0904, decode.loss_dice: 2.9986, decode.acc_seg: 430.5345, loss: 19.0890
2024-06-23 18:51:19,193 - mmseg - INFO - Saving checkpoint at 8000 iterations
2024-06-23 18:51:20,619 - mmseg - INFO - Exp name: xxscales_input_vpt_seg_zero_vit-b_512x512_20k_12_10.py
2024-06-23 18:51:20,619 - mmseg - INFO - Iter [8000/20000]	lr: 1.300e-05, eta: 5:18:36, time: 1.703, data_time: 0.005, memory: 19051, decode.loss_mask: 15.6051, decode.loss_dice: 2.9452, decode.acc_seg: 449.0438, loss: 18.5503
2024-06-23 18:52:44,276 - mmseg - INFO - Iter [8050/20000]	lr: 1.295e-05, eta: 5:17:22, time: 1.673, data_time: 0.005, memory: 19051, decode.loss_mask: 16.0142, decode.loss_dice: 3.0332, decode.acc_seg: 429.7247, loss: 19.0474
2024-06-23 18:54:07,778 - mmseg - INFO - Iter [8100/20000]	lr: 1.291e-05, eta: 5:16:08, time: 1.670, data_time: 0.005, memory: 19051, decode.loss_mask: 17.1138, decode.loss_dice: 2.9422, decode.acc_seg: 431.0090, loss: 20.0560
2024-06-23 18:55:31,428 - mmseg - INFO - Iter [8150/20000]	lr: 1.286e-05, eta: 5:14:54, time: 1.673, data_time: 0.005, memory: 19051, decode.loss_mask: 17.5032, decode.loss_dice: 3.0820, decode.acc_seg: 431.3151, loss: 20.5852
2024-06-23 18:56:55,433 - mmseg - INFO - Iter [8200/20000]	lr: 1.282e-05, eta: 5:13:41, time: 1.680, data_time: 0.005, memory: 19051, decode.loss_mask: 17.8446, decode.loss_dice: 3.1044, decode.acc_seg: 421.0746, loss: 20.9490
2024-06-23 18:58:19,241 - mmseg - INFO - Iter [8250/20000]	lr: 1.277e-05, eta: 5:12:27, time: 1.676, data_time: 0.006, memory: 19051, decode.loss_mask: 16.7897, decode.loss_dice: 3.0371, decode.acc_seg: 432.3368, loss: 19.8269
2024-06-23 18:59:42,381 - mmseg - INFO - Iter [8300/20000]	lr: 1.273e-05, eta: 5:11:12, time: 1.663, data_time: 0.005, memory: 19051, decode.loss_mask: 14.9109, decode.loss_dice: 2.9512, decode.acc_seg: 437.2306, loss: 17.8622
2024-06-23 19:01:06,184 - mmseg - INFO - Iter [8350/20000]	lr: 1.268e-05, eta: 5:09:58, time: 1.676, data_time: 0.007, memory: 19051, decode.loss_mask: 15.9697, decode.loss_dice: 2.9317, decode.acc_seg: 437.1419, loss: 18.9014
2024-06-23 19:02:29,306 - mmseg - INFO - Iter [8400/20000]	lr: 1.264e-05, eta: 5:08:42, time: 1.662, data_time: 0.006, memory: 19051, decode.loss_mask: 17.7487, decode.loss_dice: 2.9705, decode.acc_seg: 431.2506, loss: 20.7192
2024-06-23 19:03:51,750 - mmseg - INFO - Iter [8450/20000]	lr: 1.259e-05, eta: 5:07:26, time: 1.649, data_time: 0.005, memory: 19051, decode.loss_mask: 15.9983, decode.loss_dice: 3.0370, decode.acc_seg: 440.9093, loss: 19.0353
2024-06-23 19:05:13,939 - mmseg - INFO - Iter [8500/20000]	lr: 1.255e-05, eta: 5:06:09, time: 1.644, data_time: 0.005, memory: 19051, decode.loss_mask: 15.9748, decode.loss_dice: 3.1175, decode.acc_seg: 430.9298, loss: 19.0923
2024-06-23 19:06:36,026 - mmseg - INFO - Iter [8550/20000]	lr: 1.250e-05, eta: 5:04:52, time: 1.642, data_time: 0.005, memory: 19051, decode.loss_mask: 19.5241, decode.loss_dice: 3.0331, decode.acc_seg: 414.3100, loss: 22.5572
2024-06-23 19:07:57,846 - mmseg - INFO - Iter [8600/20000]	lr: 1.246e-05, eta: 5:03:35, time: 1.636, data_time: 0.005, memory: 19051, decode.loss_mask: 17.3757, decode.loss_dice: 3.1052, decode.acc_seg: 425.6836, loss: 20.4809
2024-06-23 19:09:19,574 - mmseg - INFO - Iter [8650/20000]	lr: 1.241e-05, eta: 5:02:18, time: 1.634, data_time: 0.005, memory: 19051, decode.loss_mask: 16.0909, decode.loss_dice: 3.1147, decode.acc_seg: 435.1291, loss: 19.2057
2024-06-23 19:10:41,756 - mmseg - INFO - Iter [8700/20000]	lr: 1.237e-05, eta: 5:01:01, time: 1.644, data_time: 0.005, memory: 19051, decode.loss_mask: 16.3161, decode.loss_dice: 2.9543, decode.acc_seg: 440.2667, loss: 19.2704
2024-06-23 19:12:02,587 - mmseg - INFO - Iter [8750/20000]	lr: 1.232e-05, eta: 4:59:42, time: 1.617, data_time: 0.005, memory: 19051, decode.loss_mask: 18.3086, decode.loss_dice: 2.9190, decode.acc_seg: 429.8612, loss: 21.2277
2024-06-23 19:13:21,868 - mmseg - INFO - Iter [8800/20000]	lr: 1.228e-05, eta: 4:58:21, time: 1.586, data_time: 0.005, memory: 19051, decode.loss_mask: 16.3988, decode.loss_dice: 3.0640, decode.acc_seg: 424.6789, loss: 19.4628
2024-06-23 19:14:39,499 - mmseg - INFO - Iter [8850/20000]	lr: 1.223e-05, eta: 4:56:58, time: 1.553, data_time: 0.005, memory: 19051, decode.loss_mask: 15.6020, decode.loss_dice: 3.1040, decode.acc_seg: 435.5516, loss: 18.7060
2024-06-23 19:15:57,218 - mmseg - INFO - Iter [8900/20000]	lr: 1.219e-05, eta: 4:55:36, time: 1.554, data_time: 0.005, memory: 19051, decode.loss_mask: 16.2149, decode.loss_dice: 2.9581, decode.acc_seg: 434.0182, loss: 19.1730
2024-06-23 19:17:15,246 - mmseg - INFO - Iter [8950/20000]	lr: 1.214e-05, eta: 4:54:14, time: 1.561, data_time: 0.005, memory: 19051, decode.loss_mask: 14.8420, decode.loss_dice: 3.1637, decode.acc_seg: 428.3541, loss: 18.0057
2024-06-23 19:18:32,699 - mmseg - INFO - Exp name: xxscales_input_vpt_seg_zero_vit-b_512x512_20k_12_10.py
2024-06-23 19:18:32,699 - mmseg - INFO - Iter [9000/20000]	lr: 1.209e-05, eta: 4:52:51, time: 1.549, data_time: 0.005, memory: 19051, decode.loss_mask: 14.7647, decode.loss_dice: 3.0343, decode.acc_seg: 438.2086, loss: 17.7990
2024-06-23 19:19:53,294 - mmseg - INFO - Iter [9050/20000]	lr: 1.205e-05, eta: 4:51:32, time: 1.612, data_time: 0.046, memory: 19051, decode.loss_mask: 16.5641, decode.loss_dice: 3.0339, decode.acc_seg: 427.0600, loss: 19.5980
2024-06-23 19:21:12,320 - mmseg - INFO - Iter [9100/20000]	lr: 1.200e-05, eta: 4:50:11, time: 1.581, data_time: 0.005, memory: 19051, decode.loss_mask: 16.4554, decode.loss_dice: 3.0041, decode.acc_seg: 430.8225, loss: 19.4595
2024-06-23 19:22:30,119 - mmseg - INFO - Iter [9150/20000]	lr: 1.196e-05, eta: 4:48:48, time: 1.556, data_time: 0.005, memory: 19051, decode.loss_mask: 17.5984, decode.loss_dice: 3.0386, decode.acc_seg: 432.5312, loss: 20.6369
2024-06-23 19:23:47,810 - mmseg - INFO - Iter [9200/20000]	lr: 1.191e-05, eta: 4:47:26, time: 1.554, data_time: 0.005, memory: 19051, decode.loss_mask: 16.4122, decode.loss_dice: 3.0537, decode.acc_seg: 436.9095, loss: 19.4659
2024-06-23 19:25:05,687 - mmseg - INFO - Iter [9250/20000]	lr: 1.187e-05, eta: 4:46:04, time: 1.558, data_time: 0.005, memory: 19051, decode.loss_mask: 16.6346, decode.loss_dice: 3.1372, decode.acc_seg: 430.1771, loss: 19.7717
2024-06-23 19:26:23,747 - mmseg - INFO - Iter [9300/20000]	lr: 1.182e-05, eta: 4:44:42, time: 1.561, data_time: 0.005, memory: 19051, decode.loss_mask: 17.3341, decode.loss_dice: 2.9423, decode.acc_seg: 436.2329, loss: 20.2764
2024-06-23 19:27:43,603 - mmseg - INFO - Iter [9350/20000]	lr: 1.178e-05, eta: 4:43:22, time: 1.597, data_time: 0.005, memory: 19051, decode.loss_mask: 14.7156, decode.loss_dice: 2.9058, decode.acc_seg: 435.5689, loss: 17.6214
2024-06-23 19:29:02,185 - mmseg - INFO - Iter [9400/20000]	lr: 1.173e-05, eta: 4:42:01, time: 1.572, data_time: 0.005, memory: 19051, decode.loss_mask: 15.8188, decode.loss_dice: 2.9589, decode.acc_seg: 439.1475, loss: 18.7777
2024-06-23 19:30:20,200 - mmseg - INFO - Iter [9450/20000]	lr: 1.169e-05, eta: 4:40:39, time: 1.560, data_time: 0.005, memory: 19051, decode.loss_mask: 16.2156, decode.loss_dice: 2.8497, decode.acc_seg: 445.2219, loss: 19.0652
2024-06-23 19:31:38,716 - mmseg - INFO - Iter [9500/20000]	lr: 1.164e-05, eta: 4:39:18, time: 1.570, data_time: 0.005, memory: 19051, decode.loss_mask: 14.2884, decode.loss_dice: 3.0683, decode.acc_seg: 442.9358, loss: 17.3568
2024-06-23 19:32:57,413 - mmseg - INFO - Iter [9550/20000]	lr: 1.159e-05, eta: 4:37:57, time: 1.574, data_time: 0.004, memory: 19051, decode.loss_mask: 15.9060, decode.loss_dice: 3.0420, decode.acc_seg: 434.6334, loss: 18.9480
2024-06-23 19:34:15,838 - mmseg - INFO - Iter [9600/20000]	lr: 1.155e-05, eta: 4:36:36, time: 1.569, data_time: 0.004, memory: 19051, decode.loss_mask: 15.7392, decode.loss_dice: 2.9356, decode.acc_seg: 436.9561, loss: 18.6747
2024-06-23 19:35:33,661 - mmseg - INFO - Iter [9650/20000]	lr: 1.150e-05, eta: 4:35:14, time: 1.556, data_time: 0.004, memory: 19051, decode.loss_mask: 14.6136, decode.loss_dice: 2.9163, decode.acc_seg: 441.2367, loss: 17.5299
2024-06-23 19:36:52,188 - mmseg - INFO - Iter [9700/20000]	lr: 1.146e-05, eta: 4:33:53, time: 1.571, data_time: 0.004, memory: 19051, decode.loss_mask: 15.6771, decode.loss_dice: 3.1102, decode.acc_seg: 435.4362, loss: 18.7874
2024-06-23 19:38:10,209 - mmseg - INFO - Iter [9750/20000]	lr: 1.141e-05, eta: 4:32:31, time: 1.560, data_time: 0.004, memory: 19051, decode.loss_mask: 15.6110, decode.loss_dice: 2.9925, decode.acc_seg: 431.4056, loss: 18.6035
2024-06-23 19:39:27,926 - mmseg - INFO - Iter [9800/20000]	lr: 1.137e-05, eta: 4:31:09, time: 1.554, data_time: 0.004, memory: 19051, decode.loss_mask: 16.8612, decode.loss_dice: 3.0279, decode.acc_seg: 437.3740, loss: 19.8890
2024-06-23 19:40:45,728 - mmseg - INFO - Iter [9850/20000]	lr: 1.132e-05, eta: 4:29:47, time: 1.556, data_time: 0.005, memory: 19051, decode.loss_mask: 17.2086, decode.loss_dice: 2.9832, decode.acc_seg: 434.4945, loss: 20.1918
2024-06-23 19:42:03,748 - mmseg - INFO - Iter [9900/20000]	lr: 1.127e-05, eta: 4:28:26, time: 1.560, data_time: 0.004, memory: 19051, decode.loss_mask: 12.7455, decode.loss_dice: 2.9637, decode.acc_seg: 444.3063, loss: 15.7092
2024-06-23 19:43:21,460 - mmseg - INFO - Iter [9950/20000]	lr: 1.123e-05, eta: 4:27:04, time: 1.554, data_time: 0.004, memory: 19051, decode.loss_mask: 18.1975, decode.loss_dice: 2.9238, decode.acc_seg: 433.3072, loss: 21.1212
2024-06-23 19:44:39,135 - mmseg - INFO - Saving checkpoint at 10000 iterations
2024-06-23 19:44:39,970 - mmseg - INFO - Exp name: xxscales_input_vpt_seg_zero_vit-b_512x512_20k_12_10.py
2024-06-23 19:44:39,970 - mmseg - INFO - Iter [10000/20000]	lr: 1.118e-05, eta: 4:25:43, time: 1.570, data_time: 0.004, memory: 19051, decode.loss_mask: 15.2870, decode.loss_dice: 2.9878, decode.acc_seg: 442.5582, loss: 18.2749
2024-06-23 19:45:57,159 - mmseg - INFO - Iter [10050/20000]	lr: 1.114e-05, eta: 4:24:21, time: 1.544, data_time: 0.004, memory: 19051, decode.loss_mask: 15.3575, decode.loss_dice: 2.9336, decode.acc_seg: 430.2101, loss: 18.2912
2024-06-23 19:47:15,241 - mmseg - INFO - Iter [10100/20000]	lr: 1.109e-05, eta: 4:23:00, time: 1.562, data_time: 0.004, memory: 19051, decode.loss_mask: 16.7402, decode.loss_dice: 3.0442, decode.acc_seg: 426.1138, loss: 19.7843
2024-06-23 19:48:33,335 - mmseg - INFO - Iter [10150/20000]	lr: 1.105e-05, eta: 4:21:38, time: 1.562, data_time: 0.004, memory: 19051, decode.loss_mask: 15.3763, decode.loss_dice: 2.9554, decode.acc_seg: 436.4961, loss: 18.3317
2024-06-23 19:49:51,179 - mmseg - INFO - Iter [10200/20000]	lr: 1.100e-05, eta: 4:20:17, time: 1.557, data_time: 0.004, memory: 19051, decode.loss_mask: 16.7751, decode.loss_dice: 2.9899, decode.acc_seg: 433.2355, loss: 19.7649
2024-06-23 19:51:09,374 - mmseg - INFO - Iter [10250/20000]	lr: 1.095e-05, eta: 4:18:56, time: 1.564, data_time: 0.004, memory: 19051, decode.loss_mask: 14.9411, decode.loss_dice: 3.1394, decode.acc_seg: 435.9805, loss: 18.0805
2024-06-23 19:52:27,026 - mmseg - INFO - Iter [10300/20000]	lr: 1.091e-05, eta: 4:17:34, time: 1.553, data_time: 0.004, memory: 19051, decode.loss_mask: 16.7938, decode.loss_dice: 2.9235, decode.acc_seg: 431.3598, loss: 19.7173
2024-06-23 19:53:46,734 - mmseg - INFO - Iter [10350/20000]	lr: 1.086e-05, eta: 4:16:15, time: 1.594, data_time: 0.004, memory: 19051, decode.loss_mask: 16.8436, decode.loss_dice: 3.0296, decode.acc_seg: 423.8972, loss: 19.8731
2024-06-23 19:55:05,589 - mmseg - INFO - Iter [10400/20000]	lr: 1.082e-05, eta: 4:14:54, time: 1.577, data_time: 0.004, memory: 19051, decode.loss_mask: 14.5103, decode.loss_dice: 2.8193, decode.acc_seg: 438.5819, loss: 17.3297
2024-06-23 19:56:23,572 - mmseg - INFO - Iter [10450/20000]	lr: 1.077e-05, eta: 4:13:33, time: 1.560, data_time: 0.004, memory: 19051, decode.loss_mask: 16.5728, decode.loss_dice: 2.9956, decode.acc_seg: 431.7411, loss: 19.5684
2024-06-23 19:57:41,725 - mmseg - INFO - Iter [10500/20000]	lr: 1.072e-05, eta: 4:12:12, time: 1.563, data_time: 0.004, memory: 19051, decode.loss_mask: 15.0609, decode.loss_dice: 3.0109, decode.acc_seg: 434.0683, loss: 18.0718
2024-06-23 19:59:01,507 - mmseg - INFO - Iter [10550/20000]	lr: 1.068e-05, eta: 4:10:53, time: 1.596, data_time: 0.046, memory: 19051, decode.loss_mask: 14.4213, decode.loss_dice: 2.8718, decode.acc_seg: 446.7906, loss: 17.2931
2024-06-23 20:00:19,269 - mmseg - INFO - Iter [10600/20000]	lr: 1.063e-05, eta: 4:09:31, time: 1.555, data_time: 0.004, memory: 19051, decode.loss_mask: 17.0905, decode.loss_dice: 3.0780, decode.acc_seg: 432.1954, loss: 20.1685
2024-06-23 20:01:37,374 - mmseg - INFO - Iter [10650/20000]	lr: 1.059e-05, eta: 4:08:10, time: 1.562, data_time: 0.005, memory: 19051, decode.loss_mask: 15.3828, decode.loss_dice: 2.8939, decode.acc_seg: 437.9781, loss: 18.2767
2024-06-23 20:02:55,179 - mmseg - INFO - Iter [10700/20000]	lr: 1.054e-05, eta: 4:06:49, time: 1.556, data_time: 0.005, memory: 19051, decode.loss_mask: 15.5829, decode.loss_dice: 2.9390, decode.acc_seg: 437.5088, loss: 18.5219
2024-06-23 20:04:13,444 - mmseg - INFO - Iter [10750/20000]	lr: 1.049e-05, eta: 4:05:28, time: 1.565, data_time: 0.006, memory: 19051, decode.loss_mask: 16.1654, decode.loss_dice: 2.7662, decode.acc_seg: 440.1609, loss: 18.9316
2024-06-23 20:05:31,089 - mmseg - INFO - Iter [10800/20000]	lr: 1.045e-05, eta: 4:04:07, time: 1.553, data_time: 0.005, memory: 19051, decode.loss_mask: 16.4573, decode.loss_dice: 3.0312, decode.acc_seg: 428.9713, loss: 19.4885
2024-06-23 20:06:49,000 - mmseg - INFO - Iter [10850/20000]	lr: 1.040e-05, eta: 4:02:46, time: 1.558, data_time: 0.005, memory: 19051, decode.loss_mask: 16.0962, decode.loss_dice: 2.9920, decode.acc_seg: 438.6737, loss: 19.0882
2024-06-23 20:08:06,660 - mmseg - INFO - Iter [10900/20000]	lr: 1.035e-05, eta: 4:01:25, time: 1.553, data_time: 0.005, memory: 19051, decode.loss_mask: 14.5157, decode.loss_dice: 2.9166, decode.acc_seg: 440.5457, loss: 17.4323
2024-06-23 20:09:25,588 - mmseg - INFO - Iter [10950/20000]	lr: 1.031e-05, eta: 4:00:05, time: 1.579, data_time: 0.006, memory: 19051, decode.loss_mask: 14.7307, decode.loss_dice: 2.9972, decode.acc_seg: 436.9289, loss: 17.7279
2024-06-23 20:10:44,401 - mmseg - INFO - Exp name: xxscales_input_vpt_seg_zero_vit-b_512x512_20k_12_10.py
2024-06-23 20:10:44,401 - mmseg - INFO - Iter [11000/20000]	lr: 1.026e-05, eta: 3:58:44, time: 1.576, data_time: 0.006, memory: 19051, decode.loss_mask: 16.5721, decode.loss_dice: 2.9732, decode.acc_seg: 430.5565, loss: 19.5453
2024-06-23 20:12:02,290 - mmseg - INFO - Iter [11050/20000]	lr: 1.022e-05, eta: 3:57:23, time: 1.558, data_time: 0.005, memory: 19051, decode.loss_mask: 15.9024, decode.loss_dice: 2.9569, decode.acc_seg: 438.7038, loss: 18.8593
2024-06-23 20:13:20,099 - mmseg - INFO - Iter [11100/20000]	lr: 1.017e-05, eta: 3:56:02, time: 1.556, data_time: 0.005, memory: 19051, decode.loss_mask: 13.0087, decode.loss_dice: 3.0452, decode.acc_seg: 442.7565, loss: 16.0540
2024-06-23 20:14:39,451 - mmseg - INFO - Iter [11150/20000]	lr: 1.012e-05, eta: 3:54:43, time: 1.587, data_time: 0.006, memory: 19051, decode.loss_mask: 15.6073, decode.loss_dice: 2.9422, decode.acc_seg: 437.8603, loss: 18.5494
2024-06-23 20:15:56,994 - mmseg - INFO - Iter [11200/20000]	lr: 1.008e-05, eta: 3:53:21, time: 1.551, data_time: 0.005, memory: 19051, decode.loss_mask: 14.7442, decode.loss_dice: 3.0782, decode.acc_seg: 436.7638, loss: 17.8224
2024-06-23 20:17:14,751 - mmseg - INFO - Iter [11250/20000]	lr: 1.003e-05, eta: 3:52:01, time: 1.555, data_time: 0.005, memory: 19051, decode.loss_mask: 15.4298, decode.loss_dice: 2.8680, decode.acc_seg: 429.0062, loss: 18.2978
2024-06-23 20:18:33,072 - mmseg - INFO - Iter [11300/20000]	lr: 9.983e-06, eta: 3:50:40, time: 1.566, data_time: 0.005, memory: 19051, decode.loss_mask: 17.9121, decode.loss_dice: 2.9638, decode.acc_seg: 424.0755, loss: 20.8759
2024-06-23 20:19:51,312 - mmseg - INFO - Iter [11350/20000]	lr: 9.937e-06, eta: 3:49:19, time: 1.565, data_time: 0.005, memory: 19051, decode.loss_mask: 16.6311, decode.loss_dice: 2.8437, decode.acc_seg: 437.2817, loss: 19.4748
2024-06-23 20:21:10,543 - mmseg - INFO - Iter [11400/20000]	lr: 9.890e-06, eta: 3:48:00, time: 1.585, data_time: 0.005, memory: 19051, decode.loss_mask: 15.2821, decode.loss_dice: 2.8637, decode.acc_seg: 441.0970, loss: 18.1458
2024-06-23 20:22:28,567 - mmseg - INFO - Iter [11450/20000]	lr: 9.844e-06, eta: 3:46:39, time: 1.560, data_time: 0.005, memory: 19051, decode.loss_mask: 15.6553, decode.loss_dice: 2.9456, decode.acc_seg: 431.8446, loss: 18.6008
2024-06-23 20:23:46,109 - mmseg - INFO - Iter [11500/20000]	lr: 9.797e-06, eta: 3:45:18, time: 1.551, data_time: 0.005, memory: 19051, decode.loss_mask: 16.9709, decode.loss_dice: 2.9293, decode.acc_seg: 434.6493, loss: 19.9002
2024-06-23 20:25:03,666 - mmseg - INFO - Iter [11550/20000]	lr: 9.751e-06, eta: 3:43:57, time: 1.551, data_time: 0.005, memory: 19051, decode.loss_mask: 15.0353, decode.loss_dice: 3.0925, decode.acc_seg: 435.7091, loss: 18.1277
2024-06-23 20:26:22,282 - mmseg - INFO - Iter [11600/20000]	lr: 9.704e-06, eta: 3:42:37, time: 1.572, data_time: 0.005, memory: 19051, decode.loss_mask: 13.3429, decode.loss_dice: 2.9080, decode.acc_seg: 440.4281, loss: 16.2509
2024-06-23 20:27:39,937 - mmseg - INFO - Iter [11650/20000]	lr: 9.657e-06, eta: 3:41:16, time: 1.553, data_time: 0.005, memory: 19051, decode.loss_mask: 15.4440, decode.loss_dice: 2.9838, decode.acc_seg: 433.2679, loss: 18.4277
2024-06-23 20:28:58,058 - mmseg - INFO - Iter [11700/20000]	lr: 9.611e-06, eta: 3:39:56, time: 1.562, data_time: 0.005, memory: 19051, decode.loss_mask: 17.1603, decode.loss_dice: 2.9660, decode.acc_seg: 430.6499, loss: 20.1262
2024-06-23 20:30:16,017 - mmseg - INFO - Iter [11750/20000]	lr: 9.564e-06, eta: 3:38:35, time: 1.559, data_time: 0.005, memory: 19051, decode.loss_mask: 15.3165, decode.loss_dice: 3.0297, decode.acc_seg: 428.9030, loss: 18.3461
2024-06-23 20:31:35,056 - mmseg - INFO - Iter [11800/20000]	lr: 9.517e-06, eta: 3:37:15, time: 1.581, data_time: 0.006, memory: 19051, decode.loss_mask: 15.1225, decode.loss_dice: 2.7879, decode.acc_seg: 450.5437, loss: 17.9104
2024-06-23 20:32:53,636 - mmseg - INFO - Iter [11850/20000]	lr: 9.471e-06, eta: 3:35:55, time: 1.572, data_time: 0.005, memory: 19051, decode.loss_mask: 15.2287, decode.loss_dice: 3.0348, decode.acc_seg: 437.8410, loss: 18.2635
2024-06-23 20:34:13,659 - mmseg - INFO - Iter [11900/20000]	lr: 9.424e-06, eta: 3:34:36, time: 1.600, data_time: 0.005, memory: 19051, decode.loss_mask: 15.7052, decode.loss_dice: 2.8635, decode.acc_seg: 440.1751, loss: 18.5686
2024-06-23 20:35:34,294 - mmseg - INFO - Iter [11950/20000]	lr: 9.377e-06, eta: 3:33:17, time: 1.613, data_time: 0.005, memory: 19051, decode.loss_mask: 14.9311, decode.loss_dice: 2.9848, decode.acc_seg: 432.1044, loss: 17.9159
2024-06-23 20:36:53,567 - mmseg - INFO - Saving checkpoint at 12000 iterations
2024-06-23 20:36:54,468 - mmseg - INFO - Exp name: xxscales_input_vpt_seg_zero_vit-b_512x512_20k_12_10.py
2024-06-23 20:36:54,469 - mmseg - INFO - Iter [12000/20000]	lr: 9.330e-06, eta: 3:31:58, time: 1.604, data_time: 0.005, memory: 19051, decode.loss_mask: 15.9136, decode.loss_dice: 2.9252, decode.acc_seg: 436.3674, loss: 18.8387
2024-06-23 20:38:14,047 - mmseg - INFO - Iter [12050/20000]	lr: 9.283e-06, eta: 3:30:39, time: 1.592, data_time: 0.046, memory: 19051, decode.loss_mask: 15.0062, decode.loss_dice: 2.8934, decode.acc_seg: 436.7983, loss: 17.8996
2024-06-23 20:39:32,040 - mmseg - INFO - Iter [12100/20000]	lr: 9.236e-06, eta: 3:29:18, time: 1.560, data_time: 0.005, memory: 19051, decode.loss_mask: 15.0955, decode.loss_dice: 3.0539, decode.acc_seg: 442.4180, loss: 18.1494
2024-06-23 20:40:49,937 - mmseg - INFO - Iter [12150/20000]	lr: 9.190e-06, eta: 3:27:58, time: 1.558, data_time: 0.005, memory: 19051, decode.loss_mask: 15.5201, decode.loss_dice: 2.9995, decode.acc_seg: 436.7331, loss: 18.5196
2024-06-23 20:42:10,216 - mmseg - INFO - Iter [12200/20000]	lr: 9.143e-06, eta: 3:26:39, time: 1.606, data_time: 0.006, memory: 19051, decode.loss_mask: 13.5766, decode.loss_dice: 2.9116, decode.acc_seg: 447.5633, loss: 16.4882
2024-06-23 20:43:29,272 - mmseg - INFO - Iter [12250/20000]	lr: 9.096e-06, eta: 3:25:19, time: 1.581, data_time: 0.006, memory: 19051, decode.loss_mask: 15.3833, decode.loss_dice: 3.0277, decode.acc_seg: 437.5247, loss: 18.4110
2024-06-23 20:44:47,659 - mmseg - INFO - Iter [12300/20000]	lr: 9.049e-06, eta: 3:23:59, time: 1.568, data_time: 0.005, memory: 19051, decode.loss_mask: 17.0167, decode.loss_dice: 2.9795, decode.acc_seg: 430.5153, loss: 19.9961
2024-06-23 20:46:06,858 - mmseg - INFO - Iter [12350/20000]	lr: 9.002e-06, eta: 3:22:39, time: 1.584, data_time: 0.005, memory: 19051, decode.loss_mask: 13.9519, decode.loss_dice: 2.9985, decode.acc_seg: 439.1726, loss: 16.9504
2024-06-23 20:47:27,760 - mmseg - INFO - Iter [12400/20000]	lr: 8.954e-06, eta: 3:21:21, time: 1.618, data_time: 0.005, memory: 19051, decode.loss_mask: 15.7670, decode.loss_dice: 2.9468, decode.acc_seg: 423.8329, loss: 18.7139
2024-06-23 20:48:45,680 - mmseg - INFO - Iter [12450/20000]	lr: 8.907e-06, eta: 3:20:00, time: 1.558, data_time: 0.005, memory: 19051, decode.loss_mask: 14.9999, decode.loss_dice: 2.9495, decode.acc_seg: 447.5245, loss: 17.9495
2024-06-23 20:50:03,198 - mmseg - INFO - Iter [12500/20000]	lr: 8.860e-06, eta: 3:18:40, time: 1.550, data_time: 0.005, memory: 19051, decode.loss_mask: 16.1184, decode.loss_dice: 2.8418, decode.acc_seg: 433.6874, loss: 18.9601
2024-06-23 20:51:21,210 - mmseg - INFO - Iter [12550/20000]	lr: 8.813e-06, eta: 3:17:19, time: 1.560, data_time: 0.005, memory: 19051, decode.loss_mask: 16.6046, decode.loss_dice: 2.9016, decode.acc_seg: 442.3572, loss: 19.5062
2024-06-23 20:52:38,356 - mmseg - INFO - Iter [12600/20000]	lr: 8.766e-06, eta: 3:15:58, time: 1.543, data_time: 0.005, memory: 19051, decode.loss_mask: 14.4423, decode.loss_dice: 2.7918, decode.acc_seg: 453.5801, loss: 17.2341
2024-06-23 20:53:55,735 - mmseg - INFO - Iter [12650/20000]	lr: 8.719e-06, eta: 3:14:38, time: 1.548, data_time: 0.005, memory: 19051, decode.loss_mask: 15.2346, decode.loss_dice: 3.0315, decode.acc_seg: 434.5871, loss: 18.2661
2024-06-23 20:55:13,140 - mmseg - INFO - Iter [12700/20000]	lr: 8.671e-06, eta: 3:13:17, time: 1.548, data_time: 0.005, memory: 19051, decode.loss_mask: 15.0150, decode.loss_dice: 2.9774, decode.acc_seg: 440.6673, loss: 17.9924
2024-06-23 20:56:30,946 - mmseg - INFO - Iter [12750/20000]	lr: 8.624e-06, eta: 3:11:57, time: 1.556, data_time: 0.005, memory: 19051, decode.loss_mask: 15.3560, decode.loss_dice: 2.9510, decode.acc_seg: 432.0279, loss: 18.3070
2024-06-23 20:57:48,859 - mmseg - INFO - Iter [12800/20000]	lr: 8.577e-06, eta: 3:10:37, time: 1.558, data_time: 0.005, memory: 19051, decode.loss_mask: 15.0425, decode.loss_dice: 3.0518, decode.acc_seg: 431.4065, loss: 18.0943
2024-06-23 20:59:07,324 - mmseg - INFO - Iter [12850/20000]	lr: 8.529e-06, eta: 3:09:17, time: 1.569, data_time: 0.005, memory: 19051, decode.loss_mask: 14.6908, decode.loss_dice: 2.8865, decode.acc_seg: 445.3110, loss: 17.5773
2024-06-23 21:00:25,268 - mmseg - INFO - Iter [12900/20000]	lr: 8.482e-06, eta: 3:07:56, time: 1.559, data_time: 0.005, memory: 19051, decode.loss_mask: 14.8501, decode.loss_dice: 2.8779, decode.acc_seg: 446.6773, loss: 17.7280
2024-06-23 21:01:44,081 - mmseg - INFO - Iter [12950/20000]	lr: 8.435e-06, eta: 3:06:37, time: 1.576, data_time: 0.005, memory: 19051, decode.loss_mask: 14.4541, decode.loss_dice: 3.0096, decode.acc_seg: 435.2195, loss: 17.4637
2024-06-23 21:03:01,685 - mmseg - INFO - Exp name: xxscales_input_vpt_seg_zero_vit-b_512x512_20k_12_10.py
2024-06-23 21:03:01,686 - mmseg - INFO - Iter [13000/20000]	lr: 8.387e-06, eta: 3:05:16, time: 1.552, data_time: 0.005, memory: 19051, decode.loss_mask: 15.2564, decode.loss_dice: 2.8453, decode.acc_seg: 440.8214, loss: 18.1017
2024-06-23 21:04:19,906 - mmseg - INFO - Iter [13050/20000]	lr: 8.340e-06, eta: 3:03:56, time: 1.564, data_time: 0.005, memory: 19051, decode.loss_mask: 16.1302, decode.loss_dice: 2.9688, decode.acc_seg: 433.4107, loss: 19.0990
2024-06-23 21:05:37,831 - mmseg - INFO - Iter [13100/20000]	lr: 8.292e-06, eta: 3:02:36, time: 1.558, data_time: 0.005, memory: 19051, decode.loss_mask: 16.2351, decode.loss_dice: 2.9161, decode.acc_seg: 435.9216, loss: 19.1512
2024-06-23 21:06:55,475 - mmseg - INFO - Iter [13150/20000]	lr: 8.244e-06, eta: 3:01:16, time: 1.553, data_time: 0.005, memory: 19051, decode.loss_mask: 14.1667, decode.loss_dice: 2.8071, decode.acc_seg: 450.5843, loss: 16.9738
2024-06-23 21:08:14,861 - mmseg - INFO - Iter [13200/20000]	lr: 8.197e-06, eta: 2:59:56, time: 1.588, data_time: 0.005, memory: 19051, decode.loss_mask: 16.8153, decode.loss_dice: 2.8579, decode.acc_seg: 435.1224, loss: 19.6733
2024-06-23 21:09:32,791 - mmseg - INFO - Iter [13250/20000]	lr: 8.149e-06, eta: 2:58:36, time: 1.559, data_time: 0.005, memory: 19051, decode.loss_mask: 16.4544, decode.loss_dice: 2.7567, decode.acc_seg: 444.5651, loss: 19.2111
2024-06-23 21:10:50,388 - mmseg - INFO - Iter [13300/20000]	lr: 8.102e-06, eta: 2:57:16, time: 1.552, data_time: 0.005, memory: 19051, decode.loss_mask: 13.1967, decode.loss_dice: 2.8878, decode.acc_seg: 436.6683, loss: 16.0846
2024-06-23 21:12:08,213 - mmseg - INFO - Iter [13350/20000]	lr: 8.054e-06, eta: 2:55:56, time: 1.557, data_time: 0.005, memory: 19051, decode.loss_mask: 14.5754, decode.loss_dice: 2.9831, decode.acc_seg: 439.4567, loss: 17.5585
2024-06-23 21:13:26,350 - mmseg - INFO - Iter [13400/20000]	lr: 8.006e-06, eta: 2:54:36, time: 1.563, data_time: 0.005, memory: 19051, decode.loss_mask: 15.1071, decode.loss_dice: 2.9338, decode.acc_seg: 440.2174, loss: 18.0409
2024-06-23 21:14:44,112 - mmseg - INFO - Iter [13450/20000]	lr: 7.958e-06, eta: 2:53:16, time: 1.555, data_time: 0.005, memory: 19051, decode.loss_mask: 14.6160, decode.loss_dice: 2.9426, decode.acc_seg: 438.6887, loss: 17.5586
2024-06-23 21:16:01,855 - mmseg - INFO - Iter [13500/20000]	lr: 7.910e-06, eta: 2:51:56, time: 1.555, data_time: 0.005, memory: 19051, decode.loss_mask: 16.0452, decode.loss_dice: 3.1357, decode.acc_seg: 429.2609, loss: 19.1809
2024-06-23 21:17:19,619 - mmseg - INFO - Iter [13550/20000]	lr: 7.863e-06, eta: 2:50:35, time: 1.555, data_time: 0.004, memory: 19051, decode.loss_mask: 14.5481, decode.loss_dice: 2.8606, decode.acc_seg: 433.8761, loss: 17.4087
2024-06-23 21:18:39,783 - mmseg - INFO - Iter [13600/20000]	lr: 7.815e-06, eta: 2:49:16, time: 1.603, data_time: 0.046, memory: 19051, decode.loss_mask: 13.5622, decode.loss_dice: 2.9944, decode.acc_seg: 443.9609, loss: 16.5566
2024-06-23 21:19:57,286 - mmseg - INFO - Iter [13650/20000]	lr: 7.767e-06, eta: 2:47:56, time: 1.550, data_time: 0.004, memory: 19051, decode.loss_mask: 15.5921, decode.loss_dice: 2.9827, decode.acc_seg: 434.3515, loss: 18.5749
2024-06-23 21:21:15,183 - mmseg - INFO - Iter [13700/20000]	lr: 7.719e-06, eta: 2:46:36, time: 1.558, data_time: 0.004, memory: 19051, decode.loss_mask: 15.2826, decode.loss_dice: 2.9504, decode.acc_seg: 441.5180, loss: 18.2330
2024-06-23 21:22:33,169 - mmseg - INFO - Iter [13750/20000]	lr: 7.671e-06, eta: 2:45:16, time: 1.560, data_time: 0.004, memory: 19051, decode.loss_mask: 14.2849, decode.loss_dice: 2.8909, decode.acc_seg: 441.5317, loss: 17.1758
2024-06-23 21:23:51,316 - mmseg - INFO - Iter [13800/20000]	lr: 7.623e-06, eta: 2:43:56, time: 1.563, data_time: 0.004, memory: 19051, decode.loss_mask: 16.4749, decode.loss_dice: 2.8223, decode.acc_seg: 439.9839, loss: 19.2973
2024-06-23 21:25:09,861 - mmseg - INFO - Iter [13850/20000]	lr: 7.575e-06, eta: 2:42:37, time: 1.571, data_time: 0.004, memory: 19051, decode.loss_mask: 14.7630, decode.loss_dice: 2.7725, decode.acc_seg: 441.2048, loss: 17.5355
2024-06-23 21:26:29,050 - mmseg - INFO - Iter [13900/20000]	lr: 7.527e-06, eta: 2:41:17, time: 1.584, data_time: 0.004, memory: 19051, decode.loss_mask: 13.6096, decode.loss_dice: 2.9031, decode.acc_seg: 443.9381, loss: 16.5127
2024-06-23 21:27:47,503 - mmseg - INFO - Iter [13950/20000]	lr: 7.478e-06, eta: 2:39:58, time: 1.569, data_time: 0.004, memory: 19051, decode.loss_mask: 13.9955, decode.loss_dice: 2.9688, decode.acc_seg: 440.1082, loss: 16.9643
2024-06-23 21:29:06,869 - mmseg - INFO - Saving checkpoint at 14000 iterations
2024-06-23 21:29:07,750 - mmseg - INFO - Exp name: xxscales_input_vpt_seg_zero_vit-b_512x512_20k_12_10.py
2024-06-23 21:29:07,751 - mmseg - INFO - Iter [14000/20000]	lr: 7.430e-06, eta: 2:38:39, time: 1.605, data_time: 0.004, memory: 19051, decode.loss_mask: 15.4370, decode.loss_dice: 2.8236, decode.acc_seg: 437.2086, loss: 18.2606
2024-06-23 21:30:29,039 - mmseg - INFO - Iter [14050/20000]	lr: 7.382e-06, eta: 2:37:20, time: 1.626, data_time: 0.004, memory: 19051, decode.loss_mask: 13.4071, decode.loss_dice: 2.8655, decode.acc_seg: 445.1142, loss: 16.2726
2024-06-23 21:31:48,028 - mmseg - INFO - Iter [14100/20000]	lr: 7.334e-06, eta: 2:36:01, time: 1.580, data_time: 0.004, memory: 19051, decode.loss_mask: 14.9725, decode.loss_dice: 2.8010, decode.acc_seg: 443.0653, loss: 17.7736
2024-06-23 21:33:05,820 - mmseg - INFO - Iter [14150/20000]	lr: 7.285e-06, eta: 2:34:41, time: 1.556, data_time: 0.004, memory: 19051, decode.loss_mask: 16.0882, decode.loss_dice: 3.0257, decode.acc_seg: 421.3031, loss: 19.1139
2024-06-23 21:34:24,458 - mmseg - INFO - Iter [14200/20000]	lr: 7.237e-06, eta: 2:33:21, time: 1.573, data_time: 0.004, memory: 19051, decode.loss_mask: 13.5092, decode.loss_dice: 3.0125, decode.acc_seg: 443.1731, loss: 16.5217
2024-06-23 21:35:42,338 - mmseg - INFO - Iter [14250/20000]	lr: 7.189e-06, eta: 2:32:01, time: 1.558, data_time: 0.005, memory: 19051, decode.loss_mask: 14.7744, decode.loss_dice: 2.7919, decode.acc_seg: 444.0123, loss: 17.5664
2024-06-23 21:37:00,252 - mmseg - INFO - Iter [14300/20000]	lr: 7.140e-06, eta: 2:30:41, time: 1.558, data_time: 0.004, memory: 19051, decode.loss_mask: 17.7983, decode.loss_dice: 2.7584, decode.acc_seg: 439.3660, loss: 20.5567
2024-06-23 21:38:18,670 - mmseg - INFO - Iter [14350/20000]	lr: 7.092e-06, eta: 2:29:22, time: 1.568, data_time: 0.005, memory: 19051, decode.loss_mask: 16.5582, decode.loss_dice: 2.9223, decode.acc_seg: 437.6402, loss: 19.4805
2024-06-23 21:39:36,826 - mmseg - INFO - Iter [14400/20000]	lr: 7.043e-06, eta: 2:28:02, time: 1.563, data_time: 0.004, memory: 19051, decode.loss_mask: 14.7860, decode.loss_dice: 2.8864, decode.acc_seg: 441.4396, loss: 17.6723
2024-06-23 21:40:55,511 - mmseg - INFO - Iter [14450/20000]	lr: 6.995e-06, eta: 2:26:42, time: 1.574, data_time: 0.004, memory: 19051, decode.loss_mask: 14.4928, decode.loss_dice: 2.9502, decode.acc_seg: 437.7211, loss: 17.4430
2024-06-23 21:42:13,398 - mmseg - INFO - Iter [14500/20000]	lr: 6.946e-06, eta: 2:25:23, time: 1.558, data_time: 0.004, memory: 19051, decode.loss_mask: 14.6384, decode.loss_dice: 3.0180, decode.acc_seg: 430.0062, loss: 17.6564
2024-06-23 21:43:31,565 - mmseg - INFO - Iter [14550/20000]	lr: 6.897e-06, eta: 2:24:03, time: 1.563, data_time: 0.004, memory: 19051, decode.loss_mask: 15.7666, decode.loss_dice: 2.8783, decode.acc_seg: 437.8128, loss: 18.6449
2024-06-23 21:44:49,374 - mmseg - INFO - Iter [14600/20000]	lr: 6.849e-06, eta: 2:22:43, time: 1.556, data_time: 0.004, memory: 19051, decode.loss_mask: 15.1682, decode.loss_dice: 3.0339, decode.acc_seg: 435.3745, loss: 18.2020
2024-06-23 21:46:07,365 - mmseg - INFO - Iter [14650/20000]	lr: 6.800e-06, eta: 2:21:23, time: 1.560, data_time: 0.004, memory: 19051, decode.loss_mask: 16.1545, decode.loss_dice: 2.9144, decode.acc_seg: 436.3361, loss: 19.0689
2024-06-23 21:47:25,703 - mmseg - INFO - Iter [14700/20000]	lr: 6.751e-06, eta: 2:20:04, time: 1.567, data_time: 0.004, memory: 19051, decode.loss_mask: 14.2664, decode.loss_dice: 2.9102, decode.acc_seg: 435.5795, loss: 17.1766
2024-06-23 21:48:43,485 - mmseg - INFO - Iter [14750/20000]	lr: 6.702e-06, eta: 2:18:44, time: 1.556, data_time: 0.004, memory: 19051, decode.loss_mask: 16.2941, decode.loss_dice: 2.9778, decode.acc_seg: 439.8082, loss: 19.2720
2024-06-23 21:50:01,669 - mmseg - INFO - Iter [14800/20000]	lr: 6.653e-06, eta: 2:17:24, time: 1.564, data_time: 0.004, memory: 19051, decode.loss_mask: 14.8581, decode.loss_dice: 2.9424, decode.acc_seg: 441.2811, loss: 17.8005
2024-06-23 21:51:21,144 - mmseg - INFO - Iter [14850/20000]	lr: 6.604e-06, eta: 2:16:05, time: 1.589, data_time: 0.005, memory: 19051, decode.loss_mask: 14.6374, decode.loss_dice: 2.8226, decode.acc_seg: 441.8485, loss: 17.4600
2024-06-23 21:52:41,781 - mmseg - INFO - Iter [14900/20000]	lr: 6.555e-06, eta: 2:14:46, time: 1.613, data_time: 0.004, memory: 19051, decode.loss_mask: 14.0177, decode.loss_dice: 2.8959, decode.acc_seg: 443.4273, loss: 16.9136
2024-06-23 21:54:00,957 - mmseg - INFO - Iter [14950/20000]	lr: 6.506e-06, eta: 2:13:27, time: 1.584, data_time: 0.004, memory: 19051, decode.loss_mask: 14.1678, decode.loss_dice: 2.9879, decode.acc_seg: 440.4261, loss: 17.1557
2024-06-23 21:55:19,252 - mmseg - INFO - Exp name: xxscales_input_vpt_seg_zero_vit-b_512x512_20k_12_10.py
2024-06-23 21:55:19,253 - mmseg - INFO - Iter [15000/20000]	lr: 6.457e-06, eta: 2:12:07, time: 1.566, data_time: 0.005, memory: 19051, decode.loss_mask: 15.7090, decode.loss_dice: 2.8248, decode.acc_seg: 446.7755, loss: 18.5338
2024-06-23 21:56:37,315 - mmseg - INFO - Iter [15050/20000]	lr: 6.408e-06, eta: 2:10:47, time: 1.561, data_time: 0.004, memory: 19051, decode.loss_mask: 14.1211, decode.loss_dice: 2.8599, decode.acc_seg: 446.5783, loss: 16.9811
2024-06-23 21:57:57,570 - mmseg - INFO - Iter [15100/20000]	lr: 6.359e-06, eta: 2:09:29, time: 1.605, data_time: 0.046, memory: 19051, decode.loss_mask: 14.7504, decode.loss_dice: 2.9397, decode.acc_seg: 444.2095, loss: 17.6901
2024-06-23 21:59:15,744 - mmseg - INFO - Iter [15150/20000]	lr: 6.310e-06, eta: 2:08:09, time: 1.563, data_time: 0.004, memory: 19051, decode.loss_mask: 14.3459, decode.loss_dice: 2.9196, decode.acc_seg: 435.6530, loss: 17.2655
2024-06-23 22:00:34,293 - mmseg - INFO - Iter [15200/20000]	lr: 6.260e-06, eta: 2:06:49, time: 1.571, data_time: 0.004, memory: 19051, decode.loss_mask: 14.5485, decode.loss_dice: 2.7686, decode.acc_seg: 448.8812, loss: 17.3170
2024-06-23 22:01:52,354 - mmseg - INFO - Iter [15250/20000]	lr: 6.211e-06, eta: 2:05:30, time: 1.561, data_time: 0.004, memory: 19051, decode.loss_mask: 14.7805, decode.loss_dice: 2.8707, decode.acc_seg: 447.5792, loss: 17.6512
2024-06-23 22:03:10,563 - mmseg - INFO - Iter [15300/20000]	lr: 6.162e-06, eta: 2:04:10, time: 1.564, data_time: 0.004, memory: 19051, decode.loss_mask: 13.1734, decode.loss_dice: 2.8514, decode.acc_seg: 443.2718, loss: 16.0249
2024-06-23 22:04:28,593 - mmseg - INFO - Iter [15350/20000]	lr: 6.112e-06, eta: 2:02:51, time: 1.561, data_time: 0.004, memory: 19051, decode.loss_mask: 14.4752, decode.loss_dice: 2.9477, decode.acc_seg: 442.1396, loss: 17.4229
2024-06-23 22:05:48,314 - mmseg - INFO - Iter [15400/20000]	lr: 6.063e-06, eta: 2:01:31, time: 1.594, data_time: 0.004, memory: 19051, decode.loss_mask: 18.5465, decode.loss_dice: 2.8271, decode.acc_seg: 435.9358, loss: 21.3735
2024-06-23 22:07:10,285 - mmseg - INFO - Iter [15450/20000]	lr: 6.013e-06, eta: 2:00:13, time: 1.639, data_time: 0.004, memory: 19051, decode.loss_mask: 14.4412, decode.loss_dice: 2.9326, decode.acc_seg: 439.2141, loss: 17.3738
2024-06-23 22:08:31,962 - mmseg - INFO - Iter [15500/20000]	lr: 5.964e-06, eta: 1:58:54, time: 1.634, data_time: 0.004, memory: 19051, decode.loss_mask: 14.6637, decode.loss_dice: 2.9274, decode.acc_seg: 436.6588, loss: 17.5911
2024-06-23 22:09:53,956 - mmseg - INFO - Iter [15550/20000]	lr: 5.914e-06, eta: 1:57:36, time: 1.640, data_time: 0.004, memory: 19051, decode.loss_mask: 13.7842, decode.loss_dice: 2.8857, decode.acc_seg: 444.1272, loss: 16.6699
2024-06-23 22:11:15,530 - mmseg - INFO - Iter [15600/20000]	lr: 5.864e-06, eta: 1:56:17, time: 1.631, data_time: 0.004, memory: 19051, decode.loss_mask: 14.9944, decode.loss_dice: 2.8429, decode.acc_seg: 445.2707, loss: 17.8373
2024-06-23 22:12:37,617 - mmseg - INFO - Iter [15650/20000]	lr: 5.815e-06, eta: 1:54:59, time: 1.642, data_time: 0.004, memory: 19051, decode.loss_mask: 13.8972, decode.loss_dice: 2.7726, decode.acc_seg: 443.9271, loss: 16.6699
2024-06-23 22:13:59,539 - mmseg - INFO - Iter [15700/20000]	lr: 5.765e-06, eta: 1:53:40, time: 1.638, data_time: 0.004, memory: 19051, decode.loss_mask: 15.1586, decode.loss_dice: 2.7735, decode.acc_seg: 445.5019, loss: 17.9321
2024-06-23 22:15:21,523 - mmseg - INFO - Iter [15750/20000]	lr: 5.715e-06, eta: 1:52:22, time: 1.640, data_time: 0.005, memory: 19051, decode.loss_mask: 13.5710, decode.loss_dice: 2.9170, decode.acc_seg: 440.8690, loss: 16.4879
2024-06-23 22:16:43,294 - mmseg - INFO - Iter [15800/20000]	lr: 5.665e-06, eta: 1:51:03, time: 1.635, data_time: 0.004, memory: 19051, decode.loss_mask: 12.9858, decode.loss_dice: 2.8895, decode.acc_seg: 443.8922, loss: 15.8753
2024-06-23 22:18:04,657 - mmseg - INFO - Iter [15850/20000]	lr: 5.615e-06, eta: 1:49:44, time: 1.627, data_time: 0.004, memory: 19051, decode.loss_mask: 14.9156, decode.loss_dice: 2.9292, decode.acc_seg: 436.4401, loss: 17.8449
2024-06-23 22:19:23,301 - mmseg - INFO - Iter [15900/20000]	lr: 5.565e-06, eta: 1:48:25, time: 1.573, data_time: 0.004, memory: 19051, decode.loss_mask: 13.2989, decode.loss_dice: 2.7963, decode.acc_seg: 450.2018, loss: 16.0952
2024-06-23 22:20:41,415 - mmseg - INFO - Iter [15950/20000]	lr: 5.515e-06, eta: 1:47:05, time: 1.562, data_time: 0.004, memory: 19051, decode.loss_mask: 14.4301, decode.loss_dice: 2.8334, decode.acc_seg: 435.1907, loss: 17.2635
2024-06-23 22:21:59,305 - mmseg - INFO - Saving checkpoint at 16000 iterations
2024-06-23 22:22:00,158 - mmseg - INFO - Exp name: xxscales_input_vpt_seg_zero_vit-b_512x512_20k_12_10.py
2024-06-23 22:22:00,158 - mmseg - INFO - Iter [16000/20000]	lr: 5.465e-06, eta: 1:45:45, time: 1.575, data_time: 0.004, memory: 19051, decode.loss_mask: 13.9777, decode.loss_dice: 2.9119, decode.acc_seg: 440.4312, loss: 16.8895
2024-06-23 22:23:17,941 - mmseg - INFO - Iter [16050/20000]	lr: 5.414e-06, eta: 1:44:26, time: 1.556, data_time: 0.004, memory: 19051, decode.loss_mask: 16.7845, decode.loss_dice: 2.8751, decode.acc_seg: 436.4279, loss: 19.6595
2024-06-23 22:24:35,675 - mmseg - INFO - Iter [16100/20000]	lr: 5.364e-06, eta: 1:43:06, time: 1.555, data_time: 0.004, memory: 19051, decode.loss_mask: 15.8807, decode.loss_dice: 3.0163, decode.acc_seg: 431.0921, loss: 18.8970
2024-06-23 22:25:53,425 - mmseg - INFO - Iter [16150/20000]	lr: 5.314e-06, eta: 1:41:46, time: 1.555, data_time: 0.004, memory: 19051, decode.loss_mask: 13.3300, decode.loss_dice: 2.8664, decode.acc_seg: 441.7092, loss: 16.1964
2024-06-23 22:27:12,564 - mmseg - INFO - Iter [16200/20000]	lr: 5.263e-06, eta: 1:40:27, time: 1.583, data_time: 0.004, memory: 19051, decode.loss_mask: 15.6383, decode.loss_dice: 2.9161, decode.acc_seg: 433.2801, loss: 18.5545
2024-06-23 22:28:30,345 - mmseg - INFO - Iter [16250/20000]	lr: 5.213e-06, eta: 1:39:07, time: 1.556, data_time: 0.004, memory: 19051, decode.loss_mask: 13.8876, decode.loss_dice: 2.9654, decode.acc_seg: 438.6703, loss: 16.8529
2024-06-23 22:29:48,001 - mmseg - INFO - Iter [16300/20000]	lr: 5.162e-06, eta: 1:37:48, time: 1.553, data_time: 0.004, memory: 19051, decode.loss_mask: 15.9354, decode.loss_dice: 2.9750, decode.acc_seg: 425.1966, loss: 18.9104
2024-06-23 22:31:06,230 - mmseg - INFO - Iter [16350/20000]	lr: 5.111e-06, eta: 1:36:28, time: 1.565, data_time: 0.004, memory: 19051, decode.loss_mask: 14.7621, decode.loss_dice: 2.7979, decode.acc_seg: 444.0020, loss: 17.5600
2024-06-23 22:32:24,178 - mmseg - INFO - Iter [16400/20000]	lr: 5.061e-06, eta: 1:35:09, time: 1.559, data_time: 0.004, memory: 19051, decode.loss_mask: 16.0488, decode.loss_dice: 2.8991, decode.acc_seg: 436.8195, loss: 18.9479
2024-06-23 22:33:43,604 - mmseg - INFO - Iter [16450/20000]	lr: 5.010e-06, eta: 1:33:49, time: 1.589, data_time: 0.004, memory: 19051, decode.loss_mask: 13.5899, decode.loss_dice: 2.8298, decode.acc_seg: 445.2253, loss: 16.4197
2024-06-23 22:35:01,463 - mmseg - INFO - Iter [16500/20000]	lr: 4.959e-06, eta: 1:32:30, time: 1.557, data_time: 0.004, memory: 19051, decode.loss_mask: 17.5614, decode.loss_dice: 2.8575, decode.acc_seg: 437.7167, loss: 20.4189
2024-06-23 22:36:19,462 - mmseg - INFO - Iter [16550/20000]	lr: 4.908e-06, eta: 1:31:10, time: 1.560, data_time: 0.004, memory: 19051, decode.loss_mask: 12.3116, decode.loss_dice: 2.8264, decode.acc_seg: 447.3389, loss: 15.1380
2024-06-23 22:37:39,049 - mmseg - INFO - Iter [16600/20000]	lr: 4.857e-06, eta: 1:29:51, time: 1.592, data_time: 0.046, memory: 19051, decode.loss_mask: 14.1939, decode.loss_dice: 2.8578, decode.acc_seg: 442.4119, loss: 17.0517
2024-06-23 22:38:56,769 - mmseg - INFO - Iter [16650/20000]	lr: 4.806e-06, eta: 1:28:31, time: 1.554, data_time: 0.004, memory: 19051, decode.loss_mask: 13.3757, decode.loss_dice: 2.8386, decode.acc_seg: 451.4550, loss: 16.2143
2024-06-23 22:40:14,841 - mmseg - INFO - Iter [16700/20000]	lr: 4.755e-06, eta: 1:27:12, time: 1.561, data_time: 0.004, memory: 19051, decode.loss_mask: 14.7615, decode.loss_dice: 2.8786, decode.acc_seg: 440.0039, loss: 17.6401
2024-06-23 22:41:32,898 - mmseg - INFO - Iter [16750/20000]	lr: 4.704e-06, eta: 1:25:52, time: 1.561, data_time: 0.004, memory: 19051, decode.loss_mask: 13.1768, decode.loss_dice: 2.8503, decode.acc_seg: 452.7903, loss: 16.0271
2024-06-23 22:42:50,531 - mmseg - INFO - Iter [16800/20000]	lr: 4.652e-06, eta: 1:24:33, time: 1.553, data_time: 0.004, memory: 19051, decode.loss_mask: 13.8897, decode.loss_dice: 3.0028, decode.acc_seg: 440.9437, loss: 16.8924
2024-06-23 22:44:08,052 - mmseg - INFO - Iter [16850/20000]	lr: 4.601e-06, eta: 1:23:13, time: 1.550, data_time: 0.004, memory: 19051, decode.loss_mask: 14.7028, decode.loss_dice: 2.8557, decode.acc_seg: 435.9053, loss: 17.5586
2024-06-23 22:45:26,076 - mmseg - INFO - Iter [16900/20000]	lr: 4.550e-06, eta: 1:21:54, time: 1.560, data_time: 0.004, memory: 19051, decode.loss_mask: 14.8665, decode.loss_dice: 2.8930, decode.acc_seg: 434.2631, loss: 17.7595
2024-06-23 22:46:44,155 - mmseg - INFO - Iter [16950/20000]	lr: 4.498e-06, eta: 1:20:34, time: 1.562, data_time: 0.004, memory: 19051, decode.loss_mask: 14.9205, decode.loss_dice: 3.0095, decode.acc_seg: 435.4027, loss: 17.9300
2024-06-23 22:48:01,972 - mmseg - INFO - Exp name: xxscales_input_vpt_seg_zero_vit-b_512x512_20k_12_10.py
2024-06-23 22:48:01,973 - mmseg - INFO - Iter [17000/20000]	lr: 4.446e-06, eta: 1:19:15, time: 1.556, data_time: 0.004, memory: 19051, decode.loss_mask: 15.2073, decode.loss_dice: 2.7975, decode.acc_seg: 448.1388, loss: 18.0049
2024-06-23 22:49:19,440 - mmseg - INFO - Iter [17050/20000]	lr: 4.395e-06, eta: 1:17:55, time: 1.549, data_time: 0.004, memory: 19051, decode.loss_mask: 13.7024, decode.loss_dice: 2.9544, decode.acc_seg: 435.7707, loss: 16.6568
2024-06-23 22:50:37,390 - mmseg - INFO - Iter [17100/20000]	lr: 4.343e-06, eta: 1:16:36, time: 1.559, data_time: 0.004, memory: 19051, decode.loss_mask: 15.7678, decode.loss_dice: 2.7332, decode.acc_seg: 440.3815, loss: 18.5010
2024-06-23 22:51:55,849 - mmseg - INFO - Iter [17150/20000]	lr: 4.291e-06, eta: 1:15:16, time: 1.569, data_time: 0.005, memory: 19051, decode.loss_mask: 15.8864, decode.loss_dice: 2.8541, decode.acc_seg: 437.8441, loss: 18.7404
2024-06-23 22:53:15,801 - mmseg - INFO - Iter [17200/20000]	lr: 4.239e-06, eta: 1:13:57, time: 1.599, data_time: 0.004, memory: 19084, decode.loss_mask: 12.7961, decode.loss_dice: 3.0247, decode.acc_seg: 444.0615, loss: 15.8209
2024-06-23 22:54:35,340 - mmseg - INFO - Iter [17250/20000]	lr: 4.187e-06, eta: 1:12:38, time: 1.591, data_time: 0.005, memory: 19084, decode.loss_mask: 13.4784, decode.loss_dice: 2.8357, decode.acc_seg: 441.2214, loss: 16.3140
2024-06-23 22:55:53,059 - mmseg - INFO - Iter [17300/20000]	lr: 4.135e-06, eta: 1:11:18, time: 1.554, data_time: 0.004, memory: 19084, decode.loss_mask: 14.0168, decode.loss_dice: 2.8794, decode.acc_seg: 440.9354, loss: 16.8962
2024-06-23 22:57:11,114 - mmseg - INFO - Iter [17350/20000]	lr: 4.082e-06, eta: 1:09:59, time: 1.561, data_time: 0.004, memory: 19084, decode.loss_mask: 14.3566, decode.loss_dice: 2.7833, decode.acc_seg: 444.3619, loss: 17.1399
2024-06-23 22:58:28,564 - mmseg - INFO - Iter [17400/20000]	lr: 4.030e-06, eta: 1:08:39, time: 1.549, data_time: 0.004, memory: 19084, decode.loss_mask: 12.9504, decode.loss_dice: 2.8193, decode.acc_seg: 445.6668, loss: 15.7697
2024-06-23 22:59:47,617 - mmseg - INFO - Iter [17450/20000]	lr: 3.978e-06, eta: 1:07:20, time: 1.581, data_time: 0.004, memory: 19084, decode.loss_mask: 13.6604, decode.loss_dice: 2.9980, decode.acc_seg: 435.0115, loss: 16.6584
2024-06-23 23:01:06,540 - mmseg - INFO - Iter [17500/20000]	lr: 3.925e-06, eta: 1:06:01, time: 1.578, data_time: 0.004, memory: 19084, decode.loss_mask: 14.0758, decode.loss_dice: 2.9018, decode.acc_seg: 441.7066, loss: 16.9776
2024-06-23 23:02:24,678 - mmseg - INFO - Iter [17550/20000]	lr: 3.872e-06, eta: 1:04:42, time: 1.563, data_time: 0.005, memory: 19084, decode.loss_mask: 15.5091, decode.loss_dice: 2.8255, decode.acc_seg: 450.2194, loss: 18.3346
2024-06-23 23:03:42,718 - mmseg - INFO - Iter [17600/20000]	lr: 3.820e-06, eta: 1:03:22, time: 1.561, data_time: 0.004, memory: 19084, decode.loss_mask: 13.1889, decode.loss_dice: 3.0321, decode.acc_seg: 439.6652, loss: 16.2211
2024-06-23 23:05:00,729 - mmseg - INFO - Iter [17650/20000]	lr: 3.767e-06, eta: 1:02:03, time: 1.560, data_time: 0.004, memory: 19084, decode.loss_mask: 12.0572, decode.loss_dice: 2.8364, decode.acc_seg: 448.1418, loss: 14.8936
2024-06-23 23:06:20,605 - mmseg - INFO - Iter [17700/20000]	lr: 3.714e-06, eta: 1:00:44, time: 1.598, data_time: 0.004, memory: 19084, decode.loss_mask: 15.6566, decode.loss_dice: 2.8956, decode.acc_seg: 433.9181, loss: 18.5522
2024-06-23 23:07:42,477 - mmseg - INFO - Iter [17750/20000]	lr: 3.661e-06, eta: 0:59:25, time: 1.637, data_time: 0.004, memory: 19084, decode.loss_mask: 14.7219, decode.loss_dice: 2.8992, decode.acc_seg: 433.2479, loss: 17.6211
2024-06-23 23:09:04,544 - mmseg - INFO - Iter [17800/20000]	lr: 3.607e-06, eta: 0:58:06, time: 1.641, data_time: 0.004, memory: 19084, decode.loss_mask: 14.4929, decode.loss_dice: 2.9018, decode.acc_seg: 438.2819, loss: 17.3947
2024-06-23 23:10:26,354 - mmseg - INFO - Iter [17850/20000]	lr: 3.554e-06, eta: 0:56:47, time: 1.636, data_time: 0.004, memory: 19084, decode.loss_mask: 14.8103, decode.loss_dice: 2.8693, decode.acc_seg: 439.5447, loss: 17.6797
2024-06-23 23:11:48,338 - mmseg - INFO - Iter [17900/20000]	lr: 3.500e-06, eta: 0:55:28, time: 1.640, data_time: 0.004, memory: 19084, decode.loss_mask: 13.7636, decode.loss_dice: 2.8991, decode.acc_seg: 440.7194, loss: 16.6627
2024-06-23 23:13:10,469 - mmseg - INFO - Iter [17950/20000]	lr: 3.447e-06, eta: 0:54:09, time: 1.643, data_time: 0.004, memory: 19084, decode.loss_mask: 14.1927, decode.loss_dice: 2.8386, decode.acc_seg: 446.8594, loss: 17.0313
2024-06-23 23:14:32,687 - mmseg - INFO - Saving checkpoint at 18000 iterations
2024-06-23 23:14:33,711 - mmseg - INFO - Exp name: xxscales_input_vpt_seg_zero_vit-b_512x512_20k_12_10.py
2024-06-23 23:14:33,712 - mmseg - INFO - Iter [18000/20000]	lr: 3.393e-06, eta: 0:52:50, time: 1.665, data_time: 0.004, memory: 19084, decode.loss_mask: 13.8481, decode.loss_dice: 2.8055, decode.acc_seg: 447.3399, loss: 16.6536
2024-06-23 23:15:55,287 - mmseg - INFO - Iter [18050/20000]	lr: 3.339e-06, eta: 0:51:31, time: 1.631, data_time: 0.004, memory: 19084, decode.loss_mask: 14.7459, decode.loss_dice: 2.8404, decode.acc_seg: 436.3671, loss: 17.5864
2024-06-23 23:17:19,436 - mmseg - INFO - Iter [18100/20000]	lr: 3.285e-06, eta: 0:50:13, time: 1.683, data_time: 0.046, memory: 19084, decode.loss_mask: 14.7427, decode.loss_dice: 2.8947, decode.acc_seg: 441.5348, loss: 17.6374
2024-06-23 23:18:41,628 - mmseg - INFO - Iter [18150/20000]	lr: 3.231e-06, eta: 0:48:54, time: 1.644, data_time: 0.004, memory: 19084, decode.loss_mask: 15.4267, decode.loss_dice: 2.8374, decode.acc_seg: 440.3154, loss: 18.2640
2024-06-23 23:20:04,275 - mmseg - INFO - Iter [18200/20000]	lr: 3.177e-06, eta: 0:47:35, time: 1.653, data_time: 0.004, memory: 19084, decode.loss_mask: 15.7777, decode.loss_dice: 2.8670, decode.acc_seg: 433.3216, loss: 18.6447
2024-06-23 23:21:26,511 - mmseg - INFO - Iter [18250/20000]	lr: 3.122e-06, eta: 0:46:16, time: 1.645, data_time: 0.004, memory: 19084, decode.loss_mask: 13.9688, decode.loss_dice: 2.9525, decode.acc_seg: 438.3495, loss: 16.9213
2024-06-23 23:22:48,581 - mmseg - INFO - Iter [18300/20000]	lr: 3.068e-06, eta: 0:44:56, time: 1.641, data_time: 0.004, memory: 19084, decode.loss_mask: 14.5448, decode.loss_dice: 3.0504, decode.acc_seg: 430.4975, loss: 17.5952
2024-06-23 23:24:11,195 - mmseg - INFO - Iter [18350/20000]	lr: 3.013e-06, eta: 0:43:37, time: 1.652, data_time: 0.004, memory: 19084, decode.loss_mask: 14.7709, decode.loss_dice: 2.8117, decode.acc_seg: 437.6613, loss: 17.5826
2024-06-23 23:25:33,581 - mmseg - INFO - Iter [18400/20000]	lr: 2.958e-06, eta: 0:42:18, time: 1.648, data_time: 0.004, memory: 19084, decode.loss_mask: 14.7500, decode.loss_dice: 2.8215, decode.acc_seg: 442.0635, loss: 17.5716
2024-06-23 23:26:56,276 - mmseg - INFO - Iter [18450/20000]	lr: 2.903e-06, eta: 0:40:59, time: 1.654, data_time: 0.004, memory: 19084, decode.loss_mask: 13.4146, decode.loss_dice: 2.7574, decode.acc_seg: 453.7261, loss: 16.1720
2024-06-23 23:28:18,706 - mmseg - INFO - Iter [18500/20000]	lr: 2.847e-06, eta: 0:39:40, time: 1.649, data_time: 0.004, memory: 19084, decode.loss_mask: 14.1297, decode.loss_dice: 2.9160, decode.acc_seg: 445.9933, loss: 17.0457
2024-06-23 23:29:40,719 - mmseg - INFO - Iter [18550/20000]	lr: 2.792e-06, eta: 0:38:21, time: 1.640, data_time: 0.004, memory: 19084, decode.loss_mask: 14.0033, decode.loss_dice: 2.9187, decode.acc_seg: 444.6605, loss: 16.9220
2024-06-23 23:31:03,414 - mmseg - INFO - Iter [18600/20000]	lr: 2.736e-06, eta: 0:37:02, time: 1.654, data_time: 0.004, memory: 19084, decode.loss_mask: 14.1267, decode.loss_dice: 2.8462, decode.acc_seg: 442.1781, loss: 16.9730
2024-06-23 23:32:25,741 - mmseg - INFO - Iter [18650/20000]	lr: 2.680e-06, eta: 0:35:43, time: 1.647, data_time: 0.004, memory: 19084, decode.loss_mask: 14.3582, decode.loss_dice: 2.9859, decode.acc_seg: 436.3470, loss: 17.3441
2024-06-23 23:33:47,570 - mmseg - INFO - Iter [18700/20000]	lr: 2.624e-06, eta: 0:34:24, time: 1.637, data_time: 0.004, memory: 19084, decode.loss_mask: 14.9216, decode.loss_dice: 2.8717, decode.acc_seg: 439.4335, loss: 17.7933
2024-06-23 23:35:09,299 - mmseg - INFO - Iter [18750/20000]	lr: 2.568e-06, eta: 0:33:04, time: 1.635, data_time: 0.004, memory: 19084, decode.loss_mask: 17.1932, decode.loss_dice: 2.8380, decode.acc_seg: 433.8862, loss: 20.0312
2024-06-23 23:36:31,827 - mmseg - INFO - Iter [18800/20000]	lr: 2.512e-06, eta: 0:31:45, time: 1.651, data_time: 0.004, memory: 19084, decode.loss_mask: 12.9471, decode.loss_dice: 2.9748, decode.acc_seg: 434.6056, loss: 15.9219
2024-06-23 23:37:54,213 - mmseg - INFO - Iter [18850/20000]	lr: 2.455e-06, eta: 0:30:26, time: 1.648, data_time: 0.004, memory: 19084, decode.loss_mask: 13.1183, decode.loss_dice: 2.8159, decode.acc_seg: 445.6464, loss: 15.9342
2024-06-23 23:39:16,832 - mmseg - INFO - Iter [18900/20000]	lr: 2.398e-06, eta: 0:29:07, time: 1.652, data_time: 0.004, memory: 19084, decode.loss_mask: 14.7587, decode.loss_dice: 2.8881, decode.acc_seg: 445.5566, loss: 17.6468
2024-06-23 23:40:39,582 - mmseg - INFO - Iter [18950/20000]	lr: 2.341e-06, eta: 0:27:47, time: 1.655, data_time: 0.004, memory: 19084, decode.loss_mask: 14.5283, decode.loss_dice: 2.9334, decode.acc_seg: 438.7667, loss: 17.4618
2024-06-23 23:42:01,544 - mmseg - INFO - Exp name: xxscales_input_vpt_seg_zero_vit-b_512x512_20k_12_10.py
2024-06-23 23:42:01,545 - mmseg - INFO - Iter [19000/20000]	lr: 2.283e-06, eta: 0:26:28, time: 1.639, data_time: 0.004, memory: 19084, decode.loss_mask: 14.0380, decode.loss_dice: 2.9056, decode.acc_seg: 439.5095, loss: 16.9437
2024-06-23 23:43:23,953 - mmseg - INFO - Iter [19050/20000]	lr: 2.225e-06, eta: 0:25:09, time: 1.648, data_time: 0.004, memory: 19084, decode.loss_mask: 12.6688, decode.loss_dice: 2.9168, decode.acc_seg: 441.1723, loss: 15.5856
2024-06-23 23:44:46,221 - mmseg - INFO - Iter [19100/20000]	lr: 2.167e-06, eta: 0:23:50, time: 1.645, data_time: 0.004, memory: 19084, decode.loss_mask: 14.6191, decode.loss_dice: 2.7768, decode.acc_seg: 447.8833, loss: 17.3958
2024-06-23 23:46:08,695 - mmseg - INFO - Iter [19150/20000]	lr: 2.109e-06, eta: 0:22:30, time: 1.649, data_time: 0.004, memory: 19084, decode.loss_mask: 14.6511, decode.loss_dice: 2.8252, decode.acc_seg: 443.4185, loss: 17.4763
2024-06-23 23:47:31,523 - mmseg - INFO - Iter [19200/20000]	lr: 2.050e-06, eta: 0:21:11, time: 1.657, data_time: 0.004, memory: 19084, decode.loss_mask: 14.9597, decode.loss_dice: 2.9100, decode.acc_seg: 436.0688, loss: 17.8697
2024-06-23 23:48:53,708 - mmseg - INFO - Iter [19250/20000]	lr: 1.991e-06, eta: 0:19:52, time: 1.644, data_time: 0.004, memory: 19084, decode.loss_mask: 15.8847, decode.loss_dice: 2.8284, decode.acc_seg: 440.4627, loss: 18.7131
2024-06-23 23:50:16,047 - mmseg - INFO - Iter [19300/20000]	lr: 1.931e-06, eta: 0:18:32, time: 1.647, data_time: 0.004, memory: 19084, decode.loss_mask: 12.4608, decode.loss_dice: 2.8836, decode.acc_seg: 445.1004, loss: 15.3444
2024-06-23 23:51:37,944 - mmseg - INFO - Iter [19350/20000]	lr: 1.871e-06, eta: 0:17:13, time: 1.638, data_time: 0.004, memory: 19084, decode.loss_mask: 14.6768, decode.loss_dice: 2.8509, decode.acc_seg: 442.6414, loss: 17.5278
2024-06-23 23:53:00,803 - mmseg - INFO - Iter [19400/20000]	lr: 1.811e-06, eta: 0:15:53, time: 1.657, data_time: 0.004, memory: 19084, decode.loss_mask: 14.9824, decode.loss_dice: 2.8971, decode.acc_seg: 440.3624, loss: 17.8796
2024-06-23 23:54:23,314 - mmseg - INFO - Iter [19450/20000]	lr: 1.750e-06, eta: 0:14:34, time: 1.650, data_time: 0.004, memory: 19084, decode.loss_mask: 13.6495, decode.loss_dice: 2.9746, decode.acc_seg: 441.5883, loss: 16.6241
2024-06-23 23:55:45,576 - mmseg - INFO - Iter [19500/20000]	lr: 1.688e-06, eta: 0:13:15, time: 1.645, data_time: 0.004, memory: 19084, decode.loss_mask: 12.4063, decode.loss_dice: 2.8813, decode.acc_seg: 443.3493, loss: 15.2876
2024-06-23 23:57:07,711 - mmseg - INFO - Iter [19550/20000]	lr: 1.626e-06, eta: 0:11:55, time: 1.643, data_time: 0.004, memory: 19084, decode.loss_mask: 16.7500, decode.loss_dice: 2.8135, decode.acc_seg: 437.0368, loss: 19.5635
2024-06-23 23:58:32,347 - mmseg - INFO - Iter [19600/20000]	lr: 1.563e-06, eta: 0:10:36, time: 1.693, data_time: 0.045, memory: 19084, decode.loss_mask: 14.2050, decode.loss_dice: 2.8880, decode.acc_seg: 438.4556, loss: 17.0930
2024-06-23 23:59:54,687 - mmseg - INFO - Iter [19650/20000]	lr: 1.500e-06, eta: 0:09:16, time: 1.647, data_time: 0.004, memory: 19084, decode.loss_mask: 13.6628, decode.loss_dice: 2.8210, decode.acc_seg: 441.6566, loss: 16.4838
2024-06-24 00:01:17,368 - mmseg - INFO - Iter [19700/20000]	lr: 1.435e-06, eta: 0:07:57, time: 1.654, data_time: 0.004, memory: 19084, decode.loss_mask: 15.4995, decode.loss_dice: 2.9417, decode.acc_seg: 432.6477, loss: 18.4412
2024-06-24 00:02:40,110 - mmseg - INFO - Iter [19750/20000]	lr: 1.369e-06, eta: 0:06:37, time: 1.655, data_time: 0.004, memory: 19084, decode.loss_mask: 13.6294, decode.loss_dice: 2.9439, decode.acc_seg: 440.9736, loss: 16.5734
2024-06-24 00:04:02,309 - mmseg - INFO - Iter [19800/20000]	lr: 1.302e-06, eta: 0:05:18, time: 1.644, data_time: 0.004, memory: 19084, decode.loss_mask: 14.0218, decode.loss_dice: 2.8656, decode.acc_seg: 448.7019, loss: 16.8874
2024-06-24 00:05:24,791 - mmseg - INFO - Iter [19850/20000]	lr: 1.234e-06, eta: 0:03:58, time: 1.650, data_time: 0.004, memory: 19084, decode.loss_mask: 15.6954, decode.loss_dice: 2.9217, decode.acc_seg: 437.0982, loss: 18.6171
2024-06-24 00:06:47,086 - mmseg - INFO - Iter [19900/20000]	lr: 1.163e-06, eta: 0:02:39, time: 1.646, data_time: 0.004, memory: 19084, decode.loss_mask: 12.6410, decode.loss_dice: 2.8099, decode.acc_seg: 446.0839, loss: 15.4509
2024-06-24 00:08:09,419 - mmseg - INFO - Iter [19950/20000]	lr: 1.088e-06, eta: 0:01:19, time: 1.647, data_time: 0.004, memory: 19084, decode.loss_mask: 14.9362, decode.loss_dice: 2.8287, decode.acc_seg: 437.8192, loss: 17.7649
2024-06-24 00:09:31,628 - mmseg - INFO - Saving checkpoint at 20000 iterations
2024-06-24 00:09:32,545 - mmseg - INFO - Exp name: xxscales_input_vpt_seg_zero_vit-b_512x512_20k_12_10.py
2024-06-24 00:09:32,545 - mmseg - INFO - Iter [20000/20000]	lr: 1.003e-06, eta: 0:00:00, time: 1.663, data_time: 0.004, memory: 19084, decode.loss_mask: 14.3843, decode.loss_dice: 2.9083, decode.acc_seg: 448.7601, loss: 17.2926
