####################
#
# Example Job for HTCondor
#
####################

#---------------------------------------------
# Name your batch so it's easy to distinguish in the q.
JobBatchName = "Antoine-ZegCLIP-train-2-specific"

# --------------------------------------------
# Executable and its arguments
#executable    = /mnt/fast/nobackup/users/ae01116/multi-modal-dissertation-uos/zegenv/bin/python3.9
executable    = /mnt/fast/nobackup/scratch4weeks/ae01116/zegenv/bin/python3.9
arguments     = $ENV(PWD)/start_training.py
#arguments     = $ENV(PWD)/start_testing.py
#arguments    = $ENV(PWD)/just_print.py

# ---------------------------------------------------
# Universe (vanilla, docker)
universe         = vanilla

# -------------------------------------------------
# Event, out and error logs
log    = logs/c$(cluster).p$(process).log
output = logs/c$(cluster).p$(process).out
error  = logs/c$(cluster).p$(process).error

stream_output = True
stream_error  = True

# -----------------------------------
# File Transfer, Input, Output
should_transfer_files = YES
when_to_transfer_output = ON_EXIT

# transfer all the files in the current directory

# transfer_input_files = $ENV(PWD)
#transfer_input_files = $ENV(PWD)/antoine-zeg.submit_file, $ENV(PWD)/train.py, $ENV(PWD)/get_flops.py, $ENV(PWD)/logs, $ENV(PWD)/models, $ENV(PWD)/data, $ENV(PWD)/docker_stderror, $ENV(PWD)/start_training.py, $ENV(PWD)/test.py, $ENV(PWD)/dist_train.sh, $ENV(PWD)/weights, $ENV(PWD)/configs
transfer_input_files = $ENV(PWD)/start_training.py, $ENV(PWD)/dist_train.sh, $ENV(PWD)/start_testing.py

# Make certain project spaces available in container
# Uncomment this environment line if you're not running on /mnt/fast
#environment = "mount=$ENV(PWD)"

# -------------------------------------
# Requirements for the Job (Requirements are explained in further detail in example09.submit_file)
# NOTE: HasStornext is not valid on orca.
# requirements = (CUDAGlobalMemoryMb > 4500) && (CUDAGlobalMemoryMb <  19000) && \
#               (HasStornext) && \
#               (CUDACapability > 2.0)

requirements = (CUDACapability > 2.0) && (CUDAGlobalMemoryMb > 10000) && (CUDAGlobalMemoryMb <  16000)
#+GPUDevice = "GPU-2d0384f8-9b4f-de85-ae26-75080ed9ec3b"

# # --------------------------------------
# # Resources
request_GPUs     = 4
# # this needs to be specified for the AI@Surrey cluster if requesting a GPU
+GPUMem          = 10000  
request_CPUs   = 1
# # tailor the number of CPUs to your needs - check epoch time or GPU power usage via 
# # https://wandb.ai/site to know that you're not staving the GPU
request_memory   = 64G

#This job will complete in less than 1 hour
+JobRunTime = 1

#This job can checkpoint
+CanCheckpoint = true

# -----------------------------------
# Queue commands

queue
